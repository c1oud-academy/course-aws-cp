WEBVTT

00:00:00.000 --> 00:00:02.440
Добрый день, уважаемые студенты!

00:00:02.440 --> 00:00:06.760
Я рад вас всех видеть на очередной сессии демо.

00:00:06.760 --> 00:00:10.760
Тема сегодняшней сессии – это часто встречающиеся

00:00:10.760 --> 00:00:13.760
сценарии на реальном экзамене AWS.

00:00:13.760 --> 00:00:19.720
Мы рассмотрим все популярные и возможные ответы в случае

00:00:19.720 --> 00:00:20.720
такого сценария.

00:00:20.720 --> 00:00:22.840
Итак, давайте начнем.

00:00:22.840 --> 00:00:28.760
Перед тем, как мы начнем, я бы хотел указать источник,

00:00:28.760 --> 00:00:30.160
что эта информация была взята.

00:00:30.160 --> 00:00:35.080
Все вы, возможно, слышали, возможно, нет, но есть такой

00:00:35.080 --> 00:00:40.120
человек Джон Бонса, достаточно яркая личность в сфере подготовки

00:00:40.120 --> 00:00:41.960
к экзаменам AWS.

00:00:41.960 --> 00:00:45.840
Все начиналось с того, что этот человек владел сайтом,

00:00:45.840 --> 00:00:50.480
на котором закидывал гайды по определенным сервисам.

00:00:50.480 --> 00:00:53.880
То есть берется какой-то сервис AWS Lambda и подготовленная

00:00:53.880 --> 00:00:57.960
для него тезисная информация о этом сервисе.

00:00:57.960 --> 00:01:00.320
И эта информация, она часто встречается на экзамене

00:01:00.320 --> 00:01:05.720
и довольно хорошо помогает повторить большую часть

00:01:05.720 --> 00:01:08.680
материала, читая эти тезисы.

00:01:08.680 --> 00:01:11.840
Они достаточно короткие и сжатые, и так было приготовлено

00:01:11.840 --> 00:01:13.840
для большей части сервисов.

00:01:13.840 --> 00:01:18.800
Далее проект развивался буквально на глазах, и в

00:01:18.800 --> 00:01:24.240
какой-то момент появились тесты для подготовки к

00:01:24.240 --> 00:01:29.360
экзаменам AWS, опубликованные в Udemy.

00:01:29.360 --> 00:01:39.600
После чего этот проект вырос уже из Udemy и tutorials.dojo.com

00:01:39.600 --> 00:01:42.200
превратился в некий учебный портал, в котором начали

00:01:42.200 --> 00:01:44.080
появляться тесты.

00:01:44.080 --> 00:01:48.240
Есть движок тестирования, который подбирает вопросы,

00:01:48.240 --> 00:01:50.760
интерфейс улучшился.

00:01:50.760 --> 00:01:53.960
Через какое-то время наступил следующий шаг, подготовили

00:01:53.960 --> 00:01:56.840
дополнительный материал и уже появились не только

00:01:56.840 --> 00:02:03.240
разборы тестовых вопросов, но и целые курсы для подготовки

00:02:03.240 --> 00:02:06.760
к определенному экзамену AWS.

00:02:06.760 --> 00:02:13.020
Наряду со всем этим материалом также есть страницы, специально

00:02:13.020 --> 00:02:16.320
предназначенные для каждого экзамена AWS, которые рассматривают

00:02:16.320 --> 00:02:17.320
ее с разных сторон.

00:02:17.320 --> 00:02:22.000
И один кейс, это Common Exam Scenarios, как раз таки по этой ссылке

00:02:22.000 --> 00:02:27.480
вы можете напрямую перейти, либо в Google написать Bonsu AWS

00:02:27.480 --> 00:02:31.520
CP, то есть Cloud Practitioner и Common Scenarios, вы попадете

00:02:31.520 --> 00:02:32.880
на нужную вам страницу.

00:02:32.880 --> 00:02:41.000
Я достаточно позитивно высказался касательно ресурса, это

00:02:41.000 --> 00:02:46.160
действительно так, но есть один небольшой нюанс, который

00:02:46.160 --> 00:02:47.800
достаточно важен.

00:02:47.800 --> 00:02:50.280
Материала много, материал полезный.

00:02:50.280 --> 00:02:53.200
Из минусов это то, что он полностью на английском,

00:02:53.200 --> 00:02:54.200
это первое.

00:02:54.200 --> 00:02:58.880
И второе, это то, что не все материалы, не вся информация,

00:02:58.880 --> 00:03:00.480
она актуальная.

00:03:00.480 --> 00:03:08.600
Поэтому какие-то цифры, точные факты рекомендуется

00:03:08.600 --> 00:03:13.840
перепроверять на документации AWS.

00:03:13.840 --> 00:03:16.960
Основные же концепции, они в целом редко меняются

00:03:16.960 --> 00:03:21.000
и можно сказать, что вот такого рода информацию

00:03:21.000 --> 00:03:26.040
можно читать и воспринимать как актуальную на вот подобных

00:03:26.040 --> 00:03:30.040
сайтах.

00:03:30.040 --> 00:03:32.000
Возвращаемся обратно к нашим слайдам.

00:03:32.000 --> 00:03:35.240
Слайды организованы следующим образом.

00:03:35.240 --> 00:03:38.760
Все слайды поделены на четыре направления, это домены,

00:03:38.760 --> 00:03:42.580
старые домены экзамена AWS Certified Cloud Practitioner, сейчас

00:03:42.580 --> 00:03:49.680
пять доменов, но это никак не понижает ценность этой

00:03:49.680 --> 00:03:55.760
информации, а лишь помогает нам сгруппировать все кейсы

00:03:55.760 --> 00:04:00.080
по четырем различным направлениям.

00:04:00.080 --> 00:04:02.320
Сами слайды организованы следующим образом.

00:04:02.320 --> 00:04:04.760
Есть сценарии, там какое-то предложение либо часть

00:04:04.760 --> 00:04:08.200
предложения, описывающие наш сценарий и соответственно

00:04:08.200 --> 00:04:09.200
решение.

00:04:09.200 --> 00:04:11.220
� ешением в большинстве случаев является один или

00:04:11.220 --> 00:04:15.400
несколько сервисов AWS, в каких-то случаях это определенный

00:04:15.400 --> 00:04:19.360
функционал внутри определенного сервиса, либо какое-то понятие

00:04:19.360 --> 00:04:20.360
и термин.

00:04:20.360 --> 00:04:28.480
Я бы здесь хотел особо отметить, что это не является шпаргалкой.

00:04:28.480 --> 00:04:34.560
Это больше материал для повторения студентам,

00:04:34.560 --> 00:04:37.260
которые прошли весь теортический материал и здесь как раз

00:04:37.260 --> 00:04:40.280
таки рассматриваются самые популярные кейсы, а основные

00:04:40.280 --> 00:04:42.880
моменты, на которые стоит акцентировать, обратить

00:04:42.880 --> 00:04:45.840
внимание и дополнительно повторить.

00:04:45.840 --> 00:04:49.960
Поэтому для тех, кто только зашел на курс и сразу перешел

00:04:49.960 --> 00:04:53.080
на последнее демо, это бесполезный материал, набор непонятных

00:04:53.080 --> 00:04:54.080
терминов.

00:04:54.080 --> 00:04:57.760
Для тех, кто планомерно двигался, это достаточно

00:04:57.760 --> 00:05:00.720
ценный материал, который вам поможет структурировать

00:05:00.720 --> 00:05:01.720
ваши знания.

00:05:01.720 --> 00:05:06.000
Более того, эти частые кейсы не только те кейсы, которые

00:05:06.000 --> 00:05:08.200
встречаются на экзамене AWS.

00:05:08.200 --> 00:05:10.560
В нашем экзамен построен на том, чтобы помогать вам

00:05:10.560 --> 00:05:13.360
в будущем, когда вы будете работать с AWS.

00:05:13.360 --> 00:05:19.080
Поэтому внутри экзамена вопросы взяты из реальной

00:05:19.080 --> 00:05:21.280
жизни облачного инженера.

00:05:21.280 --> 00:05:24.000
И те кейсы, которые мы здесь разберем, вы также будете

00:05:24.000 --> 00:05:27.000
использовать, когда вы будете работать облачным инженером

00:05:27.000 --> 00:05:28.560
в одной из компаний.

00:05:28.560 --> 00:05:32.040
Хорошо, давайте начинаем, двигаемся дальше.

00:05:32.040 --> 00:05:37.720
Первый домен, первая группа сценариев.

00:05:37.720 --> 00:05:41.760
Это Cloud Concepts, то есть основные понятия облачных технологий.

00:05:41.760 --> 00:05:47.520
Итак, сценарий.

00:05:47.520 --> 00:05:51.640
Какие финансовые преимущества получает компания при миграции

00:05:51.640 --> 00:05:57.480
всех своих систем из локального дата центра в AWS?

00:05:57.480 --> 00:05:58.480
Ответ.

00:05:58.480 --> 00:06:02.160
Первым ответом является то, что компания заменяет

00:06:02.160 --> 00:06:05.760
капитальные расходы на операционные расходы.

00:06:05.760 --> 00:06:07.640
Что это означает?

00:06:07.640 --> 00:06:10.800
Мы с вами говорили, что капитальные расходы это, когда мы несем

00:06:10.800 --> 00:06:12.480
расходы наперед.

00:06:12.480 --> 00:06:16.280
Одним из ярких примеров это покупка целого сервера.

00:06:16.280 --> 00:06:21.320
То есть вы покупаете за большую сумму и вне зависимости

00:06:21.320 --> 00:06:24.920
от того, вы будете использовать пять лет либо три месяца,

00:06:24.920 --> 00:06:26.680
вы должны оплатить всю сумму.

00:06:26.680 --> 00:06:30.040
Когда мы говорим операционные расходы и в частности облака

00:06:30.040 --> 00:06:36.120
AWS, мы можем поднять EC2 instance достаточно мощный, использовать

00:06:36.120 --> 00:06:40.360
его три часа, оплатить только за три часа и после этого

00:06:40.360 --> 00:06:43.680
высвободить наши ресурсы для того, чтобы не платить.

00:06:43.680 --> 00:06:52.960
Таким образом мы можем все или большую часть капитальных

00:06:52.960 --> 00:06:58.280
расходов, когда мы владеем собственным дата центром,

00:06:58.280 --> 00:07:01.680
перенести на операционные расходы и оплачивать только

00:07:01.680 --> 00:07:05.800
за то, что мы используем при переходе на AWS.

00:07:05.800 --> 00:07:08.720
Третье пример, это reduce the total cost of ownership.

00:07:08.720 --> 00:07:12.400
То есть идея такая же, когда мы владеем собственным

00:07:12.400 --> 00:07:17.160
локальным дата центром, то в этом случае нам необходимо

00:07:17.160 --> 00:07:18.840
все закупать сразу.

00:07:18.840 --> 00:07:23.200
Возможно у вас очень большие затраты пойдут на покупку

00:07:23.200 --> 00:07:26.120
помещения либо ежемесячная трата на аренду.

00:07:26.120 --> 00:07:29.520
Далее у вас есть штат сотрудников, которые поддерживают

00:07:29.520 --> 00:07:30.880
работу дата центра.

00:07:30.880 --> 00:07:34.560
Это те расходы, которые постоянные, не меняются.

00:07:34.560 --> 00:07:40.720
Даже если у вас на вашем сайте не будет ни одного

00:07:40.720 --> 00:07:42.740
пользователя, то вы все равно будете нести эти

00:07:42.740 --> 00:07:43.740
расходы.

00:07:43.740 --> 00:07:48.320
Когда же мы говорим про AWS, мы можем построить инфраструктуру

00:07:48.320 --> 00:07:52.140
таким образом, что она автомасштабируется и в большую и в меньшую

00:07:52.140 --> 00:07:53.140
сторону.

00:07:53.140 --> 00:07:59.800
И в случае, когда мы видим спад трафика, нет ни одного

00:07:59.800 --> 00:08:03.100
пользователя на нашем сайте, нет нагрузки, в этом случае

00:08:03.100 --> 00:08:06.280
инфраструктура может автоматически уменьшиться до минимальных

00:08:06.280 --> 00:08:07.280
размеров.

00:08:07.280 --> 00:08:11.000
Таким образом мы будем нести также минимальные расходы

00:08:11.000 --> 00:08:12.560
на нашу инфраструктуру.

00:08:12.560 --> 00:08:17.680
Сценарий.

00:08:17.680 --> 00:08:23.920
Укажите принципы построения архитектуры в облаке AWS.

00:08:23.920 --> 00:08:25.440
Ответы решения.

00:08:25.440 --> 00:08:27.200
Первое это Design for Failure.

00:08:27.200 --> 00:08:31.200
Идея в том, что при увеличении размеров вашей инфраструктуры

00:08:31.200 --> 00:08:35.160
пропорционально также увеличивается вероятность того, что где-то

00:08:35.160 --> 00:08:38.560
что-то пойдет не так, какой-то из компонентов сломается.

00:08:38.560 --> 00:08:42.680
И идея этого принципа в том, что необходимо думать

00:08:42.680 --> 00:08:46.520
наперед, зная какие компоненты могут сломаться, добавлять

00:08:46.520 --> 00:08:51.520
либо избыточность, либо возможность быстрого авто-восстановления.

00:08:51.520 --> 00:08:54.680
Второе Decouple your components.

00:08:54.680 --> 00:08:57.840
Идея в том, что нужно строить архитектуру таким образом,

00:08:57.840 --> 00:09:01.040
чтобы все компоненты были слабо связаны между собой.

00:09:01.040 --> 00:09:02.800
Зачем это нужно?

00:09:02.800 --> 00:09:06.320
При слабой связанности можно легко заменить каждый

00:09:06.320 --> 00:09:07.320
компонент.

00:09:07.320 --> 00:09:14.220
Более того, при поломке какого-то компонента оно меньше влияет

00:09:14.220 --> 00:09:15.680
на соседние компоненты.

00:09:15.680 --> 00:09:22.040
Таким образом, разрушительное влияние какой-то поломки

00:09:22.040 --> 00:09:26.040
оно будет уменьшено за счет вот такой архитектуры.

00:09:26.040 --> 00:09:28.880
Третье, четвертое это связано Implement Elasticity.

00:09:28.880 --> 00:09:35.800
То есть говорим про гибкость и Think Parallel это про масштабирование.

00:09:35.800 --> 00:09:39.440
Идея в том, что у нас есть связка сервисов, при правильной

00:09:39.440 --> 00:09:42.400
настройке архитектура превращается в живой организм.

00:09:42.400 --> 00:09:45.400
И может в зависимости от некоторых метрик, например

00:09:45.400 --> 00:09:48.320
нагрузки на ваши сервера, увеличиваться автоматически

00:09:48.320 --> 00:09:51.360
в размерах как в большую, так и в меньшую сторону.

00:09:51.360 --> 00:09:56.000
Более подробно вы можете посмотреть наши принципы

00:09:56.000 --> 00:10:00.600
построения архитектур на лекционном занятии.

00:10:00.600 --> 00:10:01.600
Сценарий.

00:10:01.600 --> 00:10:05.960
У нас есть критические нагрузки в облаке AWS, которые должны

00:10:05.960 --> 00:10:07.200
быть высоко доступны.

00:10:07.200 --> 00:10:11.560
Что необходимо использовать как частое решение это

00:10:11.560 --> 00:10:14.600
строить инфраструктуру на нескольких availability

00:10:14.600 --> 00:10:15.600
зонах.

00:10:15.600 --> 00:10:19.480
Таким образом, крайне вероятное событие выхода из строя

00:10:19.480 --> 00:10:27.160
целой одной availability зоны, она будет учтена и в случае,

00:10:27.160 --> 00:10:32.320
даже если произойдет это событие, ваша инфраструктура

00:10:32.320 --> 00:10:35.600
продолжит работать, но уже на оставшихся двух либо

00:10:35.600 --> 00:10:37.480
второй availability зоне.

00:10:37.480 --> 00:10:39.800
Сценарий.

00:10:39.800 --> 00:10:43.740
Нам необходимо, чтобы изменение либо поломка одного из компонентов

00:10:43.740 --> 00:10:46.600
не эскалировало на другие компоненты.

00:10:46.600 --> 00:10:49.320
То есть не переходило и не влияло, не ломало следующие

00:10:49.320 --> 00:10:52.000
компоненты, которые по соседству.

00:10:52.000 --> 00:10:56.480
Как решение строить архитектуру слабосвязную, то есть loose

00:10:56.480 --> 00:10:57.480
coupling.

00:10:57.480 --> 00:10:59.680
Если мы говорим сильно связные, то есть соответствующий

00:10:59.680 --> 00:11:00.880
термин tight coupling.

00:11:00.880 --> 00:11:04.480
И нам необходимо стремиться строить архитектуру от tight

00:11:04.480 --> 00:11:06.360
coupling в сторону loose coupling.

00:11:06.360 --> 00:11:07.360
Сценарий.

00:11:07.360 --> 00:11:16.600
У вас есть VPC, VPC есть public subnet и внутри EC2 instance.

00:11:16.600 --> 00:11:21.080
Необходимо, чтобы этот EC2 instance мог выходить в общий

00:11:21.080 --> 00:11:22.080
интернет.

00:11:22.080 --> 00:11:25.920
Как решение, нам необходим интернет gateway.

00:11:25.920 --> 00:11:29.720
Сценарий.

00:11:29.720 --> 00:11:34.040
У вас есть настроенные VPC, внутри VPC есть private subnet

00:11:34.040 --> 00:11:36.840
и внутри private subnet EC2 instance.

00:11:36.840 --> 00:11:39.920
Необходимо, чтобы этот EC2 instance мог выходить в интернет.

00:11:39.920 --> 00:11:46.080
Так как в вопросе явно указано, что EC2 instance находится внутри

00:11:46.080 --> 00:11:51.240
private subnet, то ресурс который дает доступ в интернет

00:11:51.240 --> 00:11:54.000
instance это NAT gateway.

00:11:54.000 --> 00:11:57.720
NAT gateway настраивается в public subnet и мы настраиваем

00:11:57.720 --> 00:12:02.200
дополнительный route, чтобы направлять трафик из private

00:12:02.200 --> 00:12:06.600
subnet в NAT gateway в public subnet.

00:12:06.600 --> 00:12:09.320
Там далее уже на уровне VPC настраивается интернет

00:12:09.320 --> 00:12:13.540
gateway, через который и выходят в интернет все ресурсы внутри

00:12:13.540 --> 00:12:17.260
вашего VPC.

00:12:17.260 --> 00:12:21.520
Мы с вами переходим к следующему блоку сценариев.

00:12:21.520 --> 00:12:27.640
Это security и compliance.

00:12:27.640 --> 00:12:31.520
Укажите инструмент для настройки безопасности,

00:12:31.520 --> 00:12:37.840
а именно настройки WAV рулов поверх нескольких аккаунтов.

00:12:37.840 --> 00:12:44.080
Как ответ это сервис AWS Firewall Manager.

00:12:44.080 --> 00:12:45.080
Сценарий.

00:12:45.080 --> 00:12:49.080
Компании необходимо загрузить документы, подтверждающие

00:12:49.080 --> 00:12:53.800
соответствия AWS определенным регуляторным требованиям

00:12:53.800 --> 00:12:56.040
либо требованиям стандартов.

00:12:56.040 --> 00:12:57.040
Ответ.

00:12:57.040 --> 00:13:00.080
Вам необходимо обратиться в сервис AWS Artifact, где загружены

00:13:00.080 --> 00:13:04.440
все эти документы и вы можете по требованию эти документы

00:13:04.440 --> 00:13:05.440
скачать.

00:13:05.440 --> 00:13:08.360
Сценарий.

00:13:08.360 --> 00:13:10.480
Что необходимо сделать для того, чтобы улучшить

00:13:10.480 --> 00:13:13.400
безопасность IAM пользователей.

00:13:13.400 --> 00:13:17.960
Первый ответ это настроить multifactor authentication.

00:13:17.960 --> 00:13:24.840
Второе это настроить достаточно сложное правило для пароли

00:13:24.840 --> 00:13:25.840
ваших пользователей.

00:13:25.840 --> 00:13:36.960
Какая сущность IAM использует аксесс ключи для доступа

00:13:36.960 --> 00:13:41.600
к ресурсам в облаке AWS через AWS CLI.

00:13:41.600 --> 00:13:45.720
Ответ IAM user.

00:13:45.720 --> 00:13:46.720
Сценарий.

00:13:46.720 --> 00:13:53.400
К какой сущности IAM мы предоставляем временный доступ к нашим

00:13:53.400 --> 00:13:55.040
AWS ресурсам.

00:13:55.040 --> 00:14:00.280
Ответ IAM role.

00:14:00.280 --> 00:14:05.480
Что необходимо использовать для того, чтобы управлять

00:14:05.480 --> 00:14:09.240
доступами для большого количества IAM пользователей.

00:14:09.240 --> 00:14:10.400
Ответ IAM группы.

00:14:10.400 --> 00:14:17.160
Что мы можем использовать для того, чтобы предоставить

00:14:17.160 --> 00:14:22.800
доступ к нашим ресурсам в бакете S3.

00:14:22.800 --> 00:14:23.800
Ответ.

00:14:23.800 --> 00:14:27.480
Мы можем настроить bucket policy, который привязан к бакету.

00:14:27.480 --> 00:14:32.440
Там вы указываете уже операции и пользователей, которые

00:14:32.440 --> 00:14:34.560
могут обращаться к вашему бакету.

00:14:34.560 --> 00:14:38.720
Можно настроить с другой стороны, а именно user policy.

00:14:38.720 --> 00:14:42.560
Вы для каждого пользователя, для группы, либо для роли

00:14:42.560 --> 00:14:47.360
прописываете дополнительные полиси о том, что эта полиси

00:14:47.360 --> 00:14:51.000
дает доступ к определенным операциям, к таким-то ресурсам.

00:14:51.000 --> 00:14:56.320
Как ресурс мы указываем наши S3 бакеты.

00:14:56.320 --> 00:15:02.040
Нам необходимо предоставить доступ к AWS через предоставление

00:15:02.040 --> 00:15:05.040
временных credential для пользователей.

00:15:05.040 --> 00:15:08.080
И эти пользователи, они авторизованы через социальные

00:15:08.080 --> 00:15:11.400
медиа, либо совсем могут быть не авторизованы, то

00:15:11.400 --> 00:15:13.520
есть анонимные гости.

00:15:13.520 --> 00:15:16.320
Что мы можем использовать для того, чтобы это обеспечить.

00:15:16.320 --> 00:15:19.240
Как ответ использовать Amazon Cognito Identity Pool.

00:15:19.240 --> 00:15:23.440
Сценарий.

00:15:23.440 --> 00:15:27.560
Вы являетесь стартапом и вам необходимо оценить,

00:15:27.560 --> 00:15:30.040
как работают ваши IAM policy.

00:15:30.040 --> 00:15:35.200
Для этого необходимо использовать IAM policy simulator.

00:15:35.200 --> 00:15:36.200
Следующий сценарий.

00:15:36.200 --> 00:15:43.240
Необходимо указать сервис, который находит, классифицирует

00:15:43.240 --> 00:15:47.760
и защищает важную информацию, которая относится к PII,

00:15:47.760 --> 00:15:50.280
то есть это информация, которая может идентифицировать

00:15:50.280 --> 00:15:53.240
личность, либо относится к интеллектуальной собственности.

00:15:53.240 --> 00:15:56.240
В этом случае необходимо воспользоваться сервисом

00:15:56.240 --> 00:16:00.080
Amazon Macie.

00:16:00.080 --> 00:16:05.640
Укажите сервис, который мониторит весь ваш AWS аккаунт

00:16:05.640 --> 00:16:09.300
для поиска различных угроз и подозрительной активности.

00:16:09.300 --> 00:16:12.040
Это сервис Amazon GuardDuty.

00:16:12.040 --> 00:16:17.120
Вам необходимо запретить не авторизованное удаление

00:16:17.120 --> 00:16:19.160
объектов внутри S3 пакетов.

00:16:19.160 --> 00:16:27.040
Для этого необходимо настроить MFA и при удалении объектов

00:16:27.040 --> 00:16:30.280
доступ будет разрешен только тем сущностям, то есть

00:16:30.280 --> 00:16:34.580
ролям пользователям, у которых была пройдена

00:16:34.580 --> 00:16:35.580
MFA проверка.

00:16:35.580 --> 00:16:41.720
В компании необходимо контролировать трафик между сабнетами

00:16:41.720 --> 00:16:42.720
VPC.

00:16:42.720 --> 00:16:48.680
Это относится как к входящим, так и исходящему трафику.

00:16:48.680 --> 00:16:55.840
Необходимо для этого использовать Network ICO.

00:16:55.840 --> 00:16:58.840
Укажите, что является неким виртуальным фаерволом

00:16:58.840 --> 00:17:05.680
и работает для контроля трафика на уровне EC2-инстанца.

00:17:05.680 --> 00:17:10.280
Ответ – это security-группа.

00:17:10.280 --> 00:17:13.800
Укажите сервис, который проводит автоматические

00:17:13.800 --> 00:17:17.980
проверки безопасности для ваших приложений.

00:17:17.980 --> 00:17:20.680
Это Amazon Inspector.

00:17:20.680 --> 00:17:24.760
Мы с вами добрались до следующего блока сценариев, связанных

00:17:24.760 --> 00:17:26.400
с технологиями.

00:17:26.400 --> 00:17:33.800
В компании необходимо начать использовать глобальную

00:17:33.800 --> 00:17:37.040
инфраструктуру AWS для того, чтобы улучшить доступность

00:17:37.040 --> 00:17:41.360
своих приложений, при этом чтобы они были доступны

00:17:41.360 --> 00:17:43.640
по любому статическому IP-адресу.

00:17:43.640 --> 00:17:53.520
В этом случае нам необходимо использовать AWS Global Accelerator.

00:17:53.520 --> 00:17:54.800
Следующий сценарий.

00:17:54.800 --> 00:18:01.480
Нам необходимо безопасно передать в AWS сотни петабайтов

00:18:01.480 --> 00:18:02.480
данных.

00:18:02.480 --> 00:18:06.760
Что для этого можно использовать?

00:18:06.760 --> 00:18:11.320
Вы видите, что петабайт передавать по сети – это

00:18:11.320 --> 00:18:15.160
достаточно большой объем информации, это много времени,

00:18:15.160 --> 00:18:18.480
а много времени, соответственно, компания не всегда может

00:18:18.480 --> 00:18:19.480
ждать.

00:18:19.480 --> 00:18:26.440
Поэтому есть решение, когда AWS выгружает кейс, в котором

00:18:26.440 --> 00:18:30.600
у нас есть жесткие диски, вычислительная мощность

00:18:30.600 --> 00:18:33.800
и отправляет этот чемоданчик нам в офис.

00:18:33.800 --> 00:18:36.920
Как только она приезжает, мы подключаем ее к сети

00:18:36.920 --> 00:18:39.080
и можем в него загрузить большой объем информации

00:18:39.080 --> 00:18:41.920
по локальной сети, что намного быстрее.

00:18:41.920 --> 00:18:46.000
И после того, как мы закончили, мы этот чемоданчик возвращаем

00:18:46.000 --> 00:18:49.320
обратно и как только она доходит до любого дата-центра

00:18:49.320 --> 00:18:52.400
AWS, они подключают уже к своей локальной сети и

00:18:52.400 --> 00:18:56.400
быстренько загружают ее с локальной, с быстрой

00:18:56.400 --> 00:19:01.680
скоростью в инфраструктуру AWS.

00:19:01.680 --> 00:19:05.760
Есть несколько видов решений Snowball.

00:19:05.760 --> 00:19:12.400
Есть Snowball Edge, Snowball обычные, которые поменьше.

00:19:12.400 --> 00:19:17.320
И есть Snowmobile, когда вам отправляет целый прицеп

00:19:17.320 --> 00:19:24.880
с машиной и она добирается до вас и можно не только

00:19:24.880 --> 00:19:29.160
сотни петабайтов, а еще больше данных загрузить

00:19:29.160 --> 00:19:33.880
в этот мобильный дата-центр.

00:19:33.880 --> 00:19:39.360
Укажите тип инстанция EC2, который позволяет вам

00:19:39.360 --> 00:19:44.840
перенести лицензии, привязанные к определенному хосту.

00:19:44.840 --> 00:19:49.880
Это тип dedicated host.

00:19:49.880 --> 00:19:51.120
Следующий сценарий.

00:19:51.120 --> 00:19:53.600
Укажите сервис, который мониторит всю активность

00:19:53.600 --> 00:19:59.080
внутри AWS и фиксирует все вызовы AWS API, будь оно

00:19:59.080 --> 00:20:05.760
через AWS Management Console, либо через AWS SDK.

00:20:05.760 --> 00:20:08.560
Этим сервисом является AWS CloudTrail.

00:20:08.560 --> 00:20:16.160
CloudTrail это аналог черного ящика в самолете.

00:20:16.160 --> 00:20:21.080
Укажите DNS-веб-сервис внутри AWS, который является достаточно

00:20:21.080 --> 00:20:24.200
высокодоступным и масштабируемым.

00:20:24.200 --> 00:20:28.040
Этот сервис Amazon Route 53.

00:20:28.040 --> 00:20:30.720
Следующий пример.

00:20:30.720 --> 00:20:35.320
Нам необходимо сохранять результаты сложных SQL-запросов

00:20:35.320 --> 00:20:37.600
для того, чтобы ускорить производительность наших

00:20:37.600 --> 00:20:38.640
приложений.

00:20:38.640 --> 00:20:42.560
Для этого нам необходимо использовать кэш-сервис,

00:20:42.560 --> 00:20:46.520
это Amazon ElastiCache.

00:20:46.520 --> 00:20:49.680
Нам необходимо указать связку AWS-сервисов, которые

00:20:49.680 --> 00:20:56.680
позволяют обслуживать статические файлы с наименьшей задержкой.

00:20:56.680 --> 00:21:01.200
Это Amazon S3 и Amazon CloudFront.

00:21:01.200 --> 00:21:02.880
Следующие сценарии.

00:21:02.880 --> 00:21:05.760
Необходимо указать сервис, который предоставляет

00:21:05.760 --> 00:21:09.080
автоматическое масштабирование вычислительных мощностей

00:21:09.080 --> 00:21:12.000
в зависимости от входящего трафика для того, чтобы

00:21:12.000 --> 00:21:16.160
улучшить доступность ваших приложений и сократить

00:21:16.160 --> 00:21:20.520
падение ввиду перегрузки ваших вычислительных мощностей.

00:21:20.520 --> 00:21:26.160
Вот этим является AWS Autoscaling.

00:21:26.160 --> 00:21:31.800
Нам необходимо перенести базу данных MySQL с локального

00:21:31.800 --> 00:21:35.440
дата-центра на сервис Amazon RDS.

00:21:35.440 --> 00:21:38.360
Каким сервисом мы можем для этого воспользоваться?

00:21:38.360 --> 00:21:41.080
Есть отдельный сервис для миграции баз данных, называется

00:21:41.080 --> 00:21:48.920
AWS DMS, либо в развернутом виде AWS Database Migration Service.

00:21:48.920 --> 00:21:51.600
Следующие сценарии.

00:21:51.600 --> 00:21:56.480
Нам необходимо настроить автоматический перенос на

00:21:56.480 --> 00:21:59.760
следующий класс хранения нечасто запрашиваемых

00:21:59.760 --> 00:22:03.320
данных внутри S3-бакета для того, чтобы сэкономить

00:22:03.320 --> 00:22:04.320
на хранении.

00:22:04.320 --> 00:22:07.640
Для этого нам необходимо воспользоваться S3 Lifecycle

00:22:07.640 --> 00:22:11.120
Policy.

00:22:11.120 --> 00:22:16.240
Вам необходимо загрузить один большой объект в S3

00:22:16.240 --> 00:22:21.720
несколькими частями для того, чтобы ускорить ее

00:22:21.720 --> 00:22:22.720
перенос.

00:22:22.720 --> 00:22:24.400
Что необходимо для этого сделать?

00:22:24.400 --> 00:22:27.200
Мы для этого можем воспользоваться функционалом сервиса

00:22:27.200 --> 00:22:30.760
S3 Multi-Part Upload.

00:22:30.760 --> 00:22:34.640
Идея ее в том, что наш файл делится на несколько маленьких

00:22:34.640 --> 00:22:37.600
частей и эти части отправляются по отдельности.

00:22:37.600 --> 00:22:41.760
В случае, если какая-то часть падает, ее можно

00:22:41.760 --> 00:22:44.200
отдельно доотправить.

00:22:44.200 --> 00:22:49.080
Более того, вы можете отправлять все ваши файлы параллельно.

00:22:49.080 --> 00:22:55.360
Таким образом ускоряется в несколько раз передача

00:22:55.360 --> 00:23:00.080
ваших файлов в облако AWS.

00:23:00.080 --> 00:23:01.080
Следующий кейс.

00:23:01.080 --> 00:23:04.200
Необходимо для компании предоставить выделенные

00:23:04.200 --> 00:23:12.040
connection между локальным дата-центром и AWS VPC.

00:23:12.040 --> 00:23:14.440
Для этого нам необходимо воспользоваться сервисом

00:23:14.440 --> 00:23:18.640
AWS Direct Connect.

00:23:18.640 --> 00:23:23.160
Укажите сервис машинного обучения, который позволяет

00:23:23.160 --> 00:23:27.560
нам анализировать медиа-файлы и извлекать полезную информацию.

00:23:27.560 --> 00:23:31.920
Здесь имеется в виду как медиа-файлы, это картинки

00:23:31.920 --> 00:23:33.600
и видеоматериалы.

00:23:33.600 --> 00:23:40.320
И то, что мы можем извлечь, это тексты, различные предметы

00:23:40.320 --> 00:23:48.720
кастомные и в следующий сценарий необходимо указать

00:23:48.720 --> 00:23:52.920
сервис, который позволяет делать трансферовку запросов

00:23:52.920 --> 00:23:56.280
пользователей внутри вашего приложения.

00:23:56.280 --> 00:24:00.840
Этот сервис AWS X-Ray он часто используется в связке с

00:24:00.840 --> 00:24:02.120
AWS Lambda.

00:24:02.120 --> 00:24:05.640
Идея в том, что когда приходит запрос от ваших пользователей,

00:24:05.640 --> 00:24:09.640
неважно на ваш API либо на ваш сайт, вы можете добавить

00:24:09.640 --> 00:24:12.880
к этому запросу некоторое уникальное значение.

00:24:12.880 --> 00:24:16.280
С этим уникальным значением этот запрос будет передаваться

00:24:16.280 --> 00:24:19.640
внутри всей вашей инфраструктуры и обрабатываться.

00:24:19.640 --> 00:24:23.700
Таким образом, отслеживая этот уникальный ID, вы можете

00:24:23.700 --> 00:24:27.660
видеть как и куда проходят ваши запросы, визуально

00:24:27.660 --> 00:24:31.080
увидеть где какие задержки и попробовать улучшить

00:24:31.080 --> 00:24:32.080
ваше приложение.

00:24:32.080 --> 00:24:39.120
В следующий кейс компании необходимо получить информацию

00:24:39.120 --> 00:24:44.800
о Instance ID, публичных ключах, публичном IP адресе вашего

00:24:44.800 --> 00:24:48.280
EC2 Instance, где эту информацию можно получить.

00:24:48.280 --> 00:24:51.760
И эту информацию можно получить в AWS Management Console.

00:24:51.760 --> 00:24:56.920
Если открыть ваш EC2 Instance, внизу откроется набор

00:24:56.920 --> 00:25:00.040
вкладок и выбрать вкладку Instance metadata.

00:25:00.040 --> 00:25:05.280
Там вся эта информация доступна.

00:25:05.280 --> 00:25:06.280
Сценарий.

00:25:06.280 --> 00:25:09.240
Возникли ли возможно ускорить доставку нашего контента

00:25:09.240 --> 00:25:14.120
по всему миру наших статических файлов?

00:25:14.120 --> 00:25:20.280
Ответ это воспользуется сервисом Amazon CloudFront.

00:25:20.280 --> 00:25:21.280
Следующий сценарий.

00:25:21.280 --> 00:25:28.160
Сервис, который позволяет нам создавать и деплоить

00:25:28.160 --> 00:25:31.440
инфраструктуру как код.

00:25:31.440 --> 00:25:32.440
Ответ очевиден.

00:25:32.440 --> 00:25:33.440
Это AWS CloudFormation.

00:25:33.440 --> 00:25:43.960
Нам необходимо настроить шифрование наших логов

00:25:43.960 --> 00:25:46.960
в AWS CloudTrail.

00:25:46.960 --> 00:25:50.000
Для этого необходимо воспользоваться специальным сервисом

00:25:50.000 --> 00:25:52.160
AWS Key Management Service.

00:25:52.160 --> 00:25:56.280
Чаще вы его будете встречать как AWS KeyMS.

00:25:56.280 --> 00:25:58.960
Следующий пример сценарий.

00:25:58.960 --> 00:26:04.080
Необходимо выбрать сервис, который предоставляет

00:26:04.080 --> 00:26:08.360
базы данных для работы с JSON документами.

00:26:08.360 --> 00:26:12.600
То есть это NoSQL базы данных, не структурированные данные.

00:26:12.600 --> 00:26:16.460
Ответ Amazon DynamoDB.

00:26:16.460 --> 00:26:20.840
На этом мы добрались к следующему блоку и поговорим про сценарии,

00:26:20.840 --> 00:26:22.720
связанные с биллингом и прайсингом.

00:26:22.720 --> 00:26:26.720
Сценарий.

00:26:26.720 --> 00:26:30.040
Нам необходимо выбрать опцию, где подразумевается

00:26:30.040 --> 00:26:36.880
выделенный человек от AWS, который дополнительно

00:26:36.880 --> 00:26:39.120
помогает нам сопровождать нашу инфраструктуру в

00:26:39.120 --> 00:26:40.280
облаке.

00:26:40.280 --> 00:26:48.240
Ответ это там либо развернутый вариант Technical Account Manager.

00:26:48.240 --> 00:26:49.400
Следующий сценарий.

00:26:49.400 --> 00:26:56.920
Нам необходимо выбрать из выбранных сценарий, нам

00:26:56.920 --> 00:27:02.480
необходимо выбрать инструмент, который периодически проверяет

00:27:02.480 --> 00:27:07.960
наш AWS Account и дает рекомендации, чтобы следовать best practice

00:27:07.960 --> 00:27:08.960
AWS.

00:27:08.960 --> 00:27:13.600
Это сервис AWS Trusted Advisor.

00:27:13.600 --> 00:27:15.760
Следующий сценарий.

00:27:15.760 --> 00:27:18.920
Мы являемся стартапом и нам необходимо рассчитать

00:27:18.920 --> 00:27:23.080
стоимость переноса наших приложений с бокального

00:27:23.080 --> 00:27:25.640
дата центра на AWS.

00:27:25.640 --> 00:27:31.040
Для этого мы можем воспользоваться отдельным приложением,

00:27:31.040 --> 00:27:39.280
инструментом, который называется AWS Total Cost of Ownership.

00:27:39.280 --> 00:27:40.280
Следующий сценарий.

00:27:40.280 --> 00:27:42.920
Нам необходимо выбрать тип Reserved Instances, которые

00:27:42.920 --> 00:27:49.080
позволяют менять семейство инстанца, тип инстанца и

00:27:49.080 --> 00:27:52.320
другие свойства наших EC2 инстанцев.

00:27:52.320 --> 00:27:55.680
Правильный ответ Convertible RI.

00:27:55.680 --> 00:27:57.560
Сценарий.

00:27:57.560 --> 00:28:01.560
Нам необходимо выбрать тип EC2 инстанцев, который

00:28:01.560 --> 00:28:04.920
позволяет получить скидку до 90%.

00:28:04.920 --> 00:28:06.520
Это spot инстанции.

00:28:06.520 --> 00:28:10.840
Здесь многие допускают ошибку и выбирают вариант

00:28:10.840 --> 00:28:13.880
либо savings plans либо reserved instances.

00:28:13.880 --> 00:28:17.960
И тот и другой вариант они предлагают скидку от 60

00:28:17.960 --> 00:28:19.440
до 70%.

00:28:19.440 --> 00:28:24.520
В случае с spot инстанциями мы можем получить до 90%

00:28:24.520 --> 00:28:29.280
скидки и это самый дешевый вариант EC2 инстанцев.

00:28:29.280 --> 00:28:33.280
Есть определенные нюансы, про которых мы говорили

00:28:33.280 --> 00:28:34.280
на наших лекциях.

00:28:34.280 --> 00:28:38.000
Сценарий.

00:28:38.000 --> 00:28:41.080
Нам необходимо выбрать приложение, которое позволяет

00:28:41.080 --> 00:28:46.520
нам управлять всеми нашими полисами из одного места,

00:28:46.520 --> 00:28:54.960
а также получать совокупный счет за оплату за услуги

00:28:54.960 --> 00:28:58.320
AWS по всем нашим AWS аккаунтам.

00:28:58.320 --> 00:29:02.680
Правильный ответ это Service AWS Organizations.

00:29:02.680 --> 00:29:03.680
Следующий сценарий.

00:29:03.680 --> 00:29:07.800
Нам необходимо выбрать самый дешевый вариант хранения

00:29:07.800 --> 00:29:16.280
внутри S3, а именно мы говорим про копии баз данных, которые

00:29:16.280 --> 00:29:20.600
могут быть запрошены изредка и при этом мы можем подождать

00:29:20.600 --> 00:29:22.160
несколько минут.

00:29:22.160 --> 00:29:25.960
Идеальным вариантом для этого кейса является Amazon

00:29:25.960 --> 00:29:26.960
Glacier.

00:29:26.960 --> 00:29:27.960
Сценарий.

00:29:27.960 --> 00:29:33.120
Необходимо выбрать сервис, который предоставляет

00:29:33.120 --> 00:29:39.320
нам прогнозные будущие расходы на базе наших текущих

00:29:39.320 --> 00:29:43.000
данных на базе текущего использования сервисов

00:29:43.000 --> 00:29:44.000
AWS.

00:29:44.000 --> 00:29:48.960
Ответом является Service AWS Cost Explorer.

00:29:48.960 --> 00:29:49.960
Следующий сценарий.

00:29:49.960 --> 00:29:53.440
Нам необходимо категоризировать и отслеживать наши расходы

00:29:53.440 --> 00:29:56.560
на AWS на более подробном уровне.

00:29:56.560 --> 00:29:59.800
Для этого нам необходимо воспользоваться функционалом,

00:29:59.800 --> 00:30:04.560
который называется Cost Allocation Tags.

00:30:04.560 --> 00:30:09.720
Идея ее в том, что мы можем тегировать все наши ресурсы

00:30:09.720 --> 00:30:10.720
AWS.

00:30:10.720 --> 00:30:15.560
В специально отведенном месте мы указываем, какие

00:30:15.560 --> 00:30:20.140
теги являются Cost Allocation Tags, после чего мы можем

00:30:20.140 --> 00:30:24.640
группировать и видеть наши расходы по выбранным нами

00:30:24.640 --> 00:30:29.160
тегам в сервисы AWS Cost Explorer, а также в любых других

00:30:29.160 --> 00:30:32.480
сервисах, которые работают с расходами на облако.

00:30:32.480 --> 00:30:35.920
Сценарий.

00:30:35.920 --> 00:30:38.640
Что необходимо сделать компании, если нам нужно

00:30:38.640 --> 00:30:46.480
запустить VPC, который не входит в сервисные лимиты

00:30:46.480 --> 00:30:47.920
по умолчанию?

00:30:47.920 --> 00:30:48.920
Ответ.

00:30:48.920 --> 00:30:53.680
Необходимо создать тикет в техподдержку и запросить

00:30:53.680 --> 00:30:58.960
увеличение этого лимита, если оно является софт-лимитом.

00:30:58.960 --> 00:31:02.760
В следующий сценарий нам необходимо выбрать самый

00:31:02.760 --> 00:31:11.280
выгодный вариант покупки Reserved Instances на один год.

00:31:11.280 --> 00:31:13.000
Ответом является All Upfront.

00:31:13.000 --> 00:31:16.960
Как мы с вами помним, мы можем выбрать три варианта

00:31:16.960 --> 00:31:21.280
оплаты, когда No Upfront мы не вносим никакую оплату,

00:31:21.280 --> 00:31:24.000
лишь подписываем договор и ежемесячно продолжаем

00:31:24.000 --> 00:31:30.800
платить за использование наших ресурсов со скидкой.

00:31:30.800 --> 00:31:32.880
Следующий вариант это Partial Upfront.

00:31:32.880 --> 00:31:37.000
Какая-то часть со скидкой оплачивается сразу за один

00:31:37.000 --> 00:31:40.920
год либо за три года, в зависимости от того, какой договор подписываем.

00:31:40.920 --> 00:31:44.680
И оставшаяся часть оплачивается дальше ежемесячно также

00:31:44.680 --> 00:31:45.680
со скидкой.

00:31:45.680 --> 00:31:49.320
И третий вариант, который дает наибольшее количество

00:31:49.320 --> 00:31:51.320
скидок это All Upfront.

00:31:51.320 --> 00:31:56.160
Когда делается расчет на выбранный период, рассчитывается

00:31:56.160 --> 00:32:00.840
скидка и та оставшаяся сумма к оплате, она должна

00:32:00.840 --> 00:32:05.600
быть переведена сразу, после чего ежемесячной оплаты

00:32:05.600 --> 00:32:13.080
уже не будет за выбранные нами Reserved Instances.

00:32:13.080 --> 00:32:17.360
Вам необходимо объединить использование определенного

00:32:17.360 --> 00:32:23.240
ресурса для того, чтобы добраться до скидок по объемам.

00:32:23.240 --> 00:32:27.560
Для того, чтобы получить эти скидки и объединить

00:32:27.560 --> 00:32:31.920
ваше использование необходимо использовать consolidated billing.

00:32:31.920 --> 00:32:38.200
Его мы можем включить в сервисы AWS Organizations.

00:32:38.200 --> 00:32:42.160
Следующий сценарий представим, что вы подготовили собственный

00:32:42.160 --> 00:32:48.720
кастомный AMI и хотите ее продавать внутри AWS для других клиентов

00:32:48.720 --> 00:32:49.720
AWS.

00:32:49.720 --> 00:32:55.400
Для этого вы можете воспользоваться сервисом AWS Marketplace.

00:32:55.400 --> 00:33:00.080
Это место, где вы можете продавать различные кастомные

00:33:00.080 --> 00:33:03.160
ресурсы для других клиентов, в том числе ваши кастомные

00:33:03.160 --> 00:33:06.280
AMI.

00:33:06.280 --> 00:33:10.200
На этом мы подошли к концу нашей демо сессии.

00:33:10.200 --> 00:33:13.480
Я очень надеюсь, что вы узнали что-то новое сегодня.

00:33:13.480 --> 00:33:16.880
Еще раз напоминаю, что все то, что мы разобрали, все

00:33:16.880 --> 00:33:20.680
сценарии не являются стопроцентным ответом на вопросы из реального

00:33:20.680 --> 00:33:26.520
экзамена AWS, а лишь удобным форматом для повторения

00:33:26.520 --> 00:33:29.680
всего того материала, который вы прошли, для перепроверки

00:33:29.680 --> 00:33:30.680
себя.

00:33:30.680 --> 00:33:34.360
И помните, что каждый вопрос, который придет на экзамене

00:33:34.360 --> 00:33:37.800
AWS, должен быть вами индивидуально рассмотрен.

00:33:37.800 --> 00:33:43.280
И не всегда бывает, что тот ответ, который указан

00:33:43.280 --> 00:33:46.620
здесь, он является правильным ответом, потому как формулировка

00:33:46.620 --> 00:33:48.560
вопросов, она может меняться.

00:33:48.560 --> 00:33:51.640
Мы с вами помним, что достаточно большое количество новых

00:33:51.640 --> 00:33:56.600
вопросов добавляется в каждый экзамен AWS, и они не идут

00:33:56.600 --> 00:33:57.600
в зачет.

00:33:57.600 --> 00:34:01.640
Таким образом, у AWS есть возможность очень часто

00:34:01.640 --> 00:34:06.860
в больших объемах добавлять новые вопросы, и могут

00:34:06.860 --> 00:34:10.520
появиться вопросы с небольшим подвохом.

00:34:10.520 --> 00:34:18.000
А в целом, идея этих сценариев была в том, чтобы закрепить

00:34:18.000 --> 00:34:21.660
основные моменты, сделать акценты на популярных

00:34:21.660 --> 00:34:26.280
сценариях для того, чтобы не только помочь вам при

00:34:26.280 --> 00:34:35.240
сдаче экзамена AWS, но и дать вам те знания, освежить

00:34:35.240 --> 00:34:39.560
те моменты, которые пригодятся вам во время работы облачным

00:34:39.560 --> 00:34:40.840
инженером.

00:34:40.840 --> 00:34:42.040
Спасибо за внимание.

00:34:42.040 --> 00:35:09.120
Увидимся с вами на следующих наших активностях.