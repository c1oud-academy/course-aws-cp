Добрый день, уважаемые студенты! Я рад видеть вас всех на очередной сессии вопросов и ответов. Мы получили множество ваших вопросов и подготовили ответы. Итак, начнем. Вопрос. Предоставляют ли другие стандартные провайдеры услуги, связанные с работой с контейнерами, или это особенность только AWS? Отвечаю. Сервисы, связанные с работой с контейнерами, доступны у большинства облачных провайдеров. Однако степень их развития может варьироваться. Где-то, например, это уже хорошо отлаженный сервис, давно внедренный и активно использующийся для работы с контейнерами. У других провайдеров данный сервис появился относительно недавно, он еще не до конца отработан, и, соответственно, пользователи неохотно его применяют. Поэтому все это зависит от конкретных условий, и нужно внимательно анализировать каждый случай. Хотелось бы дополнительно отметить два момента. Во-первых, большинство сервисов первоначально появляются у AWS, а затем быстро копируются другими облачными провайдерами. Во-вторых, несмотря на лидерство AWS, каждый облачный провайдер выделяется в определенных направлениях. В своих ключевых областях они могут внедрять новые сервисы раньше, а также предлагать более продвинутые решения. Можете самостоятельно изучить, в каких направлениях сильны те или иные провайдеры, через интернет. Это не является темой нашего курса, однако стоит отметить, что данная ситуация вполне реальна. Вопрос. Какие есть преимущества при работе с Docker-контейнерами? Отвечаю. В первую очередь, если у вас возник такой вопрос, рекомендую пересмотреть лекцию: мы обсуждали эту тему достаточно подробно. На данном этапе мне бы хотелось простыми словами объяснить, почему иногда стоит обратить внимание на Docker-контейнеры и какие преимущества они могут принести компании. Главным конкурентом Docker-контейнеров являются традиционные виртуальные машины. Как мы знаем, виртуальные машины могут быть как простыми и слабыми, так и достаточно мощными. Однако иногда нам требуются очень небольшие мощности для определенных нагрузок или задач, или мы сталкиваемся с приложениями, которые нуждаются в очень специфичных ресурсах. Рассмотрим пример: у нас есть кнопка на сайте для подписки на рассылку. Эта кнопка редко используется, поэтому нецелесообразно выделять для нее целый сервер. Более того, даже маленький сервер потребляет больше средств, чем мы хотели бы вложить в эту функцию. В большинстве случаев он просто будет простаивать. Вот здесь Docker-контейнеры приходят на помощь: на одной машине мы можем разместить тысячи маленьких контейнеров, каждый из которых независим и обрабатывает определенные запросы. Это могут быть маленькие части приложения. Таким образом, мы можем значительно сократить и оптимизировать свои расходы, адаптировав необходимые мощности под реальные нагрузки. Вот в чем заключается преимущество Docker-контейнеров. Следующий вопрос связан с предыдущим, но обратная ситуация. Какие есть недостатки у Docker-контейнеров? Я не имел возможности тесно поработать с Docker-контейнерами, но основываясь на моих наблюдениях и отзывах, хочу отметить, что найти хорошего специалиста по Docker-контейнерам бывает очень непросто. Более того, такие специалисты обычно стоят дорого. Иначе говоря, альтернативой является подготовка собственных специалистов. Однако не все из них готовы учиться новому. Если такие люди все-таки находятся, их ценность на рынке труда возрастает, и в определенный момент они могут найти более высокооплачиваемую работу или попросить увеличения зарплаты в связи с повышением своей квалификации. Это вопросы, связанные с бизнес-процессами компании, и руководству следует принимать во внимание эти моменты. Иногда стоимость содержания высококвалифицированного специалиста может превысить экономию, достигаемую при переходе с виртуальных машин на Docker-контейнеры. Даже если размеры виртуальных машин не идеально подходят под ваши нагрузки, это может быть дешевле, чем зарплата одного специалиста. Все зависит от масштаба вашего бизнеса. Если у вас большая инфраструктура с значительными нагрузками, экономия от оптимизации мощностей может перекрыть зарплату специалиста. Поэтому все очень зависит от конкретной ситуации, и именно от нее следует исходить. Вопрос. Чем отличаются Docker-контейнеры от виртуальных машин? Отвечаю. Мы подробно обсуждали это на лекции, и если остались вопросы, рекомендую к ней обратиться. Здесь же хотел бы простыми словами пояснить следующее: Docker-контейнеры обычно гораздо меньше обычных виртуальных машин, что позволяет разместить на одном сервере тысячи контейнеров. Таким образом, с помощью Docker-контейнеров можно максимально точно подогнать мощности сервера под существующие нагрузки. Кроме того, благодаря своей специфике, контейнеры запускаются гораздо быстрее, что ускоряет работу вашей инфраструктуры и позволяет экономить ресурсы. Виртуальные машины, в силу своей универсальности и долгой истории, присутствуют на рынке с самого начала эпохи облачных технологий. Множество решений было разработано для оптимизации работы с виртуальными машинами, и специалистов, умеющих с ними работать, гораздо больше. В случае с Docker-контейнерами могут возникнуть сложности при поиске квалифицированного специалиста. Кроме того, если вы его найдете, такой специалист может оказаться достаточно дорогим из-за узкой специализации. Вопрос. Могут ли Docker-контейнеры заменить виртуальные машины? Отвечаю. Да, контейнеры могут заменить виртуальные машины, поскольку они представляют собой альтернативную технологию, набирающую популярность. Однако здесь стоит сделать небольшую оговорку: контейнеры все равно запускаются на виртуальной машине. Но отличие заключается в уровне работы. Если раньше мы работали на уровне виртуальной машины, то теперь виртуальная машина становится своего рода многоэтажным домом, где каждая 'квартира' - это наш контейнер. Таким образом, мы работаем уже на уровне контейнеров. В будущем, скорее всего, использование контейнеров станет еще более массовым, количество специалистов увеличится, а значит, компания получит доступ к профессионалам, знакомым с Docker и Kubernetes. Кроме того, ожидается появление новых сервисов, которые дополнительно упростят работу с контейнерами, что приведет к дальнейшему распространению IT-инфраструктуры, которая изначально или со временем перейдет на контейнеры и откажется от использования чистых виртуальных машин. Еще одним важным моментом является существование другой технологии - Serverless, которая была упомянута на наших лекциях. Она представляет собой альтернативное и выгодное решение, но применимость зависит от конкретных бизнес-задач и контекста. Вопрос. Что означает open source программное обеспечение? Отвечаю. Это термин, который применяется в общей сфере информационных технологий и не ограничивается только облачными технологиями. Его идея заключается в том, что существует множество энтузиастов, разрабатывающих различные решения и готовых делиться ими с мировым сообществом безвозмездно. Такой подход позволяет объединять энтузиастов со всего мира, которые стремятся решить общую проблему, и они сотрудничают в группах для разработки программного обеспечения, решающего конкретные задачи. Отдельная тема, связанная с open source, - это лицензии, включая open source PLO, и связанные с ними нюансы. Они определяют условия использования, ограничения и особенности каждой лицензии. Однако эта тема не входит в рамки нашего курса, поэтому вам рекомендуется изучить ее самостоятельно. Когда мы говорим о применении open source в бизнесе, это общий вопрос. Нельзя однозначно на него ответить, так как все зависит от конкретного бизнеса и места использования open source решения в вашей инфраструктуре. Кроме того, необходимо оценить само open source решение: популярность, надежность, отсутствие ошибок и безопасность. Например, для компаний в финансовой сфере этот вопрос особенно актуален, поскольку могут существовать уязвимости, которые могут негативно сказаться на бизнесе в будущем, если хакеры воспользуются ими для атаки и нарушения работы компании. Если сфера вашего бизнеса менее строгая, то стоит рассмотреть использование open source решений, поскольку на данный момент существует множество продвинутых программ, которые успешно применяются в крупных компаниях и корпоративной среде. Вопрос. Какие основные преимущества использования Kubernetes? Отвечаю. Kubernetes является надстройкой для оркестрации docker-контейнеров. Использование docker-контейнеров оправдано, особенно при большом количестве, начиная от 100 и до 1000 и более контейнеров. В таких случаях Kubernetes предоставляет продвинутые методы для управления этим "зоопарком" контейнеров, которые могут сильно различаться между собой. При небольшом количестве docker-контейнеров вы можете рассмотреть использование сервиса Amazon ECS (Elastic Container Service), который оркестрирует docker-контейнеры, но не использует Kubernetes. Также существуют и другие решения, которые работают напрямую с docker-контейнерами. Выбор зависит от ваших конкретных задач и бизнеса. Компании различаются по своему характеру. Некоторые компании, такие как компании-производители продуктов, могут не всегда находить оправдание в использовании Kubernetes и docker-контейнеров. Иногда компании, особенно те, которые разрабатывают множество приложений или имеют архитектуру, состоящую из независимых мини-приложений, могут рассмотреть применение docker-контейнеров. Однако перед переходом необходимо провести предварительный расчет и убедиться, что переход действительно принесет выгоду, так как сам процесс перехода является затратным. Требуются специалисты, обучение, перестройка, отладка и весь процесс перехода от текущего состояния к новому с использованием docker-контейнеров. Поэтому все это следует тщательно просчитывать. Если преимущества действительно существенны, то компания может принять решение о переходе к использованию docker-контейнеров, а возможно и Kubernetes вместе с ними. Вопрос. Приведите примеры компании, которые используют определенные AWS сервисы. Отвечаю. Давайте рассмотрим самые интересные примеры. Мы познакомились с сервисами вычисления, среди которых есть те, которые работают с контейнерами. Начнем с ECR. Это сервис, и если вы откроете страницу этого сервиса, во вкладке "Customers" вы увидите примеры компаний, активно использующих данный сервис. Там же есть ссылки на презентации и видео с конференции Reinvent. Reinvent - это большая ежегодная конференция, организуемая AWS, на которой выступают партнеры и крупные пользователи сервисов AWS. Если рассматривать сервис Amazon Elastic Container Registry (Amazon ECR), то одним из популярных пользователей является компания Pinterest, широко известное и часто используемое в нашей жизни приложение. Еще одним примером является сервис Amazon Elastic Container Service (Amazon ECS), который использует компания Volkswagen, известный автомобильный производитель. Стоит отметить компанию Autodesk, разрабатывающую программное обеспечение для 3D-моделирования. Если говорить о сервисе Amazon Elastic Kubernetes Service (Amazon EKS), то популярным примером использования является Snapchat, приложение, которое мы используем ежедневно. Кроме того, доступны ссылки на презентации Snapchat из 2018-2019 годов, где они делятся опытом использования и преимуществами данного сервиса. Другим примером является HSBC, крупный инвестиционный банк, который активно использует сервис Amazon EKS. Вы можете найти и другие примеры, просто открыв основную страницу сервиса и перейдя во вкладку "Customers", чтобы узнать, кто еще использует данный сервис. Также доступны ссылки на презентации и видео, где компании рассказывают о своем опыте использования сервисов и полученных выгодах. Некоторые из них делятся уникальным опытом, позволяющим сэкономить значительные суммы денег или оптимизировать внутренние процессы. В презентациях представлены цифры и графики, что делает их особенно интересными для изучения. Вопрос. Чем отличаются pull и push архитектуры на примере сервисов Amazon SNS и Amazon SQS? Отвечаю, достаточно хороший вопрос. Если рассматривать принципы pull и push в архитектуре, то простыми словами, в случае архитектуры pull источник запроса инициирует отправку запроса и триггерит получателя. Получатель затем обрабатывает это сообщение. С другой стороны, в архитектуре push мы накапливаем набор сообщений на стороне источника для последующей обработки. При готовности сторона, которая должна обработать эти сообщения, обращается к очереди (pull) и последовательно обрабатывает эти сообщения. Каждый подход имеет свои плюсы и минусы. Использование подхода pull с сервисами Amazon SNS и Amazon SQS позволяет создавать слабосвязные архитектуры. Слабосвязность в архитектуре является более гибкой и лучшей альтернативой чем сильно связанные архитектуры. Мы обсудим это более подробно на последних лекциях в последние недели. В слабосвязных архитектурах намного проще заменить, модернизировать или удалить некоторые компоненты, если они становятся ненужными. В случае, если все компоненты сильно связаны, процесс улучшения, обновления или удаления становится сложной задачей. В этом контексте сервисы Amazon SNS и Amazon SQS оказывают значительную помощь. Вопрос. Что такое lambda-функция? Отвечаю. Lambda-функция является IT-ресурсом в рамках сервиса AWS Lambda. AWS Lambda предоставляет бессерверные вычислительные мощности. Для создания lambda-функции необходимо загрузить код, который должен быть выполнен внутри функции. При необходимости можно указать источники данных, откуда lambda-функция будет получать информацию для работы. Например, источником может быть API Gateway. При использовании API Gateway вы получаете отдельный URL. При обращении по этому URL, вы можете передавать дополнительные параметры, которые затем проходят через сервис API Gateway и передаются в lambda-функцию. API Gateway вызывает lambda-функцию, и функция обрабатывает свой код, используя переданные входные данные. Lambda-функция может быть настроена таким образом, что она не принимает никаких входных данных и выполняет одну и ту же логику. Однако, когда входные данные поступают, можно программировать динамическое поведение lambda-функции внутри кода, в зависимости от этих данных. Еще одним примером использования lambda-функции является настройка AWS EventBridge для вызова функции по определенному событию или расписанию. Это часто используется для автоматизации внутри IT-инфраструктуры. Например, мы можем запланировать включение и отключение инстансов Amazon EC2 на ежедневной основе: включение в 7 утра и отключение в 2 часа ночи. Таким образом, мы можем сэкономить ресурсы, отключая инстансы Amazon EC2 в периоды, когда наши сервисы не используются и никто не заходит. В целом, функции и сервисы "serverless" представляют обширную тему. Это новое направление в разработке. Некоторые IT-инфраструктуры полностью основаны на бессерверных технологиях, что позволяет существенно экономить ресурсы, особенно для сервисов и бизнеса с переменной нагрузкой. Хочу отметить, что наше решение от Cloud Academy также построено с использованием бессерверных технологий, таких как API Gateway, AWS Lambda, DynamoDB и Amazon S3. Вопрос. Почему lambda-функция максимально может работать лишь 15 минут? Это много или мало по сравнению с другими сервисами? Отвечаю. Да, это верно. Максимальное время работы lambda-функции составляет 15 минут, и это не soft limit, это hard limit, поэтому мы изменить его не можем. 15 минут равны 900 секундам. Из опыта как собственного, так и коллег из других компаний, могу сказать, что в 99% случаев 15 минут более чем достаточно. Очень часто используется комбинация AWS Lambda и API Gateway. Однако, стоит учесть, что API Gateway имеет свой собственный hard limit - 29 секунд. Если AWS Lambda не отвечает в течение 29 секунд, то запрос считается превышающим время ожидания (timeout), и соответствующая ошибка возвращается на frontend, на UI или на веб-сайт, который видят ваши пользователи. В данном случае видно, что 15 минут гораздо больше, чем 29 секунд. Исходя из того, что есть определенные сайты, то есть frontend, который используется через API Gateway, и на backend построена lambda, которая отрабатывает, 29 секунд более чем достаточно. Если еще глубже опускаться, то мы все знаем, что для того, чтобы пользователь не разочаровался и не ушел, веб-сайты ускоряют работу и выполнение некоторых действий внутри сайта. Если в течение одной-двух секунд не получается ответ, то это неприятно и некомфортно находиться на этом веб-ресурсе. Компании, работая над разработкой веб-сайтов, стремятся уложить все запросы в одну-две секунды. Таким образом, даже не 29 секунд, а 1-2 минуты более чем достаточно для большинства кейсов, при использовании AWS Lambda. Да, есть кейсы, когда мы можем запускать AWS Lambda асинхронно, то есть приходит вызов через API Gateway тот же, и вызывает нашу lambda-у. И AWS Lambda выполняет какую-то долгосрочную задачу. И UI, то есть API Gateway получает, что да, ваш запрос принят на обработку и уже не сможет вернуть какой-то результат, потому что самообработка занимает больше 29 секунд. Поэтому вызывайте эту lambda-у асинхронно. Дальше уже эта Lambda может до 15 минут работать, чтобы завершить эту задачу. Рассмотрим следующий момент. Если lambda-функция не успевает завершить работу в течение 15 минут (что является редким случаем, но возможным), то часто используется связка AWS Lambda и AWS Step Functions. AWS Step Functions представляет собой функцию для оркестрации работы lambda-функций. Она не только подключает lambda-функции, но также может взаимодействовать с другими сервисами, хотя связка с AWS Lambda является распространенным вариантом. Если ваша задача может быть прервана и продолжена, то lambda-функция работает в пределах 15 минут или немного меньше. Затем она сохраняет свое состояние и передает его в AWS Step Functions. AWS Step Functions получает выходные данные первой lambda-функции и передает их входными данными следующей lambda-функции. Этот процесс продолжается, пока каждая последующая lambda-функция не завершит работу. Внутри AWS Step Functions можно создать цикл, в котором последовательно вызываются следующие lambda-функции до завершения всей работы. AWS Step Functions также является бессерверным решением, полностью управляемым сервисом от AWS. Он быстро настраивается, и большая часть задач по поддержке инфраструктуры решается с его помощью. Сравнивать AWS Lambda с другими сервисами довольно сложно, так как они имеют свои уникальные особенности. Однако, в ответе на ваш первый вопрос я постарался объяснить, что 15 минут обычно более чем достаточно. В случае, когда это не хватает, есть решение, которое вы можете использовать для решения ваших внутренних бизнес-задач. Вопрос. Что означает Serverless? Отвечаю. Serverless – это новая технология, которая позволяет для пользователей того или иного serverless-сервиса не отвлекаться на обслуживание IT-ресурсов, в том числе виртуальных серверов, ваших вычислительных мощностей, а больше сконцентрироваться на бизнес-задачи. Приведу пример. Один из самых ярких примеров – это AWS Lambda. Это тот сервис, который позволяет вам загрузить код, и все то, что относится к запуску, обслуживанию этого запуска выполняется на стороне AWS. То есть оно полностью исключает от вас задачи обслуживания. Другим примером serverless-решения является сервис API Gateway, который также является популярным. Он работает в сотрудничестве с AWS Lambda. С использованием этого сервиса вам не нужно разрабатывать и поддерживать серверы, которые обрабатывают запросы, проходящие через API. Вместо этого вы можете создать необходимые настройки в AWS Management Console, используя SDK, CLI или даже путем написания конфигурации в CloudFormation. Затем вы передаете эти настройки сервису API Gateway, который автоматически настраивает и обслуживает ваш API. Фактически, вы платите только за количество обслуженных запросов, и все остальное обслуживание запросов обрабатывается AWS. На стороне AWS также есть большое количество serverless-сервисов, которые могут быть использованы в связке. Это DynamoDB, это Amazon S3, это Step Functions и так далее. Таким образом вы видите, что есть достаточно большой набор serverless-сервисов, и есть такая тенденция в мире, что IT-инфраструктуры полностью поднимаются на serverless-решениях. Таким образом, в этом случае нет необходимости содержать большой штат, и при этом это решение позволяет максимально экономить деньги в случае, если у вас не постоянные нагрузки. Когда речь идет о постоянных нагрузках, не все serverless-решения являются оптимальными. В таких случаях компании начинают рассматривать возможность перехода к контейнерам или использованию традиционных виртуальных машин. Однако, экономия в начальном этапе является значительным преимуществом. Особенно в случае, когда компания только начинает свою работу или является стартапом. Возможность сэкономить и не платить за неиспользуемые ресурсы является ценным преимуществом, позволяющим избежать излишних расходов в самом начале и использовать доступные средства для других нужд. Также это увеличивает вероятность того, что стартап достигнет нормального состояния и справится с постоянными нагрузками. После этого можно рассмотреть возможность перехода на другие архитектуры, в зависимости от внутренних процессов и задач компании. На этом мы разобрали все вопросы, которые от вас получили, касающиеся лекции этой недели. Я думаю, вы получили свои ответы, лучше поняли некоторые аспекты работы с облаками AWS. Если есть еще вопросы, пожалуйста, пишите, мы эти вопросы будем собирать и публиковать в виде сессии вопросов и ответов. На этом мы заканчиваем и увидимся с вами на следующих наших активностях.