 Добрый день, уважаемые студенты! Я рад вас всех видеть на очередной сессии вопросов и ответов. Мы получили от вас достаточное количество вопросов и подготовили для вас ответы. Итак, давайте начнем. Вопрос. Предоставляете ли другие обычные провайдеры, сервисы, работающие с контейнерами или это только у AWS? Отвечаю. Сервисы, которые работают с контейнерами, доступны у большинства облачных провайдеров. Развитие оно в той или иной мере может отличаться. Где-то, например, достаточно отработанный сервис достаточно давно вышел и в целом есть определенные нагрузки именно с контейнерами. У некоторых же провайдеров этот сервис появился относительно недавно, сырой, и соответственно неохотно его используют пользователи конкретного обычного провайдера. Поэтому это все зависит, надо смотреть. Два момента буквально, которые хотелось бы дополнительно отметить. Это то, что большинство сервисов, они появляются первыми у AWS и далее они достаточно оперативно копируются оставшимися облачными провайдерами. Это первое. Второе, это то, что несмотря на то, что AWS является лидером, тем не менее каждый облачный провайдер силен в чем-то одном, либо в нескольких других направлениях. И соответственно развитие своем направлении, где он является лидером, то соответствующие сервисы могут появляться раньше, они могут быть более продвинутыми и так далее. То, в каких направлениях силен тот или иной обычный провайдер вы можете самостоятельно изучить в интернете. Это не является темой в рамках нашего курса, но сам факт того, что вот такая ситуация сложилась, она есть, это правда. Вопрос. Какие есть преимущества при работе с Docker-контейнерами? Отвечаю. В первую очередь, если у вас возникает подобный вопрос, я вам рекомендую пересмотреть лекцию, там достаточно подробно мы это проговорили. Здесь я бы хотел простыми словами ответить, почему иногда стоит посмотреть в сторону Docker-контейнеров и компания может получить определенные выгоды. Самым основным конкурентом, альтернативой Docker-контейнерам являются традиционные виртуальные машины. Мы с вами знаем, что виртуальные машины могут быть достаточно простыми, слабыми, либо достаточно мощными. Но бывают у нас некоторые нагрузки, некоторые задачи, либо приложения, которые требуют очень маленьких мощностей, либо могут быть ввиду стабильные нагрузки точно подогнанные под определенные мощности. Например, мы можем сказать, что у нас есть внутри сайта одна кнопка, которая позволяет подписаться на рассылки. Так как эта кнопка часто не нажимается, то не хотелось бы для нее выделять целый сервер. И более того, целый сервер, даже если он маленький, он будет больше денег потреблять, нежели она будет использоваться. В большинстве случаев она будет просто простаивать. И в этой связи мы можем благодаря Docker-контейнерам в одну машину поместить десятки тысяч контейнеров, которые очень маленькие, но каждый из них независим друг от друга и обрабатывает какие-то запросы. Это какая-то там маленькая часть приложения. И в этой связи мы можем сильно сэкономить, сжать и оптимизировать наши расходы и более, скажем так, охватить либо подогнать наши необходимые мощности под те нагрузки, которые у нас есть. Это и есть преимущество Docker-контейнеров. Следующий вопрос связан с предыдущим, но обратная ситуация. Какие есть недостатки у Docker-контейнеров? У меня не было возможности достаточно тесно поработать с Docker-контейнерами, но из того, что явно напрашивается, из того, что видно, что мы слышим обычно, очень непросто найти специалиста, хорошего специалиста по Docker-контейнерам. Более того, если такой специалист находится, он достаточно дорогой, поэтому другая альтернатива – это взращивать своих специалистов. И не всегда находятся специалисты, которые готовы что-то новое изучить для себя. Если такие находятся, то ценности этого сотрудника тоже растут на рынке, и в какой-то момент он тоже может найти более высокооплачиваемую работу либо попросить ввиду повышения своей квалификации большую зарплату. Это вопросы касательно бизнесовой части и компании, бизнесу нужно эти моменты учитывать. Бывает такое, что чем оплачивать содержание этого дорогостоящего специалиста, дешевле будет оставаться на виртуальных машинах. И, соответственно, хоть и где-то не совсем оптимально подгонять размеры ваших виртуальных машин под ваши нагрузки, тем не менее это будет выходить дешевле, чем целая зарплата одного специалиста. Это все зависит от ваших объемов. Если у вас достаточно большая инфраструктура, у вас большие нагрузки, то в этом случае экономия от того, что вы лучше подгоните ваши мощности под ваши нагрузки, она может быть больше, чем потенциальная зарплата одного специалиста. Поэтому все сильно зависит от конкретной ситуации, и надо из этого исходить. Вопрос, чем отличаются Docker-контейнеры от виртуальных машин? Отвечаю. Мы рассмотрели это подробно на нашей лекции, и если совсем непонятно, то рекомендую обратиться к лекции. Здесь же я хотел бы простыми словами ответить. Это то, что Docker-контейнеры, они могут быть намного меньше, и мы в одну машину тысячи контейнеров можем расположить. Таким образом, можно с Docker-контейнерами максимально подогнать размеры нашей мощности к нагрузкам, которые есть. Более того, контейнеры, в виду своей специфики, как это все организовано, оно запускается намного быстрее. Таким образом, Docker, он ускоряет в каком-то смысле вашу инфраструктуру и позволяет экономить из-за точного подгона ваших серверных мощностей. Виртуальные же машины, они достаточно универсальные, они давно появились, с самого начала как бы живут, есть. И очень много решений сделано для виртуальных машин с точки зрения оптимизации. И больше всего специалистов вы найдете, которые, скорее всего, смогут работать с обычной виртуальной машиной традиционной. Тогда как с Docker-контейнерами могут быть некоторые сложности с поиском специалиста. Либо, когда вы его найдете, то этот специалист может быть достаточно дорогостоящим в виду своей узкой направленности. Вопрос, могут ли Docker-контейнеры заменить виртуальные машины? Отвечаю, там могут заменить, так как контейнеры являются альтернативной технологией, которая набирает популярность. Здесь надо сделать небольшую ремарку, потому как контейнеры все также и будут запускаться на этой виртуальной машине. Но тут уже отличается то, как мы работаем, на каком уровне. До этого мы работали на уровне виртуальной машины, а теперь у нас виртуальная машина превращается в некие многоэтажные здания, и каждая квартира внутри – это наш контейнер. И мы работаем уже на уровне контейнеров. В будущем, скорее всего, будет так, что использование контейнеров станет еще более массовым, специалистов станет больше, соответственно, специалисты со знаниями Docker, Кубернеты будут доступны для компании. Более того, скорее всего, появятся новые сервисы, которые еще больше упрощают работу с контейнерами, и, соответственно, больше будет у нас IT-инфраструктуру в мире, которые изначально, а может со временем, перешли на контейнеры и не используют в чистом виде виртуальные машины. Другой момент – это то, что есть другая технология, технология Serverless, про которую мы на наших лекциях поговорили, и является также альтернативным решением, которое является достаточно выгодным решением, подходом, но все зависит от бизнес-задачи, от бизнес-контекста. Вопрос – что означает open source программное обеспечение? Отвечаю – это термин, который не привязан к облачным технологиям, общий IT-термин. Идея ее в том, что в мире есть очень много энтузиастов, которые разрабатывают некоторые решения, они готовы делиться с этим решением со всем миром на безвозмездной основе, и таким образом оно позволяет находить со всего мира таких же энтузиастов, которые хотят решить одну проблему, и объединяются таким образом, объединяются в группы и разрабатывают уже достаточно серьезное программное обеспечение, а это программное обеспечение решает какую-то определенную задачу. Отдельная тема лицензии open source, open source PLO, и есть некоторые нюансы, в каком случае, какую лицензию нужно использовать, какие есть ограничения, какие есть отличительные особенности. Это не является темой нашего курса, поэтому вы ее можете самостоятельно изучить. Когда мы говорим про open source использование в бизнесе, это тоже достаточно общий вопрос, однозначно на него ответить не получится, ввиду того, что все зависит от конкретного вашего бизнеса, от того, где, в каком месте вашей инфраструктуры будет использована это open source решение. Более того, нужно смотреть на само open source решение, является ли оно достаточно популярным, отлаженным, без большого количества ошибок, без дыр безопасности. Например, если вы компания, которая работает в сфере финансов, то этот вопрос достаточно остро будет стоять, то есть, использовать или не использовать open source решение, потому как там могут быть дыры безопасности, что очень негативно может сказаться в будущем на вашем в целом бизнесе, если хакеры будут использовать вот эту дыру безопасности для своих целях, для того, чтобы поломать работу вашей компании. Если это другая какая-то более лояльная сфера к open source решениям, то почему бы не рассмотреть это решение, так как open source программ много, очень много сильных и продвинутых программ, которые и на текущий момент используются в больших компаниях, в корпоративной среде. Вопрос, какие основные преимущества использования Kubernetes? Отвечаю, Kubernetes является некоторой надстройкой для того, чтобы аркестрировать докер контейнеры. Зачастую использование докер контейнеров оправдано, если у вас достаточно большое количество докер контейнеров, от 100, от 1000 и выше. В этом случае Kubernetes предоставляет достаточно продвинутые методы для механики, для того, чтобы легче справляться с этим, в кавычках, зоопарком контейнеров, которые сильно друг от друга могут отличаться. Если мы говорим про небольшое количество докер контейнеров, то возможно вам достаточно будет использовать сервисы ECS, например elastic container service, который как раз таки аркестрирует докер контейнеры, но не является Kubernetes, либо же другое какое-то решение, которое работает не с Kubernetes, а напрямую с докер контейнерами. Все зависит от вашей конкретной задачи, от вашего бизнеса. Компании бывают разные. Некоторые компании, например, продуктовые, они разрабатывают один или несколько продуктов, и в этом случае не всегда оправдано использование Kubernetes и докер контейнеров. Иногда бывает, что есть компания, которая разрабатывает очень много приложений, либо это по своей специфике приложения, которые архитектурно разработаны так, что это маленькие мини-приложения, независимо друг от друга работающие. В этом случае вполне возможно попробовать применить докер контейнеры. Предварительно, естественно, нужно будет сделать некий расчет и убедиться, что действительно будут какие-то преимущества от этого перехода, потому как сам переход – это тоже достаточно затратная часть. Нужны специалисты, нужно обучение, нужно перестроить, отладить и провести целый процесс по переходу от предыдущего состояния в новое состояние с докер контейнерами. Поэтому это все необходимо просчитывать. И в случае, если это действительно достаточно существенная выгода, то компания решается на это и переходит к использованию докер контейнеров, а возможно и кубернетес вместе. Вопрос – приведите примеры компании, которые используют определенные AWS сервисы. Отвечаю. Давайте рассмотрим самые интересные примеры. Мы с вами познакомились с сервисами вычисления, и среди них есть те, которые работают с контейнерами. Начнем мы с ECR. Это тот сервис. Если вы откроете страницу этого сервиса, во вкладке Customers вы можете увидеть примеры компании, которые достаточно активно используют тот или иной сервис. Также там же вы можете увидеть ссылки на презентации, видео презентации в Reinvent. То есть Reinvent – это большая конференция, организуемая AWS ежегодно, в которой в том числе и выступают партнеры, и достаточно крупные пользователи сервисов AWS. Если мы говорим про сервис Elastic Container Registry, то одним из самых популярных пользователей является компания Pinterest. То есть это то приложение, которое мы достаточно часто используем в нашей жизни. Другой пример – это сервис Elastic Container Service, то есть ECS. Здесь как пример можно привести к компании Volkswagen, автомобильная компания. Также есть Autodesk. Это компания, которая разрабатывает программу для 3D-моделирования. Если же мы говорим про сервис EKS, то есть Elastic Kubernetes Service, то один из самых популярных примеров – это Snapchat. Тоже приложение, которое мы на ежедневной основе используем. Здесь же также можно, в случае Snapchat есть даже две ссылки на презентации от 2018-19 года, в котором они рассказывают, как они используют, какие выгоды они получают от использования этого приложения. Другой пример – это HSBC. Это достаточно крупный инвестиционный банк, и он тоже достаточно активно использует сервис EKS. Другие примеры вы также можете посмотреть, достаточно лишь открыть основную страницу сервиса и во вкладке Customers посмотреть, кто же все-таки использует. Еще раз повторюсь, есть ссылки на презентации, видео презентации, которые рассказывают, каким образом компания использует тот или иной сервис, какие выгоды от этого получает. Где-то бывает они рассказывают уникальный опыт свой, который позволил либо сэкономить достаточно большое количество денег ввиду использования этого сервиса, либо сильно оптимизировать некоторые свои внутренние процессы. Приводят определенные цифры, графики, и это достаточно интересно просматривается. Вопрос – чем отличаются Pool и Push архитектуры на примере сервисов Amazon SNS и Amazon SQS? Отвечаю, достаточно хороший вопрос. Если мы говорим про Pool и Push, то простыми словами, когда мы строим архитектуру по принципу Pool, это значит источник запроса инвестирует отправку вот самого запроса и триггерит получателя. И дальше получатель уже обрабатывает это сообщение. А когда мы говорим про архитектуру, построенную по принципу Push, это когда мы накапливаем на стороне источника набор сообщений для отработки, обработки. И, соответственно, та сторона, которая должна обработать эти сообщения, по готовности обращается в некоторый Pool, в некоторую очередь, и по очереди обрабатывает эти сообщения. Есть плюсы и минусы каждого из подходов. Идея в том, что благодаря Pool, благодаря сервисам Amazon SNS и Amazon SQS у нас есть возможность сделать архитектуру слабосвязной. Слабосвязная архитектура это намного лучше. Архитектуры сильно связные. Мы про это поговорим с вами на последних наших лекциях, в последних неделях. И идея в том, что когда у нас архитектура слабосвязная, то очень просто и намного легче заменить некоторые части архитектуры, возможно, модернизировать, улучшить, либо совсем исключить, если она не нужна. Если же у нас все сильно связано между собой, то вот этот процесс улучшения, обновления, либо удаления некоторых компонентов внутри архитектуры – это целая проблема. Поэтому сервисы Amazon SNS, Amazon SQS нам в этом сильно помогают. Вопрос, что такое Lambda функция? Отвечаю. Lambda функция – это IT ресурс в рамках сервиса AWS Lambda. AWS Lambda – это сервис, который предоставляет бессерверные мощности. И вам достаточно создать этот ресурс, Lambda функцию. В Lambda функцию загрузить код, который должен отрабатывать. При необходимости вы можете указать ваши источники, откуда вы будете получать информацию о том, что Lambda функция должна начать работать. Это может быть API Gateway. Таким образом, у вас появляется, простыми словами, отдельный URL. Как только вы на этот URL обращаетесь, возможно, вы дополнительные какие-то параметры передаете, то эти параметры дальше проходят через сервис API Gateway и попадают на Lambda. API Gateway вызывает Lambda функцию, и Lambda функция, соответственно, отрабатывает свой код, исходя из входных данных. Может быть такое, что она не принимает никаких входных данных. Это тоже нормальный пример. И в этом случае Lambda функция отрабатывает по одной и той же логике. Когда приходят уже входные данные, то Lambda функция внутри кода можно запрограммировать некоторое динамическое поведение в зависимости от входных данных. Другой пример. Мы можем также настроить уже внутри AWS сервиса, AWS EventBridge, который будет либо по некоторому событию, либо по некоторому расписанию вызывать Lambda функцию. Это тоже достаточно частое применение Lambda функции, когда мы хотим что-то автоматизировать внутри нашей IT инфраструктуры и, представим, хотим на ежедневной основе включать EC2 инстанции в начале 7 часов утра, а в 2 часа ночи, например, отключать. И вот разница в 5 часов, когда никто не заходит, не использует наши сервисы, мы можем сэкономить, отключив EC2 инстанции. В целом, серверлесс функции, серверлесс сервисы – это достаточно обширная тема, это новое направление. Есть некоторые IT инфраструктуры, которые полностью построены на бессерверных технологиях, что позволяет сильно экономить, в случае, если у этого сервиса, у этого бизнеса непостоянные нагрузки. Я хотел бы также здесь добавить, что наше решение от Cloud Academy также было построено с использованием сервисов на основе бессерверных технологий, то есть серверлесс – это API, Gateway, Lambda, DynamoDB и так далее. S3 сюда тоже можно отнести. Вопрос. Почему Lambda функция максимально может работать лишь 15 минут? Это много ли бы мало по сравнению с другими сервисами? Отвечаю. Да, действительно, Lambda функция максимально может работать 15 минут. Это не soft limit, это hard limit, поэтому мы изменить его не можем. 15 минут – это 900 секунд. По опыту и по опыту коллег других компаний могу сказать, что в 99% случаев 15 минут более чем достаточно. Более того, очень частая связка – это Lambda плюс API Gateway. А на стороне API Gateway есть другой hard limit – это 29 секунд. API Gateway передает запрос Lambda, и если в течение 29 секунд Lambda не отвечает, то, соответственно, запрос считается timeout, то есть время истекло, и соответствующая ошибка возвращается на frontend, на UI, на веб-сайт, который видят ваши пользователи. И здесь также мы видим, что 15 минут – это намного больше чем 29 секунд. Исходя из того, что есть определенные сайты, то есть frontend, который используют через API Gateway, и на бэкэнде построена Lambda, которая отрабатывает и 29 секунд более чем достаточно. Если еще глубже опускаться, то мы с вами все знаем, что для того, чтобы пользователь не развернулся и не ушел, веб-сайты ускоряют работу, ускоряют выполнение некоторых действий внутри сайта. И если в течение одной-двух секунд не получает ответа, то очень неприятно, некомфортно находиться на этом веб-ресурсе. Поэтому компании, когда работают с разработкой веб-сайтов, они стремятся все свои запросы уложить в одну-две секунды. Таким образом, даже не 29 секунд, а 1-2 минуты более чем достаточно для того, чтобы успешно справляться с большинством кейсов, когда используется Lambda. Да, есть кейсы, когда мы можем запускать Lambda асинхронно, то есть приходит вызов через API Gateway тот же, и вызывает нашу Lambda. И Lambda выполняет какую-то долгосрочную задачу. И UI, то есть API Gateway получает, что да, ваш запрос принят на обработку и уже не сможет вернуть какой-то результат, потому что самообработка занимает больше 29 секунд. Поэтому вызывайте эту Lambda асинхронно. Дальше уже эта Lambda может до 15 минут работать, чтобы завершить эту задачу. Теперь здесь возникает следующий момент. Если Lambda не успевает отрабатывать в течение 15 минут, это достаточно редкий кейс, но такие кейсы бывают. И зачастую используют уже следующую связку Lambda и Step Functions. Step Functions – это еще одна функция для оркестрации работы Lambda функций. Там не только Lambda функции подключаются, можно подключить и другие сервисы, но это достаточно частая связка. И вы можете, в случае, если ваша задача может быть прервана и продолжена, то Lambda функция в течение 15 минут либо чуть меньше отрабатывает, что она успевает, сохраняет свое состояние и передает Step Functions. Step Functions получает выход первой Лямды и на вход подает результат состояния, на котором остановилась первая Лямда, передает для второй Лямды. Она с этого момента продолжает и пытается завершить эту работу. Можно даже внутри Step Functions сделать некоторый цикл, где она будет вызывать каждую следующую Лямду до того момента, как она не обработается. Step Functions также является сервер-лесс-решением, полностью менеджит AWS сервис. Таким образом ее достаточно быстро можно настроить, и вы большинство задач по поддержке инфраструктуры именно Step Functions с ней не сталкиваетесь. Это все на стороне AWS. Если сравнивать с другими сервисами, то это достаточно не совсем подходящий вопрос, потому что очень сложно сравнивать Lambda с другими сервисами, но я попытался вам, когда отвечал на первый вопрос, объяснить, что 15 минут более чем достаточно. В случае, когда не хватает, есть также решение, что вы можете сделать для решения своих внутренних бизнес задач. Вопрос, что означает сервер-лесс? Отвечаю. Сервер-лесс – это новая технология, которая позволяет для пользователей того или иного сервер-лесс-сервиса не отвлекаться на обслуживание IT-ресурсов, в том числе виртуальных серверов, ваших вычислительных мощностей, а больше сконцентрироваться на бизнес-задачи. Приведу пример. Один из самых ярких примеров – это AWS Lambda. Это тот сервис, который позволяет вам загрузить код, и все то, что относится к запуску, обслуживанию этого запуска, оно выполняется на стороне AWS. То есть оно полностью исключает от вас задачи обслуживания. Другой пример сервер-лесс-решения – это API Gateway. Тоже достаточно популярный сервис, работает в связке с Lambda. И в этом случае вам нет необходимости разрабатывать, писать код, заниматься поддержкой серверов, которые обрабатывают эти запросы, проходящие через API. А достаточно либо внутри AWS Management Console накликать необходимые настройки, либо же через SDK, либо CLI, либо возможно через CloudFormation написать то состояние, какой набор API нужен в виде конфигурации, и дальше передать это сервису API Gateway для того, чтобы он поднял, настроил и все работало за вас. Фактически вы оплачиваете только за объем обслуженных запросов, и все остальное обслуживание вот этих запросов, оно на стороне AWS. На стороне AWS также есть большое количество сервер-лесс-сервисов, которые могут быть использованы в связке. Это DynamoDB, это S3, это Step Functions и так далее. Таким образом вы видите, что есть достаточно большой набор сервер-лесс-сервисов, и есть такая тенденция в мире, что IT-инфраструктуры полностью поднимаются на сервер-лесс-решениях. Таким образом в этом случае нет необходимости содержать большой штат, и при этом это решение позволяет максимально экономить деньги в случае, если у вас не постоянные нагрузки. Когда мы говорим про постоянные нагрузки, то не все сервер-лесс-решения становятся оптимальными, и в этом случае вы начинаете рассматривать и переходить либо в контейнеры, либо в использование традиционных виртуальных машин. Но сама экономия в начале – это очень большое преимущество. То есть, где у нас не постоянные нагрузки, это обычно, когда компания только-только начинает работать, либо это какой-то начинающий стартап, и в этом случае возможность сэкономить и не платить за то, что мы не используем – это очень ценная возможность, что позволяет не убить в самом начале со своими лишними расходами этот стартап, а как раз таки все имеющиеся, возможно, небольшие средства направить на другие нужды. Ну и соответственно увеличить вероятность того, что этот стартап дойдет до какого-то нормального состояния, доберется до постоянных нагрузок, а там уже дальше, в зависимости от своих внутренних процессов, задач – уже рассматривать вопрос перехода на другие архитектуры. На этом мы разобрали все вопросы, которые от вас получили, касающиеся лекции этой недели. Я думаю, вы получили свои ответы, чуть больше, чуть лучше поняли некоторые аспекты работы с облаками WS. Если есть еще вопросы, пожалуйста, пишите, мы эти вопросы будем собирать и публиковать в виде сессии вопросов и ответов. На этом мы заканчиваем и увидимся с вами на следующих наших активностях.
