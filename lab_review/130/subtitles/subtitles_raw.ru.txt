 Добрый день, уважаемые студенты! Я рад вас их видеть на очередной сессии разбора лабораторной работы. Тема сегодняшней лабораторной работы это Scale and Load Balance your architecture. Мы подробнее познакомимся с сервисами ELB, Elastic Load Balancer и Autoscaling. Итак, давайте начнем. Ожидается, что вы уже находитесь на странице лабораторной работы и инициировали создание временного AWS аккаунта. Сейчас нам необходимо нажать на кнопку AWS для того, чтобы перейти на AWS Management Console. В консоли первое задание, нам необходимо создать AMI. Для этого нам необходимо в строке поиска ввести EC2 и в выдаче вы видите нужную ссылку. Давайте на нее нажмем и перейдем на сервис EC2. Далее в левом навигационном меню необходимо выбрать пункт Instances. В отобразившемся списке инстанцев необходимо выбрать Web Server 1. Далее нажать на кнопку Actions и в выпадающем меню выбрать пункт Image and Templates. И нажать на кнопку Create Image. Как только вы на нее нажмете, вас перенаправят на новую страницу, в которую необходимо ввести некоторые данные. Первое это Image Name, нужно ввести Web Server AMI. Далее Image Description, давайте введем Lab AMI for Web Server. Прокрутим чуть ниже, все остальные настройки оставляем по умолчанию и нажимаем Create Image. Как только вы на нее нажмете, вас перенаправят на предыдущую страницу и вы увидите сообщение о том, что AMI Stack and ID был успешно создан. Давайте скопируем AMI, он возможно нам понадобится в следующих заданиях. Теперь нам необходимо создать Target группу. Таргет группу мы создаем предварительно и эту таргет группу будем использовать при создании Elastic Load Balancer. Итак, нам необходимо в левом навигационном меню выбрать пункт Target Groups. Как только вы на нее нажмете, отобразится список всех существующих Target Group в нашем временном AWS аккаунте. Нам необходимо нажать на кнопку Create Target Group. Откроется соответствующая страница для ввода некоторых данных. В самом начале как тип необходимо выбрать Instances, то есть мы работаем сервисами сету. Далее прокрутить необходимо быть чуть ниже и как Target Group Name нужно ввести Lab Group. Как в VPC выбираем Lab VPC, все остальные настройки остаются такими же. В самой нижней части страницы необходимо нажать на кнопку Next. Вас направят на второй шаг создания Target группы и здесь необходимо выбрать наши таргеты. Так как наши таргеты будут управляться авто скейлинг группой, то здесь нам не нужно выбирать инстанции. Достаточно прокрутить чуть ниже страницу и нажать на кнопку Create Target Group без привязанных таргетов. Следующий шаг. Нам необходимо создать сам Load Balancer. Для этого в левом навигационном меню необходимо выбрать опцию Load Balancer и в открывшейся странице нажать на кнопку Create Load Balancer. Мы знаем с вами, что у нас есть три вида Load Balancer. В нашем случае интересует первый, это Application Load Balancer. Давайте нажмем на кнопку Create под этой опцией. Как только вы на нее нажмете, вас перенаправят на страницу для ввода входных данных. Давайте как Load Balancer Name укажем Lab BLB. Далее необходимо указать VPC, это Lab VPC. В секции Mappings нам необходимо отметить те availability зоны, в которой ELB будет распределять трафик, а также для каждой availability зоны необходимо выбрать subnet. В выпадающем меню для US East 1A необходимо выбрать Public Subnet 1, для US East 1B необходимо выбрать Public Subnet 2. Если мы прокрутим чуть ниже, в секции Security Groups, в выпадающем меню нам необходимо выбрать Web Security Group. В следующей секции Listeners and Routing необходимо удостовериться, что протокол стоит HTTP, а порт 80. Как default action давайте выберем Forward to Lab Group из выпадающего списка. Теперь нам необходимо прокрутить в самый конец страницы и нажать на кнопку Create Load Balancer. Как только вы нажмете на Create Load Balancer, вас направит на страницу с еще одной кнопкой, и по нажатию которой вы можете перейти на непосредственно ваш Load Balancer. Вы можете перейти по ней и посмотреть все детали создания этого ресурса, а мы с вами переходим к следующему заданию, теперь мы будем создавать авто скейлинг группу. Для того, чтобы создать авто скейлинг группу, первым делом создается Launch Config. Для этого в левом навигационном меню необходимо выбрать опцию Launch Configurations, и в открывшейся странице нажать на кнопку Create Launch Configuration. Вас перенаправит на страницу ввода входных данных, как Name необходимо указать Lab Config, как AMI выбрать веб-сервер AMI, который мы создавали ранее, как Instance Type необходимо выбрать C3-MICRO, если этот вариант недоступен, здесь вы можете выбрать T2-MICRO, либо любой другой. В рамках лабораторной работы разницы никакой нет. Прокручиваем чуть ниже, в секции Additional Configuration и в подсекции Monitoring, нам необходимо поставить галочку для того, чтобы активировать Detailed Monitoring. Это когда в CloudWatch отправляются метрики чаще, чем обычно. В секции Security Groups необходимо выбрать опцию Select an existing security group, то есть мы выбираем среди существующих security group, новую создавать не нужно. Для нас есть уже предварительно созданная security группа, она называется Web Security Group. Необходимо ее выбрать и мы двигаемся к следующей секции. Самая последняя секция это Key Pair, то есть мы здесь указываем ключ, по которому можно подключиться к нашим situinstance через SSH. В рамках лабораторной работы мы по SSH подключаться не будем, но как best practice мы укажем этот ключ. Необходимо Key Pair Options выбрать опцию Chosen existing key pair и далее выбрать существующий ключ в OK. Также необходимо поставить галочку о том, что мы подтверждаем, что мы будем подключаться к situinstance с использованием этого ключа. Это была последняя секция, теперь необходимо нажать в нижней части страницы на кнопку Create Launch Configuration. Как только она создастся, мы можем переходить к созданию автоскейлинг группы. Для этого в списке Launch Configuration необходимо выбрать ранее созданный LabConfig, далее нажать на кнопку Actions и в выпадающем меню выбрать опцию Create Auto Scaling Group. Вас перенаправит на страницу ввода входных данных. Давайте для поля Auto Scaling Group Name введем Lab Auto Scaling Group и нажмем на кнопку Next. На следующей странице необходимо ввести параметры Network, то есть эти. Самым первым делом необходимо указать VPC, в нашем случае это Lab VPC, мы можем его найти в выпадающем списке. Далее нам необходимо указать Availability Zones и Subnets. Здесь необходимо выбрать из выпадающего списка Private Subnet 1 и Private Subnet 2. Почему мы выбираем именно Private Subnets я объяснял в предыдущем видео, когда мы делали обзор лабораторной работы. Как только мы выбираем необходимые Subnets, мы переходим к следующей части, к следующей странице настройки, нажимаем на кнопку Next. На следующей странице есть секция Load Balancing, здесь необходимо выбрать опцию Attach to an existing Load Balancer. В следующей секции необходимо выбрать Choose from your Load Balancer Target Groups и выбрать Load Balancer Lab Group из выпадающего списка. Необходимо прокрутить чуть ниже и в секции Additional Settings для мониторинга также отметить Enable Group Metrics Collection within CloudWatch. Это говорит о том, что мы и все метрики будем агрегировать в сервисе CloudWatch. На этой странице мы вывели все необходимые входные данные, теперь необходимо нажать на кнопку Next. Мы попадаем на страницу конфигурирования размеров группы и Scaling Policy. Первым делом мы заполняем Capacity, есть три опции, это Desired Capacity, Minimum Capacity и Maximum Capacity. Чем отличаются они друг от друга, мы также разбирали в предыдущей активности обзор лабораторной работы. Здесь нам необходимо ввести значение 2, 2 и 6 и мы двигаемся дальше. Следующая секция это Scaling Policies, здесь необходимо выбрать Target Tracking Scaling Policy. Это говорит о том, что авто скейлинг группа будет смотреть на некоторую метрику и в зависимости от этой метрики будет увеличиваться либо уменьшаться в своих размерах. Как Scaling Policy Name давайте введем Lab Scaling Policy и как Metric Type введем Average CPU Utilization. То есть мы смотрим на нагрузку на наши процессоры в EC2 Instance и как Target Value укажем 60. На этом мы ввели все необходимые настройки на этой странице. Давайте прокрутим вниз и нажмем на кнопку Next. На следующей странице предлагается ввести различные уведомления. Здесь мы в рамках лабораторной работы это настраивать не будем, двигаемся дальше. Следующий и последний шаг, где мы вводим некоторые входные данные это шаг с тегами. Давайте добавим Tag Name со значением Lab Instance и оставим галочку в поле Tag New Instances. Это говорит о том, что для всех инстанцев которые создаются под Auto Scaling группой будут передаваться теги такие же которые есть у Auto Scaling группы. Мы закончили на этой странице, давайте нажмем на кнопку Next для того, чтобы перейти на самую последнюю страницу. Здесь нет необходимости вводить какие-либо данные, а отображается все входные данные, которые мы ввели ранее. Если же некоторые данные неточные или вы хотите их изменить, то возле каждой секции есть кнопка Edit для того, чтобы быстро перейти на необходимую страницу. Если же все хорошо, вы можете прокрутить в самом низ страницы и нажать на кнопку Create Auto Scaling Group. Вас перенаправит на страницу со всеми Auto Scaling группами, вы увидите статус Updating Capacity и количество инстанцев на текущий момент 0. Если мы подождем некоторое время и обновим страницу еще раз, то количество инстанцев приравняется к количеству Desired Capacity, то есть два новых инстанца создастся и статус станет Ready. Вы можете это проделать самостоятельно, а сейчас мы двигаемся дальше, мы хотим проверить, что действительно инстанцы создаются. Для этого в левое наигационное меню нам необходимо нажать на пункт Instances и вы увидите список инстанцев в этом AWS аккаунте. Появилось два новых инстанца, оба называются Lab Instance и вы видите статус Initializing, то есть они только начали создаваться. Через некоторое время они также полностью поднимутся, настроятся и пройдут все проверки статуса и примут такое же значение как существующие инстанции. Давайте теперь в левом на вигационном меню в нижней части перейдем к вкладке Target Groups для того, чтобы посмотреть какие таргеты у нас есть в созданной нами Target группе. У нас единственная таргет группа, давайте ее выберем, отобразится в нижней части экрана дополнительные вкладки с более подробной информацией. Нам необходимо перейти на вкладку Target и вы увидите, что сейчас у нас как Registry Targets значатся два инстанца. Это те два инстанца, которые были созданы авто скейлинг группой и вы видите статус Healthy, что говорит о том, что Elastic Load Balancer уже готов направлять трафик, а эти инстанции готовы чтобы трафик принимать. Чтобы это проверить, что действительно связка Elastic Load Balancing, Auto Scaling и EC2 инстанции работает, мы можем перейти в наше приложение. Для этого необходимо в левом навигационном меню выбрать вкладку Lab Load Balancers и когда мы выберем единственный Load Balancer, который мы создали ранее, в нижней части экрана отобразятся дополнительные вкладки. В первой вкладке Description мы можем скопировать DNS Name и ввести это значение в новой вкладке в веб-браузере. Вы увидите, что отобразилась некоторая страница, это говорит о том, что ваш запрос был принят Load Balancer. Ваш запрос направил на веб-сервер, веб-сервер его обработал и вернул некоторый ответ. Этот ответ вам отображен в виде веб-страницы. Более того, вы видите информацию о том, какой инстанц обработал ваш запрос. Это тот инстанц, который находится на второй availability зоне, а именно US East 1B. Отлично, теперь нам необходимо проверить, что Auto Scaling группа работает корректно, что она скейлится, увеличивается и уменьшается в размерах. Для того, чтобы это проверить, первым делом необходимо перейти на сервис CloudWatch. Давайте начнем вводить CloudWatch, либо начнем вводить Watch в строке поиска сервисов и мы увидим нужную нам ссылку. Как только мы переходим к сервису CloudWatch, в левом навигационном меню необходимо выбрать опцию All Alarms. Отобразится список всех алармов, существующих на этом AWS аккаунте. В нашем случае будет два аларма. Первый в названии содержит Alarm High, второй содержит название Alarm Low. Это противоположные алармы. Идея в том, что Alarm High принимает значение in alarm в том случае, если CPU utilization превышает 60% для каждой минуты в течении 3 минут. То есть это 3 data points. Если мы говорим про Alarm Low, в этом случае он принимает значение in alarm. Если CPU utilization меньше 54% в течении 15 минут, то есть он 15 минут мониторит, если в течении 15 минут значение уменьшилось, то он переходит в состояние alarm. Оба аларма триггерят авто скейлинг группу в противоположных направлениях. В случае когда у нас срабатывает Alarm High, то авто скейлинг группа добавляет новый instance. В случае когда срабатывает Alarm Low, то авто скейлинг группа удаляет лишний instance. Если же эти алармы у вас не отображаются, то необходимо проделать следующее действие. Нам необходимо перейти в сервис EC2, далее в левом навигационном меню выбрать опцию Auto Scaling Groups, в списке выбрать Lab Auto Scaling. И в вкладках с информацией об этой авто скейлинг группе необходимо выбрать вкладку Auto Scaling, Automatic Scaling. Здесь отображаться все полиси, Scaling Policy. У нас одна единственная Scaling Policy, необходимо ее выбрать, далее нажать на кнопку Actions и в выпадающем меню нажать на кнопку Edit для того, чтобы ее отредактировать. Здесь для того, чтобы инициировать пересоздание алармов, вам достаточно поменять значение, рекомендуется поставить значение 50 и нажать на кнопку Update. Как только вы это сделаете, вы можете возвращаться обратно в сервис CloudWatch и вы должны увидеть создающуюся аларму. Давайте выберем Alarm High. Мы перейдем на следующую страницу, где посередине будет информация, список всех существующих алармов и в правой части экрана отображается более подробная информация выбранного аларма. В нашем случае это Alarm High, вы видите красную линию, то есть это Threshold 50% и видите текущее значение нагрузки на CPU. Это абсолютно минимальная нагрузка сейчас на наши инстанции. Это очевидно, потому что нагрузка сейчас не идет на наши инстанции. Теперь, что мы сделаем? Мы возвращаемся обратно на наше приложение и в верхней части вы видите, что есть кнопка Load Test. Давайте на нее нажмем. Как только мы на нее нажмем, у нас начнется генерация нагрузки на наши EC2 инстанции. Странница обновляется каждые 5 минут и отображает текущую нагрузку на процессоры на наших EC2 инстанциях. Эту страницу закрывать нельзя, если вы ее закроете, то скрипты перестанут работать и нагрузка упадет. Нужно держать эту вкладку открытой. Сейчас нам необходимо вернуться обратно и вы видите, что через некоторое время в течении 5 минут вы можете наблюдать как меняются графики и вы увидите, что Alarm High перешел в состояние In Alarm. Почему? Потому что нагрузка на наши EC2 инстанции превысила 50 или 60% в зависимости от того, что мы выбрали. А если мы говорим Alarm Low, то он ранее принимал значение In Sufficient Data либо In Alarm, сейчас он принял значение OK, то есть противоположное состояние. Теперь нам необходимо перейти в EC2 для того, чтобы удостовериться создала ли дополнительные инстанции наша автоскейлинг группа. Для этого необходимо в левом навигационном меню перейти на вкладку Instances и вы увидите 3 либо 4 инстанции, 2 из которых будет в состоянии инициации. Через какое-то время все 4 инстанции будут принимать трафик и обрабатывать все запросы, которые пришли от Load Balancer. На этом мы завершили все основные задания. Как дополнительный эксперимент я бы хотел вам посоветовать сделать следующее. Вы можете остановить нагрузку на ваши EC2 инстанции. Как только нагрузка спадет, через какое-то время в течении 15 минут автоскейлинг группа начнет терминатируется, то есть отключать инстанции в автоскейлинг группе. И придет в исходное состояние у нас будет 2 Lab Instance. Теперь что мы можем сделать? Мы можем оба либо один из Lab Instance вручную терминатировать и посмотреть что произойдет. А произойдет следующее. Как только вы удалите один из Instance, то общее количество таргетов, то есть Instance под автоскейлинг группой станет меньше чем минимальное значение. Как мы помним минимальное значение было 2. В этом случае автоскейлинг триггерится, видит что количество Instance по тем или иным причинам стало меньше чем минимальное и инициирует создание новых Instance. И через какое-то время оно создает необходимое количество новых Instance, чтобы количество Instance было равно минимальному количеству Instance в настройках автоскейлинг группы. Мы добрались до самого последнего задания. Оно достаточно простое, идея ее следующая. Мы ранее создавали AMI от Instance Web Server 1, который принимал нагрузку, принимал запросы и обслуживал наше приложение. Теперь оно нам не нужно, мы можем ее достаточно безопасно уничтожить, удалить. Для этого необходимо из списка выбрать Web Server 1, убедитесь что не выбраны другие Instance. Далее в верхней части необходимо нажать на кнопку Instance State и в выпадающем списке выбрать опцию Terminate Instance. Выйдет сообщение о том, что действительно ли вы хотите отключить ваш Instance, необходимо нажать на Terminate и подтвердить, что вы отключаете Instance. После того как Instance будет уничтожен, вы можете перепроверить действительно ли все работает и открыть страницу вашего приложения. Там стоит ссылка на Elastic Cloud Balancer и приложение будет также продолжать работать. На этом мы завершаем нашу лабораторную работу. Сейчас нам необходимо успешно разлагиниться со всех систем. Первое это AWS Management Console, необходимо в верхней правой части нажать на название пользователя, в выпадающем списке нажать на кнопку Sign Out. Далее необходимо корректно завершить лабораторную работу в AWS Academy, для этого необходимо нажать на кнопку End Lab. Нас попросят подтвердить, что мы действительно хотим завершить лабораторную работу, мы нажимаем Yes и в всплывающем окне мы должны дождаться сообщения, что мы можем закрывать это сообщение, удаление всех созданных ресурсов было инициировано. Вы можете закрывать это всплывающее окно, а также закрывать вкладку со страницей AWS Academy. На этом мы подошли к концу нашей лабораторной работы, мы ее разобрали и очень надеюсь, что вы получили более полное представление о сервисах Elastic Load Balancing и Autoscaling. Это те сервисы базовые, которые позволяют сделать нашу инфраструктуру неким абстрактным организмом, который в зависимости от нагрузки, от внешних факторов может изменяться в размерах, увеличиваться так и уменьшаться. Это дает большие возможности компании, в первую очередь это обработать все запросы ваших пользователей, пользователей ваших приложений и другой момент это то, что при уменьшении нагрузки на ваше приложение ее размеры автоматически уменьшаются для того, чтобы сократить ваши расходы, найти инфраструктуру. Я надеюсь, что разбор лабораторной работы был полезен для вас. Спасибо за внимание и увидимся с вами на следующих наших активностях.
