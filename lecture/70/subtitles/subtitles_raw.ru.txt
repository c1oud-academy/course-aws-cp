 Добрый день, уважаемые студенты! Я рад вас всех видеть на очередной лекции. Тема сегодняшней лекции это компьютер, то есть вычисления в облаке. Эта тема достаточно важная и хотелось бы ее максимально подробно с вами разобрать. Поэтому мы эту тему поделили на две недели и сегодня у нас первая часть. Итак, давайте начнем. Сегодняшняя сессия поделена на три части. В первой части мы с вами поговорим про существующие сервисы AWS, которые предоставляют нам вычислительные ресурсы. Далее вторая и третья часть. Она посвящена сервису EC2, то есть Elastic Compute Cloud. Сервис EC2 является одним из самых основных и важных для понимания с точки зрения подготовки к экзамену AWS, а также к вашей будущей работе, так как очень большая вероятность того, что вы будете использовать этот сервис при построении своей IT-инфраструктуры в облаке. Первая секция. Обзор существующих сервисов вычислений. На этом слайде вы видите основной список сервисов, предоставляющих нам вычислительные ресурсы, и выделены те сервисы, которые мы более-менее, что-то более подробно, что-то менее подробно, насмотрим на нашем курсе. Самый первый и основной – это EC2. Это тот сервис, который предоставляет нам виртуальные машины. Далее есть так называемый EC2 Auto Scaling. Это тот сервис, который помогает настроить авто скейлинг для наших EC2-инстансов. Следующие три – это Amazon Elastic Container Registry, далее Elastic Container Service, и третий – это Elastic Kubernetes Service, то есть аббревиатуры ECR, ECS и EKS. Чем они между собой отличаются? Первый – ECR – это хранилище Docker images, образов. Далее ECS – это сервис, который нам помогает работать с Docker-образами. Следующий – это EKS, который позволяет нам работать с Kubernetes. Kubernetes – это абстрактное приложение поверх для более удобной продвинутой оркестрации Docker images. То есть если вы используете Docker и в какой-то момент количество этих образов, с которыми вам приходится работать, оно растет или достаточно большое, то обычно переходят на использование Kubernetes, то есть K8S. И также связанный сервис – это AWS Fargate, тоже сервис, который работает с контейнерами и который является менеджед сервисом. Идея в том, что большую часть административной работы AWS берет на себя, при этом основные моменты, определенные входные данные для работы с контейнерами предоставляем мы как владельца эти инфраструктуры в облаке. Следующие сервисы – это Elastic, Beanstalk и Amazon LightSail. Они в каком-то смысле также похожи, я специально рассказываю сервисы в сгруппированном виде для того, чтобы у вас структурированное это запомнилось. Elastic, Beanstalk – идея в том, что вы загружаете в этот сервис ваш код, код веб-приложения, и этот сервис за вас поднимает инфраструктуру в облаке AWS, таким образом забирает на себя большую часть административной работы. То же самое относится к LightSail, в этом случае мы говорим, что это сервис, который помогает нам строить приложения либо веб-сайты. Следующий сервис – это AWS Lambda, про него мы уже несколько раз проговаривали. Теперь на этих лекциях разберем более подробно. Это Serverless Compute Service, идея в том, что вы пишете код, все остальное с точки зрения администрирования и обслуживания этого кода, оно происходит на стороне AWS. Идеальный сервис для разработчиков, так как максимально уменьшает все то, что связано с администрированием инфраструктуры. Также хотелось бы отметить AWS Batch, это тот сервис, который помогает нам проводить batch jobs, то есть некие работы в больших объемах или группами. И еще один сервис, который также хотелось бы отметить, это AWS Outposts, это тот сервис, который позволяет нам управлять локальной инфраструктурой через интерфейс AWS. Таким образом мы взаимодействуем как будто с AWS, но под капотом используются вычислительные ресурсы, которые у нас в тета-центре. Мы можем поделить определенную часть сервисов вычисления на четыре группы. Первая группа это сервисы по модели IaaS, infrastructure as a service, в нашем случае это Amazon EC2. Атомарной единицей в рамках этого сервиса, то есть ресурсом, с которым мы работаем, является виртуальная машина. Так как этот сервис предоставляется по модели infrastructure as a service, у нас абсолютно полный контроль над этими виртуальными машинами. Мы можем устанавливать любую операционную систему, любые приложения. Единственный момент, нужны специалисты, которые все это проделывают. Если есть специалисты и есть определенные уникальные требования к IT инфраструктуре, то EC2 это наш выбор. Следующий вариант это серверлесс ресурсы. Яркий представитель это AWS Lambda. Когда мы пишем код, этот код загружаем в облако и все то, что связано с администрированием, обслуживанием этого кода, оно происходит на стороне AWS. Это идеальный выбор в случае, когда есть недостаток специалистов, которые будут обслуживать вашу инфраструктуру. Третья группа это сервисы, которые связаны с контейнерами. Мы чуть подробнее далее поговорим, что такое контейнеры. Здесь есть четыре сервиса, которые работают с контейнерами. Это ACS, AQS, ECR и Fargate. Четвертая группа это сервис, который предоставляется по модели Platform as a Service. И минимальной единице, атомарной единице, ресурсом в этом случае является один веб-аппликашн. Сервис это Elastic Beanstalk. Идея в том, что мы пишем код, этот код загружаем в облако. Дальше Elastic Beanstalk самостоятельно разворачивает необходимую инфраструктуру. Естественно, мы передаем дополнительные параметры, которые прописывают некоторые ограничения условия либо мощность этой инфраструктуры. Но всю ту работу по поднятию и поддержке осуществляет этот сервис Elastic Beanstalk, так как оно предоставляется по модели Platform as a Service. Вы видите, что даже когда мы говорим про вычислительные ресурсы, то AWS предоставляет несколько вариантов сервисов, которые в зависимости от вашей бизнес задачи могут вам идеально подойти. Здесь единственный момент, который я бы хотел отметить, это то, что компания всегда находится в различных стадиях развития. Таким образом, в начале представим, что вы какой-то маленький стартап, у вас небольшие нагрузки. В этом случае, возможно, вам идеально подойдут сервисы, которые сервер-лес, например, Lambda. Когда у вас нет штата, у вас нет штатного системного администратора, который этим всем занимается, более того, у вас нет больших нагрузок или постоянных нагрузок на ваш продукт, IT-продукт, в этом случае достаточно использовать Lambda. Когда у вас растут нагрузки, у вас растет штат, далее у вас появляются некоторые уникальные требования к IT-инфраструктуре, то вам нужно больше контроля над вашими же IT-ресурсами в облаке. В этом случае вы постепенно будете перебираться от моделей, когда вам предоставляется сервис, когда вы лишь малую часть выполняете, а большую часть делает AWS, к сервисам, которые дают вам полный контроль над IT-ресурсами, самый максимальный случай, который возможен, это IaaS и, в нашем случае, EC2. Мы с вами добрались до второй части нашей сессии, с этого момента мы начнем подробное знакомство с сервисом Amazon EC2. Amazon EC2 расшифруется как Amazon Elastic Compute Cloud. Этот сервис, который предоставляет нам виртуальные машины. Эта виртуальная машина ничем не отличается от выделенного сервера, который мы заказываем от локального hosting провайдера, либо который мы настраиваем и заказываем на локальном дата-центре. Отличие лишь в том, что предоставляются все преимущества облачных технологий по сравнению с локальным развёртыванием. А именно это то, что вы можете за минуты запросить необходимое количество вычислительных мощностей, в любой момент, когда вам эти вычислительные мощности не нужны, вы можете их отозвать и вернуть обратно и оплата будет производиться только за то время и за то количество инстанцев, типов инстанцев, которые вы использовали. Уже вы сразу можете видеть, что по сравнению с локальной инфраструктурой и облачной инфраструктурой, абсолютно такой же с использованием EC2 сервиса, мы уже получаем некоторые выгоды. Для нас она выходит выгодной, потому как большинство IT-проектов, нагрузка на IT-инфраструктуру, она идет динамическая. Например, если это какой-то веб-сайт по продаже одежды, то обычно люди занимаются покупками либо в выходные, либо в так называемые prime hours, то есть часы, когда идет пиковая нагрузка. Это время либо утром в 9 до 9, либо это обеденное время, или это время после 6-7 часов вечера до 10 часов вечера, когда люди свободны от работы и у них появляется время делать какие-то покупки. В этом случае, когда у вас есть серверы на локальном дата-центре, то для того, чтобы обслужить все нагрузки, которые приходят, максимальное время, чтобы не потерять ни одного клиента, у вас должен быть какой-то запас серверов, которые постоянно там находятся. Потому как быстро в течение минуты получить новый сервер – это нереальная задача, когда вы хоститесь локально. Обычно заказ сервера занимает несколько дней, а более реалистичный вариант – это несколько недель. Таким образом, у вас должен быть какой-то запас. Другой момент – это то, что те серверы, которые вы уже заказали, вы никуда на временное использование или вернуть обратно быстро не можете. Поэтому, раз вы купили, вы уже понесли основные ваши расходы в большом объеме. И в случае, когда у вас нет нагрузки, например, в 4 часа утра, никто не использует ваш веб-сайт, в этом случае все ваши висчлительные мощности простаивают. Фактически, вы теряете ваши деньги. Когда мы работаем с сервисами облачными, в этом случае мы можем настроить скейлинг, автоскейлинг, когда, в зависимости от нагрузки на нашу инфраструктуру, мы получаем необходимое количество EC2-инстанцев. И это уже позволяет нам экономить, потому как в те часы, когда нагрузки небольшие, мы отдаем большую часть серверов обратно Амазону и за эти часы не оплачиваем. И сохраняем только минимальное количество инстанцев для того, чтобы обслуживать клиентов в эти непопулярные часы. Потом, в тот момент, когда у нас происходят часы пика, то есть когда люди в большом количестве посещают ваш сайт, в этом случае, количество инстанцев необходимо запрашивается у облачного провайдера и в течение нескольких минут она доступна и на него можно направлять трафик. Все происходит автоматически, так как это некий живой организм в облаке. И это позволяет, даже если нагрузки у вас в 10 раз увеличатся внезапно, то все те новые пользователи, которые к вам пришли поверх, они будут обслужены успешно, потому как вы всего-навсего запросите в 10 раз больше инстанцев. Естественно, вы что-то заработаете, это будет для вас очень выгодно и в тот момент, когда пиковые часы пройдут, вы вернете обратно эти инстанцы и у вас не будет случаев, когда ваша инфраструктура простаивает. Примерами использования EC2-инстанца могут быть все те примеры, которые могут быть развернуты в локальном сервере, а именно это может быть сервер, обслуживающий приложение, веб-сайт, базы данных, может быть сервер какой-то игры, который обслуживает игру по сети, далее это может быть почтовый сервер, медиа-сервер, когда вы раздаете картинки, может быть аудио либо видео. Материалы стримите, например, какое-то видео. И другой вариант – это файл-сервер, да, вы загружаете туда файлы и даете возможность эти файлы скачивать и работать с этими файлами, как, например, Troublesbox, это может быть какой-то proxy-сервер и все те примеры, которые применимы на локальный сервер, то есть сервер, который хостится в локальном дата-центре, они также применимы для EC2-инстанцев в облаке. Резюмируя, мы говорим, что Amazon EC2 – это сервис, который предоставляет нам виртуальные машины, эти виртуальные машины называются EC2-инстанциями. EC2 расшифруется как Elastic Compute Cloud. Также хотелось бы отметить, что EC2 поддерживает все популярные операционные системы Windows, Linux, а именно Windows версии 8, 12, 16, 19, Red Hat, SuS, Ubuntu и есть такая операционная система Amazon Linux, которая была создана, поддерживается и постоянно улучшается. Самим Amazon называется Amazon Linux. На сегодняшний день существует две версии, то есть Amazon Linux первая версия и Amazon Linux вторая. Рекомендуется переходить на следующую версию, так как за ту же цену вы получаете еще большие возможности и преимущества по сравнению с предыдущей версией. В целом также рекомендуется использовать операционную систему от Amazon, потому как она максимально интегрирована с AWS, а также все те новинки, которые выходят, они могут выходить только для этой операционной системы. Либо если появляется некое обновление для всех операционных систем, то в первую очередь она появляется внутри Amazon Linux. Давайте пройдемся по процессу создания EC2 Instance. Оно состоит из 9 различных шагов. Самый первый это выбор AMI. AMI это Amazon Machine Instance либо простыми словами это слепок либо шаблон EC2 Instance. В этот шаблон входит операционная система, все возможные настройки, установленные приложения и все то, что вы можете проделать в рамках этого EC2 Instance. Вы как будто бы замораживаете в каком-то состоянии, в определенном состоянии этот EC2 Instance со всеми необходимыми, правильно проделанными настройками и это состояние можете наложить на новый EC2 Instance. Таким образом вы экономите свое же время, исключаете человеческий фактор и все те новые Instance, которые создаются, они создаются намного быстрее, нежели вам пришлось бы все эти настройки проделывать с нуля для каждого EC2 Instance. Существует три источника AMI. Первый это делать самостоятельно, второй это AWS Marketplace. Это то место, где компания подготавливает от своего имени AMI со специфическими настройками, вы можете эти AMI там покупать. И третий вариант это Community AMI, это то место, где специалисты со всего мира подготавливают самостоятельные AMI и бесплатно публикуют в общем доступе. Так как AWS не проверяет содержимое этих AMI, то использование AMI с Community AMI, она полностью под вашу личную ответственность, то есть на ваш страх и риск. Я со своей стороны не рекомендую использовать AMI с Community AMI, в некоторых случаях это является оправданным, если покупать AMI внутри AWS Marketplace, но самым лучшим вариантом является подготовка AMI самостоятельно. Здесь вы можете видеть на диаграмме процесс создания нового AMI, то есть вы можете импортировать состояние уже существующей виртуальной машины, либо можете начать с самого начала. Следующим шагом это вы получаете немодифицированный инстанс, далее вы производите все необходимые настройки, апгрейды, обновления приложения, патчи безопасности и так далее, и получаете уже модифицированный инстанс, который в таком же состоянии сохраняете как новый AMI. Следует помнить, что AMI, оно создается в рамках определенного региона, если ваша инфраструктура развернута в нескольких регионах, то вам необходимо будет скопировать AMI с одного региана на второй, для того чтобы он был доступен уже в другом регионе. Его ID будет отличаться, но содержимое будет такое же. Следующий пункт это выбор типа инстанса. Когда мы говорим про тип инстанса, имеется в виду мощность этого виртуального сервера. Мощность определяется количеством оперативной памяти, количеством ядер процессора, информация о возможности подключения жестких дисков и объем этих жестких дисков, а также информация по каналу передачи данных по сети. На этом слайде представлена информация по характеристикам серверов в зависимости от изменения его размера. Самый маленький размер внутри AWS это nano, дальше micro, small и так далее. Также в названии инстанца вы видите как префикс идет, буквы в нашем случае T и цифра 3. Буква это семейство инстанцев, а цифра это поколение. Про семейство мы подробнее поговорим на следующем слайде. Когда мы говорим про поколение, это цифра, которая с каждым годом увеличивается на текущий момент. Последними поколениями являются 5 и 6. Когда мы говорим про размеры в таблице, вы видите, что с увеличением размера инстанца логично увеличивается количество ядер процессора, а также количество оперативной памяти. Здесь вы видите информацию по существующим семействам типов инстанцев. Не нужно запоминать каждую букву, достаточно запомнить самые основные, которые потенциально могут прийти на реальном экзамене AWS. Когда мы говорим про семейство общего назначения, это семейство A, M и T. Необходимо запомнить T. Дальше идет compute optimized, то есть для того же размера, например, large, у compute optimized инстанца будет большее количество ядер процессоров. По сравнению с large инстанцем семейства general purpose, то есть какой-нибудь T3 large и C3 large. Здесь необходимо запомнить, что это семейство C. Дальше идет у нас memory optimized, это R и X. Также есть Z, но чаще всего и самым популярным является семейство R. Здесь также по сравнению с general purpose тот же, например, T3 large и тот же R3 large. В этом случае у R3 large будет как минимум в два раза больше оперативной памяти по сравнению с тем же T3 large. При этом количество ядер процессора будет таким же. Следующие они достаточно редко используемы в зависимости от вашей бизнес задачи. Есть accelerated computing, когда вы тренируете некоторые модели машинного обучения, искусственный интеллект в этом направлении. Есть также типы инстанцев, которые позволяют вам развернуть distributed file systems, то есть распределенные файловые системы, Hadoop и так далее. В этом случае есть семейство DHAI. Я вам рекомендую остановить это видео, перейти на страницу pricing сервиса Amazon EC2. Там вы увидите, какие на текущий момент есть семейства типа финстенцев, какие есть размерности, сколько они стоят, а также какое количество оперативной памяти, ядер процессора предоставляется, какие есть возможности в плане storage и networking. Вы можете сравнить несколько разных семейств, чтобы получить полное представление. Когда мы говорим про networking, когда учитывать возможности networking. В случае, если у вас передается небольшое количество данных внутри вашей инфраструктуры, будь то между EC2 инстанцами, либо между вашими EC2 инстанцами и базой данных, в этом случае не так критично информация по сети. Она будет вам предоставлена. В случае, когда вы работаете с большим объемом информации, данные передаются по сети, в этом случае этот момент может быть для вас критичным. Поэтому обратите на это внимание и следует также учитывать, что есть специальные выделенные семейства типа финстенцев, которые оптимизированы для работы по сети. То есть у них может быть не такое большое количество оперативной памяти, либо ядер процессора, но канал для передачи данных по сети, он предоставляется больше по сравнению с другими семействами. Следующий пункт, третий, это Network Settings, в котором мы указываем всю информацию, где будет расположен наш EC2 инстанц. А именно мы указываем информацию, в каком VPC, в какой availability зоне и в каком сабнете будет находиться новый EC2 инстанц. Я здесь не говорю касательно региона, почему? Потому что до того, как вы нажмете в самом начале кнопку Create Instance или Launch Instance, регион уже должен быть выбран нужный, потому как внутри Launch Wizard вы не сможете поменять регион. Это тот момент, который следует учитывать. В случае, когда вы делаете эту программу, то скорее всего команда не сработает, если вы не укажете какой-нибудь из регионов. Еще один момент, который следует учитывать, это то, что все инстанции, которые создаются в дефолтовом VPC, они получают Public IP-адрес. Мы с вами помним, что это динамический IP-адрес, но благодаря этому адресу ваш инстанц может быть доступен из интернета. В случае, когда мы говорим не дефолтовый VPC, то флажок Выставлять, Выдавать публичное IP-адреса, оно убрано и публичные IP-адреса не выдаются. Если вам нужно выдать публичный IP-адрес, то вы должны явно это указать в настройках создания вашего VPC либо сабнета. Следующий шаг, четвертый, это привязка IAM-роли к EC2-инстанцу. Этот шаг является опциональным. Идея ее в том, что представим, что ваш инстанц, в нем крутится некоторый код, логика, которая использует и обращается к другим AWS-сервисам. В этом случае ему необходимо выдать соответствующие доступы, права. AWS предоставляет удобную и безопасную возможность это сделать, а именно создается IAM-роль. Дальше создается instance-профайл с этой ролью. В случае, когда вы делаете это все через AWS-менеджмент консоль, то в момент привязки IAM-роли к инстанцу, прозрачно для вас создается instance-профайл с таким же названием, как ваша IAM-роль. Фактически instance-профайл это некий контейнер, который содержит в себе эту роль, а instance-профайл вы можете привязать к инстанцу для того, чтобы предоставить ему доступ к другим AWS-сервисам. В случае, когда вы создаете роль и пытаетесь привязать к EC2-инстанцу программным путем, то помните, что вам необходимо также создать instance-профайл. На слайде проиллюстрирован пример, когда у нас есть роль. Роль предоставляет доступ к S3-бакету, и в тот момент, когда мы привязываем эту роль к инстанцу через instance-профайл, у инстанца, точнее у кода, который работает внутри инстанца, появляется возможность обратиться к S3-бакетам и как-то взаимодействовать с данными, которые там находятся. Аналогично будет происходить процесс выдачи прав к инстанцу к любому другому сервису AWS. Пятый шаг — это User Data Script. Этот шаг является опциональным. Идея ее в том, что вместе с созданием вашего инстанца вы можете передать некий набор команд, и эти команды запустятся в самый первый запуск вашего инстанца. Зачастую вы здесь передаете список команд, которые могут быть выполнены только после создания инстанца. Возможно, это команды, которые обновляют существующие приложения, может быть, это команды, которые привязаны к метадате вашего инстанца. Как метадата инстанца мы можем сказать, что есть private IP-адрес, public IP-адрес и другая информация. Здесь у вас может возникнуть вопрос, почему нам нужно использовать User Data, если есть уже готовый AMI, в котором мы предварительно установим все необходимые программы, запустим необходимые команды и уже все будет готово. Это абсолютно правильный ход мыслей, и так и нужно поступать. То есть все то, что вы можете обернуть и сохранить в шаблоне AMI, это нужно сделать. Все то, что не получится по тем или иным причинам положить внутри AMI, вы можете сделать в User Data. User Data доступно не только для Linux-операционных систем, так же для Windows. Следует только учесть, что когда вы запускаете в Windows, набор команд должен быть совместимым либо с Command Prompt, Windows, то есть CMD, либо с Windows PowerShell. Другой немаловажный момент, это то, что все команды, которые вы запускаете, будь то Windows, будь то Linux-операционная система, они запускаются под admin-правами, либо root-пользователем. Следующий шаг, это шестой, Specify Storage, то есть мы здесь указываем информацию по нашим жестким дискам. Здесь мы указываем основной жесткий диск, то есть root-vlm, в котором мы устанавливаем операционную систему. Так же можем указать дополнительные жесткие диски, в которых будем хранить наши данные. Если вы уже настроили ваши жесткие диски внутри AMI, то этот шаг пропускается. Когда мы говорим про жесткие диски, мы говорим про три момента. Первый это ее размер, дальше это тип, и третий это информация по шифрованию этих жестких дисков. Когда мы говорим про хранилища для EC2-инстанца, то упоминают четыре возможных варианта. Первые два это Elastic Block Store, то есть Amazon EBS, и Amazon EC2 Instance Store. Это фича сервиса Amazon EC2. Оба эти варианты являются блочным хранилищем, таким образом, что первый и второй вариант подходят для установки операционной системы и соответственно полноценного запуска нашего виртуального сервера. Есть некоторые отличия. Когда-то давно, когда не было сервиса Amazon EBS, использовался вариант только Amazon EC2 Instance Store. Это те жесткие диски, которые в дата-центре физически привязаны, то есть подключены к нашей оперативной памяти и к нашему процессору. То есть это одно целое, один сервер. Таким образом, когда что-то происходит не так, ломается, поломка и автоматически заменяется ваш инстанс, то все то, что находится в жестких дисках с этим инстансом, оно для вас более становится недоступным. Так как есть такое неудобство, был создан альтернативный вариант, это сервис Elastic Block Store. Идея в том, что жесткие диски, они более не привязаны к инстансам, то есть к вычислительным мощностям и являются чем-то отдельно стоящим. Таким образом, вы через Amazon EBS создаете ресурсы, то есть жесткие диски, которые привязываете к вашему инстанцу. В случае, когда происходит какая-то поломка либо с процессором, либо с оперативной памятью в целом, с этим инстанцем физически, то вы можете ваши жесткие диски, которые к нему не относятся, приоттачить, то есть привязать к другому инстанцу. И все будет работать, вы никакие данные не потеряете. В этом и есть отличие EBS от Instant Store. Поэтому общая рекомендация как best practice, использовать Amazon EBS там, где это возможно. В некоторых случаях оправданно использование Instant Store, это все зависит от вашей бизнес задачи и нужно детально это рассматривать. Следующий вариант это Amazon Elastic File System. Опять же, это файловая система, блочное хранилище. Отличие лишь в том, что вы не можете на нем установить операционную систему, но она отличается тем, я использую в тех случаях, когда вам нужен отдельно стоящий жесткий диск, который доступен для нескольких EC2-инстанций. И является некоторым общим жестким диском. Опять же, от вашей бизнес задачи вам может понадобиться хранить в одном месте некоторые данные, для того, чтобы ваши инстанции могли туда добираться и совместно с этими данными работать. Также другой вариант для совместной работы с несколькими инстанциями, это сервис уже знакомый нам, Amazon S3, то есть Simple Storage Service. Этот сервис предоставляет не блочное, но объектное хранилище. В случае, когда мы работаем с объектами, мы также можем воспользоваться сервисом S3 для того, чтобы совместно с несколькими инстанциями обращаться и работать с одними и теми же данными. Здесь представлен пример наглядной инстанция, которую используют как root volume Amazon EBS, а также инстанция второй, которую используют как root volume, нашей thermal volume, то есть instance store. Давайте пройдемся по отличию либо схожести этих двух вариантов в зависимости от действий или состояния, которое происходит с инстанцием. Первое это перезагрузка. В случае, когда мы перезагружаем инстанц, для обоих вариантов данные у нас сохраняются, ничего не теряется. Когда мы говорим про остановку, то есть stop инстанца, мы можем инстанц, который работает с EBS остановить. Остановленный инстанц мы не оплачиваем, мы оплачиваем только за наши данные, которые лежат внутри EBS. А за EC2, который является намного дороже, мы не оплачиваем. Это может быть удобно, если некоторые наши серверы простаивают и там проще их приостановить либо терминейтнуть для того, чтобы не терять деньги. Когда мы говорим про instance store, то функционал остановить инстанц недоступен, вы не можете его остановить. Таким образом, есть вариант либо перезагрузить, либо третий вариант это терминейтнуть, то есть уничтожить сервер. Когда мы терминейтим инстанц с EBS жесткими дисками, то терминейтится сам инстанц, а жесткие диски они сохраняются и остаются для нас доступными. Для удаления мы также можем указать, есть определенная опция с флажком. Если мы выставляем этот флажок, то наши жесткие диски совместно с EC2 инстанцем удалятся, либо мы можем не выставлять этот флажок и наши жесткие диски сохранятся. И эти жесткие диски мы после можем привязать к другому инстанцу, другого типа и все данные, которые были, они в таком же состоянии останутся доступными в таком же виде. Когда мы терминейтим инстанц, который работает с Instant Store, то данные, которые находятся в Эфирмал Воллеме, они полностью удаляются, включая операционную систему. Поэтому хранить некоторые данные, которые вы не сможете восстановить, либо важные данные не рекомендуется хранить в Instant Store. Там вы можете хранить какие-то данные для кэширования, либо любые другие данные, которые временные или вы в любой момент можете восстановить. Следующий шаг это возможность добавить теги. Здесь хотелось бы отметить, что теги это функционал, который доступен для любого ресурса, любого AWS сервиса, поэтому оно не привязано конкретно к EC2 инстанцам. Что такое теги? Теги это некий набор пар, ключ и значения. Приведу примеры ключей. Самый популярный это name. И когда вы заполняете неким значением, то это значение зачастую отображается внутри AWS Management консоли вместе с ID-шником этого ресурса. Это в большинстве случаев помогает идентифицировать ресурс. Другие варианты ключей это environment, то есть среда. Оно может быть тестовой средой для разработчиков, либо боевой средой. Соответственно, для ключа key environment будут значения внутри валвы поля, либо def, либо test, либо prod, либо любые другие. Другой вариант ключа тега это owner, то есть владелец. И как значение может указываться либо определенный человек, специалист, либо некоторый департамент управления внутри вашей компании. Идея тегов это в том, чтобы идентифицировать однозначно этот ресурс и в случае чего получить ответы. Если не получить ответы, то по крайней мере получить некоторую информацию, которая поможет найти нужных людей, нужную группу людей, нужный отдел, структуру вашей организации, которая отвечает за этот ресурс. Причины подобных вопросов или поиска людей может быть разные. Может быть такое, что этот ресурс работает долгое время и ежемесячно потребляет очень много денег. Уходит, например, тысячу долларов только на один instance, он большой. И люди, которые занимаются оптимизацией расходов внутри AWS, нашли этот ресурс и уже хотят получить ответы, почему он крутится, работает, не работает, нужно, не нужно и так далее. Другой вариант может быть такой, что есть некоторые сервисы, под сервисом, естественно, у нас разный набор ресурсов и что-то пошло не так, что-то сломалось, никто восстановить не может, не может найти специалиста, кому можно обратиться. И в этом случае нам могут помочь теги для того, чтобы понять, куда задавать вопросы, чтобы уточнить, этот сервис кому-то нужен, что-то серьезное сломалось, либо нет, нужно восстанавливать или не нужно терять на это время, потому что что-то траченное время специалисту это тоже деньги для компании. Все теги, что ключ, что значение, они являются case sensitive, это значит, что они чувствительны к регистру. Простыми словами вы можете создать ключ name с большой буквой, заглавной буквой, а также такой же ключ name, только все буквы с прописными маленькими буквами. И никакой ошибки в этом случае не будет, потому как внутри в системе эти ключи воспринимаются как отдельные. Восьмой шаг – это настройка security group. Мы можем привязать одну либо несколько security group к нашему инстанцу. Что такое security группа, мы с вами ранее проговаривали. Вкратце это некий firewall виртуальный, который фильтрует трафик то нашего инстанца. Мы указываем в security группе набор рулов, то есть правил, которые разрешают либо входящий, либо исходящий трафик. Вы можете видеть на слайде пример предоставления доступа по SSH, то есть это протокол TCP, порт 22 и как source источник вы выбираете пункт myIP. Когда вы его выбираете, то копируется ваш текущий адрес и вставляется в соответствующее поле. После чего у вас появляется возможность по SSH подключиться ко всем инстанцам, к которым привязана конкретная security группа. Для того, чтобы успешно подключиться к инстанцу, дополнительно вам также нужно соответствующие SSH ключи. Самый последний шаг во время создания EC2 инстанца это выбрать либо создать новый key pair. Key pair это связка public key и private key, то есть публичный ключ и приватный ключ. Публичный ключ сохраняется внутри EC2 инстанца, а private key вы загружаете для локального хранения. В момент подключения по SSH вы предоставляете ваш private key, и после чего происходит криптографическая операция, которая сверяется, действительно ли ваш private key относится к public key, хранящийся внутри EC2 инстанца. Если все совпадает, то доступ по SSH вам предоставляется. Здесь вы можете видеть пример списка инстанцев внутри вашего AWS аккаунта, то есть это сервис EC2. В левом навигационном меню открыта вкладка instances, и на основной странице указывается список всех инстанцев. Мы видим, что у нас отфильтрован определенный инстанс, он и выбран. В нижней части страницы вы видите несколько вкладок, таких как description, status check, monitoring text и, возможно, любые другие вкладки. В этих вкладках предоставляется информация о конкретном выбранном инстансе. Мы также с вами можем создавать инстанцы, либо проделывать любые другие действия внутри облака AWS программным путем. Для этого существует AWS CLI, то есть Command Line Interface, и второй вариант – это Software Development Kit, то есть SDK. Здесь мы видим пример CLI команды, которая создает EC2 instance. Обратите внимание, что она состоит из нескольких частей. Самое первое – это AWS, говорит о том, что мы обращаемся к AWS CLI. Далее название сервиса – это EC2, и внутри EC2 мы указываем, какую операцию нам необходимо произвести. В нашем случае это операция run instances. После чего в той же строке мы указываем параметры, которые относятся к этой операции. Здесь мы видим, что указан Image ID, то есть наш AMI. Далее указываем количество инстанцев для создания, тип инстанцев. Key name – это название публичного SSH ключа, security группы, а также информацию о AWS регионе, где создаются наши инстанцы. Как только запускаем эту команду, мы получаем ответ. Ответ может быть успешен либо не успешен. В случае ошибки предоставляется информация о коде ошибки, а также ошибка в текстовом формате для того, чтобы получить представление, что же пошло не так. В случае, если мы получаем успешный ответ, то в нем как минимум будет указан ID EC2 instance, а также другая информация, которая существует и доступна для этой операции. На этом слайде представлена информация по жизненному циклу любого EC2 instance. В квадратных фигурах указано состояние инстанца, а название стрелок – это то действие, которое мы производим. Начнем с самого начала. Есть у нас AMI. Когда мы запускаем instance, то instance переходит от AMI в состояние в pending. Pending состояние означает, что AMI устанавливается на железо внутри дата центра. Как только все настройки произведены и instance готов к бою, то есть он может начать принимать трафик, вы можете подключаться по SSH, и в целом он доступен для работы, то он переходит от состояния pending в состояние running. Мы с вами помним, что операционная система, то есть root volume EC2 instance может быть EBS, back-up, то есть жесткие диски, созданные внутри сервиса Amazon EBS, либо используется опция instance store, когда мы работаем с жесткими дисками, напрямую привязанные к нашему железу внутри дата центра. И для обоих вариантов у нас доступен вариант reboot, то есть перезагрузить сервер, в этом случае сервер перезагружается, и данные, которые там находятся в обоих случаях, они сохраняются. Теперь в случае, когда мы работаем с EBS жесткими дисками, то у нас есть вариант остановить наш instance, она от состояния running, как только мы стартовали действие stop, переходит в состояние stopped через состояние stopping. В состоянии stopped мы не оплачиваем за instance, она в состоянии гибернации, мы оплачиваем только за EBS. Здесь я напомню, что основная часть оплаты, она не за жесткие диски, а именно за instance, таким образом остановив instance, мы экономим наши деньги. В тот момент, когда нам необходимо наш instance стартовать еще раз, то мы можем из состояния stopped его запустить, он переходит в состояние pending, и обратно возвращается в состояние running, то есть готов к бою. Далее мы можем terminate, то есть уничтожить, либо высвободить ресурсы, высвободить железо, и более не оплачивать. Таким образом происходит переход от состояния running в состояние terminated, промежуточное состояние shutting down. Как только сервер у нас остановлен, то какое-то время у нас в списке инстенсов наш остановленный, то есть отключенный instance будет отображаться и статус будет terminated. Как только удаление, высвобождение этого instance полностью заканчивается, то из списка этот instance полностью пропадает. Мы с вами поговорили подробнее про жизненный цикл и ситу инстенса. Также в зависимости от состояния ситу инстенса есть некоторые нюансы работы с публичными IP адресами. У нас есть два варианта публичного адреса, это public IP адрес, который выдаётся временно для наших инстенцев, и эти инстенсы доступны через интернет. Второй вариант это вариант static IP адрес, то есть постоянный IP адрес через сервис Elastic IP адрес, вы можете отдельно его заказать, если вам нужна такая опция. Так вот, когда мы говорим про public IP адрес, публичный IP адрес это некоторый pool, то есть некоторый набор IP адресов, не привязанных конкретно к вашему аккаунту, это общий набор IP адресов, которые доступны для Amazon. В зависимости от занятости того или иного IP адреса, вам во временное пользование вашим инстенсам выдаётся некоторое значение. И здесь важный момент, когда мы terminate им инстенс и создаём новый инстенс, здесь понятно, мы получаем случайный IP адрес публичный, и никак не влияем на её значение. В случае, когда мы останавливаем инстенс, также следует запомнить, что публичный IP адрес, он обратно возвращается AWS, для того, чтобы оно могло назначиться EC2 инстанцию в другом AWS аккаунте. Поэтому, учитывайте этот момент, и знайте, что когда сервер у нас останавливается и запускается снова, для него выдаётся новый публичный IP адрес, который доступен на тот момент, на момент запуска. Если возвращаясь к статическому IP адресу, то это Elastic IP адрес, выделенный сервис, который вам даёт статический IP адрес. По умолчанию, внутри AWS аккаунта вам доступны пять IP адресов, если же вам нужно больше, то вы можете сделать соответствующий запрос. Этот лимит он soft limit, поэтому может быть увеличен в зависимости от вашей необходимости через обращение в support. Как только ваш инстанс запущен, по у этого инстанца появляются некие метаданные. Как метаданные выступают публичный IP адрес, приватный IP адрес, информация о том, на каком регионе запущен этот инстанс, какой availability zone относится, какие security группы привязаны к этому инстанцу. То есть вся возможная информация о этом инстанце, она доступна в AWS Management Console в соответствующих вкладках в сгруппированном виде. А также эта же информация доступна из самого инстанца, если обратиться по IP адресу 169.254.169.254. Если мы идем по пути latest metadata, то мы выходим на метаданные по этому конкретному инстанцу. Если мы идем по пути latest и user data, то мы открываем список команд, которые запускаются при первом запуске этого инстанца. Вы можете использовать эти данные, эта ссылка она постоянная. И в случае, если вам нужна какая-то информация либо с user data, либо метадата конкретного инстанца, то вы можете во время настройки обращаться по этому пути. Это JSON документ, в JSON документе соответствующие ключи. Этот путь внутри JSON файла, он тоже постоянный, и вы можете эти данные использовать для финальной настройки вашего инстанца. Также я вам рекомендую запомнить оба URL адреса, так как они бывает приходят на реальный WS экзамене. Когда мы говорим про мониторинг нашего ICT-инстанца, то подразумевается сервис Amazon CloudWatch. Это тот сервис, который сохраняет метрики, и вы в графическом виде можете отобразить изменения ваших метрик и предпринимать некоторые шаги. Либо вручную, либо опять же настроить автоматическое реагирование на соответствующее значение метрик. Как метрики могут выступать? Нагруженность ваших ядер процессора, нагрузка на ваши жесткие диски, то есть операция записи отдельно, операция чтения отдельно. Также информация по загрузке канала сети, то есть Network. Здесь важно отметить, что метрика RAM, то есть загрузка оперативной памяти по умолчанию недоступна. Для того, чтобы эти метрики тоже передавать, необходимо выполнить некоторые дополнительные действия, и эти метрики также будут для вас доступны. Более того, в рамках CloudWatch есть два варианта мониторинга. Это Basic Monitoring и Detailed Monitoring. При варианте Basic Monitoring метрики передаются каждые 5 минут. И эта опция, она бесплатная, доступная по умолчанию. Вторая опция, это если ваши метрики нужно передавать чаще, либо вам нужно видеть большую детализацию. В этом случае Detailed Monitoring позволяет вам передавать и хранить метрики по каждой минуте, то есть ежеминутно. Следует отметить, что Detailed Monitoring, она оплачивается отдельно, и информацию по оплате, по стоимости вы можете посмотреть на соответствующей странице. Мы с вами добрались до конца второй части нашей лекции. Давайте резюмируем и пройдемся по самым основным моментам. Во время создания EC2-инстанца, мы можем выбрать операционную систему как Linux, так и Windows. Мы создаем EC2-инстанцы от некоторого AMI. AMI это Amazon Machine Instance, который в себя включает помимо операционной системы, также дополнительные настройки, установку неких программ и запуск определенных команд. То есть выступает как снапшот другого инстанца. Также во время создания EC2-инстанца, мы должны указать в каком VPC он будет создан. С точки зрения безопасности и best practices security рекомендуется не использовать дефолтный VPC, а создать собственный, новый. Для вашего выбора доступны различные типы инстанцев, а также есть целые семейства типов инстанцев, чтобы подобрать максимально подходящую конфигурацию с точки зрения количества ядер процессора, размера оперативной памяти, возможности хранилищ и сетей. Для того, чтобы контролировать доступ к вашим инстанцам, вы можете использовать security группы. Security группы работают на уровне инстанцев и выступают в роли виртуального firewall. Вы можете во время создания инстанца также передать список команд, который называется user data, для того, чтобы финализировать настройку и запустить те команды, которые могут быть успешно выполнены только после запуска инстанца. Операционная система инстанца может быть установлена на жесткие диски от Amazon EBS, либо EC2 Instance Store. Те инстанции, которые использует Instance Store не могут быть остановлены. Инстанции, которые используют жесткие диски от Amazon EBS могут быть остановлены. Более того, в остановленном состоянии оплата за инстанции не производится. Таким образом, вы экономите деньги. Для того, чтобы мониторить ваши инстанции, вы можете воспользоваться сервисом Amazon CloudWatch и передавать туда соответствующие метрики. На этом мы завершаем вторую часть и переходим к следующей части. Мы с вами добрались до третьей части сегодняшней нашей лекции. Здесь мы с вами подробнее поговорим про вопросы оплаты и оптимизации оплаты за сервис EC2. Давайте с вами подробнее разберем, какие модели оплаты существуют за сервис Amazon EC2. Самые первые – это on-demand instances. Это вариант, когда мы оплачиваем ровно за то, за что мы используем. Представим, что мы заказали 10 серверов на 2 часа для того, чтобы произвести некоторые расчеты, после чего эти серверы нам не нужны. Это пример расчетов нагрузки, которые непостоянные или бразовые. Таким образом on-demand позволит нам уже в конце месяца получить счет на оплату, где будет сидеть 2 часа, умноженное на 10 инстенсов, на 20 часов определенного типа инстенсов, не более. Таким образом мы оплатили ровно за то, за что мы использовали. Здесь еще важный момент – это то, что в случае, если мы работаем с операционной системой Amazon Linux или Ubuntu, то для нас становится доступны посекундные тарификации. Таким образом, если мы запустили инстенс на 1 минуту и 57 секунд, то ровно за это время мы произведем оплату. Следующая модель оплаты за Amazon Linux – это Reserved Instances. Эта модель оплаты идеально подходит для тех нагрузок, которые постоянны 24 на 7. В этом случае мы можем некоторую часть вычислительных мощностей заказать через Reserved Instances и мы получим определенные скидки от AWS. Как это работает? Мы говорим, что мы готовы приобрести определенный объем вычислительных мощностей на год либо на 3 года. Как только заключается договор, эти инстенсы со скидкой нам передаются в использовании. Есть некоторые нюансы касательно оплаты, а именно 3 варианта. От этого зависит размер скидки. Самую наименьшую скидку мы получаем в случае, когда договор мы заключаем, при этом мы продолжаем оплачивать ежемесячно. Этот вариант называется No-upfront Reserved Instances, наперед ничего не оплачиваем. Далее следующий вариант, когда мы 50% периода, год либо 3 года оплачиваем сразу, оставшиеся 50% оплачиваем ежемесячно. Это называется Partial Upfront Reserved Instances либо PURI. И третий вариант, когда мы получаем максимальную скидку в рамках Reserved Instances, это Auri, то есть All Upfront Reserved Instances. И как вы догадались, мы оплачиваем сразу год либо 3 года работы наших инстенсов наперед. Таким образом, ежемесячно нам производить оплату не нужно. Этот вариант идеально подходит для тех случаев, когда вы как бизнес выросли, у вас есть определенный набор объем нагрузки постоянный 24 на 7 присутствующие. В этом случае, зная момент, что у вас есть эти постоянные нагрузки, мы можем хорошую скидку получить от AWS через модель Reserved Instances. Следующая модель оплаты за Amazon EC2 – Spot Instances. Это достаточно интересная модель. Следует запомнить, что Spot Instances дает максимальную прибыль возможную и скидка может достигать до 90%. Это говорит о том, что цены за Spot Instances за единицу времени, она может быть в 10 раз меньше, чем цены за On Demand Instances. Это очень интересное предложение, которое следует воспользоваться. Но есть здесь определенные нюансы. Spot Instances, откуда это все появилось? Так как дата-центры AWS это достаточно большие помещения, в которых есть достаточно большой объем вычислительных мощностей, частенько бывает, что какая-то часть серверов, она не нагружена. То есть она не затребована ни каким клиентам, пользователям AWS, поэтому зря простаивают. Здесь AWS не растерялся и предложил следующую модель. Он готов делать большие скидки за инстанции, которые не затребованы, не требуются для других моделей оплаты, для того, чтобы он что-то мог зарабатывать, пусть и меньше, но при этом зря деньги не терял. Это хорошо и клиентам, так как дает возможность еще больше сэкономить, используя абсолютно то же железо. Момент такой, что Spot Instances по сравнению с On Demand Instances, они даются во владение, которое контролируется и решается не нами. В случае с On Demand Instances мы заказываем инстанции, эти инстанции будут доступны для нас ровно до того момента, пока мы сами не решим от них освободиться. То есть terminated для того, чтобы освободить и вернуть AWS, и больше за них не оплачивать. В случае со Spot Instances мы используем до того момента, пока эти инстанции не затребуются другой моделью оплаты. В этом случае приходит уведомление о том, что этот Spot Instances не может быть дальше обслуживаться по этой модели и через какое-то время отключается. Есть такой нюанс. Таким образом, если у вас есть постоянные нагрузки, полностью на Spot Instances она существовать не может. Spot Instances идеально подходят для тех нагрузок, которые являются асинхронными. Представим, что у вас есть какие-то расчеты, эти расчеты могут быть сделаны сейчас, могут быть сделаны ночью в 2 часа, могут быть в любой момент прерваны и продолжены с того места, потому что у вас где-то каким-то образом сохраняется состояние. Для подобных нагрузок Spot Instances идеальный вариант. Есть еще вариант такой, когда вы скейлите, через автоскейлинг настраиваете несколько групп. Часть группы это On Demand Instances, а часть инстенсов это Spot Instances. В тот момент, когда Spot Instances доступны, вы работаете со Spot Instances. Если получается так, что Spot Instances недоступны, то AWS соответственно все Spot Instances забирает себе и автоматически автоскейлинг срабатывает и поднимает уже On Demand Instances. По цене, естественно, дороже, но как минимум благодаря этой архитектуре есть возможность значительные суммы экономить путем переброски вычислительных мощностей на Spot Instances. Это требует дополнительной настройки, нужен специалист и нужно подходить к задаче с соответствующим расчетом. Если выходит так, что выгоднее это настроить, то бизнесу это нужно предложить и это сделать. Если же выгода от этого небольшая, то рекомендуется оставаться на On Demand Instances. Как происходит ценообразование Spot Instances? Оно организовано неким аукционом, то есть вы предлагаете какую-то свою цену, другой пользователь AWS также в рамках Spot Instances предлагает свою цену и AWS, естественно, выбирает тот вариант, который максимальный для того, чтобы свою прибыль увеличить, но при этом эта цена может быть в несколько раз меньше, чем On Demand Instances. Таким образом, все зависит от региона, например, для региона Норс-Вирджиния, который является самым популярным, самым насыщенным пользователем AWS-регионом. В нем маловероятно, что будет возможность использовать Spot Instances, а, например, для регионов, которые менее популярны, Spot Instances может быть отличным вариантом, который ввиду того, что очень мало пользователей сидят в этом регионе, может получиться так, что ваши постоянные нагрузки большую часть времени отрабатывают по модели Spot Instances, при этом вы получаете максимальные скидки. Следующие две модели оплаты, они привязаны к железу EC2 Instances, называются Dedicated Hosts и Dedicated Instances. Чем они отличаются? Dedicated Hosts позволяет вам привязаться к некоторым характеристикам этого железа, для того, чтобы применить лицензии. Например, лицензии Oracle Баз данных привязываются к количеству ядер на определенном железе. В этом случае, чтобы применить эту лицензию, вы можете использовать Dedicated Hosts. Dedicated Instances – это тот кейс, когда в облаке вам выделяется отдельный сервер железа, в котором нагрузки к других пользователей WS не допускаются. Таким образом, вы являетесь не владельцем, арендуете это железо полностью под себя, и никто другой там не будет. Эти инстанции бывают нужны для некоторых регуляторных требований. Например, требуется, чтобы эти нагрузки, ввиду некоторых специфик данных, либо обработки, должны запускаться на отдельном железе. В этом случае вам необходимо использовать Dedicated Instances. Dedicated Instances, ввиду своей специфики, являются одними из самых дорогих, потому что под вас персонально выделяется конкретное железо, и это достаточно дорогостоящая услуга. Но также следует отметить, что Dedicated Instances достаточно редко требуются, опять же, ввиду некоторых регуляторных требований. Во всех других нормальных случаях on-demand instances будет более чем достаточно. И последний вариант оплаты – это Scheduled Reserved Instances. Здесь следует сразу отметить, что Scheduled Reserved Instances на текущий момент недоступны. Ввиду того, что вопросы внутри реального экзамена AWS обновляются, либо могут обновляться нечасто, то вопросы, связанные с Scheduled Reserved Instances в рамках сервиса EC2, могут вам еще приходить. Поэтому мы этот момент сейчас разберем, но при этом вы для себя имейте в виду внутри AWS на текущий момент этой опции на сегодняшний момент не существует. Что же такое Scheduled Reserved Instances? Это та опция, которая позволяет вам либо каждый день, либо определенный день недели, еженедельно, ежемесячно, по какому-то расписанию определенные часы резервировать под себя на один год. Таким образом, вы производите оплату на один год, указываете какое время, какие инстанции должны быть для вас доступны. И в этом случае они в этот момент запускаются. И вы, опять же, так же как и Reserved Instances, по некоторой скидке производите оплату за эти инстанции. Мы на следующих двух слайдах резюмируем все то, что было сказано по моделям оплаты за сервисы EC2. Если мы говорим on-demand instances, это тот вариант, который максимально гибкий. Spot instances это тот вариант, который удачно подходит для асинхронных нагрузок. Reserved instances это хороший вариант модели оплаты, когда у нас есть постоянные нагрузки 24 на 7. И мы используем dedicated hosts в том случае, когда по некоторым регуляторным требованиям нам необходимо использовать только самим одно определенное железо. Если мы говорим про use cases, on-demand instances используются для кратковременных динамических нагрузок, которые сложно предугадать. В этом случае on-demand подходят идеально. Другой вариант это мы используем on-demand instances для среды разработки либо тестирования. То есть разработка происходит не всегда постоянно, тестирование тоже происходит не всегда постоянно. Поэтому после того, как мы провели этап разработки и тестирования, и эти инстанции зря простаивают, мы можем их отключить и при этом не терять зря деньги. Spot instances это тот кейс, когда у нас асинхронные нагрузки, мы можем наши расчеты, нагрузки в любой момент остановить и продолжить с того места. Оно может отрабатывать ночью, утром, не имеет значения. И также один из примеров это когда нам необходимо запустить некоторые расчеты на больших объемах вычислительных мощностей. В этом случае spot instances даст некоторую выгоду от объемов. Следующий вариант это reserved instances, когда у нас есть постоянные нагрузки 24 на 7. Один из вариантов использования это если компания большая, у нее есть возможность оплатить наперед, при этом знать, что он получит хорошие скидки. В этом случае можно использовать reserved instances. Другой вариант это когда мы настраиваем disaster recovery. То есть disaster recovery это когда наша инфраструктура развернута на двух регионах и один основной, другой резервный. В случае когда происходит какая-то проблема с целым AWS регионом, что происходит очень редко. Но мы говорим, что наши нагрузки, наша инфраструктура должна быть 100% всегда доступна для наших клиентов. Потому как потеря клиентов ввиду недоступности на некоторое время может в целом обанкротить всю компанию. Поэтому это достаточно критичные нагрузки. В этом случае компания разрабатывает и поддерживает DR, то есть disaster recovery. И если компании нужно гарантировать, что в основном либо резервном регионе должен быть гарантированный объем вычислительных мощностей наперед, это зная. В этом случае мы можем через reserved instances эти вычислительные мощности забронировать. И как только они понадобятся их запускать. Либо держать в постоянно запущенном состоянии, зная, что мы с какой-то скидкой получили. При этом мы 100% уверены, что в момент переключения эти инстанции для нас будут доступны. И мы сможем обработать все запросы наших клиентов. Последний вариант это dedicated hosts. Один из примеров использования, если у нас есть уже купленная лицензия, мы можем опять же в зависимости от ситуации использовать свои лицензии, при этом сэкономить на этом. Другой use case это когда нам необходимо следовать некоторым регуляторным требованиям. В этом случае работаем на определенном железе, на который не допускаются другие нагрузки, чужие нагрузки. Давайте резюмируем все то, что было сказано на нашей лекции касательно оптимизации расходов на сервисе C2. Оно состоит из четырех направлений, это write sizing, increase elasticity, optimal pricing model и optimize storage choices. Давайте подробнее остановимся на каждой из этих направлений. Первое направление это write size. Идея в том, что нам необходимо подобрать тот тип инстанций, которые максимально подходят под наши нагрузки. Amazon предоставляет более 60 различных типов инстанций и размеров, поэтому определенно мы сможем найти тот вариант, который устраивает нас. Понятно, что этот процесс не одноразовый, вы не можете угадать либо по каким-либо факторам определить какой вариант определенно ваш, до того как ваши нагрузки начнутся в облаке. Происходит это следующим образом, вы выбираете тот вариант типа инстанца, который максимально дешевый и который будет обслуживать ваши нагрузки. С этим вы начинаете. Далее со временем вы периодически проверяете ваши метрики, то есть вы передаете ваши метрики в сервис Amazon CloudWatch и видите какая идет нагрузка на процессор, какая идет нагрузка на оперативную память, хранилище и сеть. И делаете выводы. Приведу простой пример. Представьте, что у вас есть инстант стайп, у которого CPU нагружена на 70%, а оперативная память нагружена на 10%. Здесь мы видим явно, что наше приложение больше использует процессорные мощности, нежели оперативную память. Таким образом мы можем выбрать тип инстанца, который меньше, но при этом из семейства, который CPU, то есть Type-C. В этом случае мы можем сэкономить на размере инстанца, потому что он будет меньше, но при этом у него оперативной памяти будет гораздо меньше. Исходя из того, что нагрузки не требует оперативной памяти, этот вариант тип инстанца больше нам подходит. Он справляется полностью с нагрузками нашими текущими, при этом мы оплачиваем меньше, нежели мы оплачивали с предыдущим вариантом инстанца. Второе направление – increase elasticity. Здесь говорится про то, что мы должны правильно настроить наш автоскейлинг. Автоскейлинг – это когда наша инфраструктура, это некий живой абстрактный организм, когда в зависимости от нагрузки количество инстанцев, которые обрабатывает ваш трафик, либо увеличивается, либо уменьшается. Представим, что вы какой-то интернет-магазин и ваши нагрузки в основном после 6 часов вечера до 10 часов вечера. В этом случае система, наблюдая за метриками на ваших инстанциях, определяет, что сейчас нагрузка растет, нагрузка на сервера растет, поэтому нам необходимо после определенного порога запустить дополнительные сервера, чтобы это все работало верно. В случае, когда мы опускаемся ниже какого-то другого второго порога, например, если нагрузка на наши сервера меньше 10%, то в этом случае мы видим, что нагрузки как таковой нет. Поэтому мы можем лишние инстанции терминировать и вернуть обратно AWS, чтобы за них не платить. Таким образом, размер нашей инфраструктуры, оно уменьшается, либо увеличивается в зависимости от нагрузки. Таким образом, вы оплачиваете только за те нагрузки, которые реальные. И у вас нет состояния, когда некоторые ваши ресурсы, инстанции просто так простаивают, и вы фактически впустую оплачиваете за его использование. Третье направление – это optimal pricing model. Мы с вами ранее проговорили, какие модели оплаты существуют для сервиса Amazon EC2. Таким образом, в зависимости от ваших нагрузок, вы можете подобрать ту модель оплаты, которая будет максимально удобная и эффективная для вас. При этом вы несете минимальные расходы на содержание этой инфраструктуры. Следующий вариант – это оптимизация нашего storage, то есть хранилища. Здесь подразумевается три момента. Первый момент – это то, что нам необходимо подбирать размер жестких дисков оптимальными. То есть для инстенса, для которого требуется 20 ГБ на основном жестком диске, нет необходимости делать большой запас и создавать жесткий диск в 500 ГБ. Вы можете создать с небольшим запасом. Также вы вспомните, что у вас есть сервис CloudWatch, куда вы пересылаете ваши метрики. Вы видите нагруженность ваших жестких дисков в тот момент, когда достигается некий порог. Например, 90% жесткого диска заполнено. В этом случае вы можете произвести какое-то действие, чтобы автоматически увеличить размер жестких дисков. Либо сообщить по любым каналам, будь то e-mail либо SMS, о том, что жесткий диск переполнен, необходимо предпринять какое-то действие. В этом случае вы можете самостоятельно подключиться, либо увеличить, либо посмотреть, почему такое произошло, если это не ожидалось. Второй пункт – это тип EBS-волымов. На следующих лекциях мы с вами пройдем, какие типы EBS-волымов бывают и в каких случаях какой из типов правильнее выбрать. И третий вариант – это то, что у вас есть некоторые снапшоты, то есть бэкапы ваших жестких дисков. Это делается, это требуется для того, чтобы в случае возникновения каких-то проблем вы могли легко восстановиться. Это нормальная практика – делать бэкапы. Но при этом хранить бэкапы пятилетней давности не всегда рационально. Достаточно хранить бэкапы, опять же, в зависимости от ваших бизнес требований, недельной давности, месячной давности, может быть, года давности, но при этом с некоторыми сдвигами по времени. То есть вы храните один бэкап, который год назад был создан, один бэкап, который был создан месяц назад, чтобы туда можно было откатиться, и семь бэкапов на последние семь дней. Это максимально оптимальный вариант хранения бэкапов. Все остальные бэкапы должны быть удалены, потому что за бесполезные бэкапы вы также оплачиваете. Это отдельно созданный ресурс внутри AWS. Чем меньше лишних ресурсов, тем меньше вы, соответственно, оплачиваете. Следует отметить, что процесс оптимизации расходов в облаке – это не разовый процесс. Это не связано, опять же, напрямую с облаком. Облако лишь дает возможность видеть все ваши ресурсы как на ладони. Но при этом проблема того, что нагрузки меняются, новые ресурсы создаются, они существуют как в облаке, так и на локальном дата-центре. Поэтому идея в том, чтобы, имея в наличии максимальную видимость на стороне облака, у вас есть возможность это все измерить, периодически мониторить и делать некоторые шаги по улучшению. После того, как вы проделали это улучшение, все эти шаги циклические повторять, потому как инфраструктура постоянно меняется, команд у вас разработки может быть много, и вся эта инфраструктура, это как живое организм, она постоянно в динамике, что-то с ней происходит. Поэтому правильно измерять, мониторить, отслеживать изменения, видеть текущее состояние и предпринимать какие-то действия, при этом все эти шаги периодически повторять – это правильный процесс работы по оптимизации расходов в облаке. Все необходимые ресурсы, возможности облака для нас предоставляет. Одним из моментов, которые следует отметить – это тегирование. Благодаря тегированию вы сможете ваши ресурсы логически подразделять для того, чтобы работать уже с меньшими группами, так как с меньшими группами работать легче. Приведу пример. Если вы будете тегировать все ваши ресурсы с ID-шником вашего департамента, то вы будете знать, какому департаменту относятся те или иные проблемные ресурсы. Вы знаете, куда адресно обратиться для того, чтобы эту проблему устранить. Более того, помимо тегинга есть ряд интересных сервисов, которые позволяют вам управлять, оптимизировать ваши расходы. Вы всегда можете одним запросом Google найти эти ресурсы, почитать про них и начать их использовать. Мы с вами добрались до конца нашей третьей части, а также до конца нашей сегодняшней лекционной сессии. Давайте пройдемся по самым основным моментам. Мы разобрали, какие модели оплаты существуют для сервиса Amazon EC2. Это on-demand инстанции, reserved инстанции, spot, dedicated instances и dedicated host, а также scheduled reserved instances, которые на текущий момент недоступны. Мы также с вами узнали, что spot instances является наиболее выгодным вариантом в случае, если у нас определенный тип нагрузок. Spot instances могут быть прерваны с двухминутной нотификацией, то есть уведомлением о том, что через два дня вы можете получить скидку с 2 минуты, и этот инстанс будет отключен. Соответственно, вам нужно строить архитектуру таким образом, чтобы адекватно реагировать на вот эти отключения. При этом вы можете получить до 90% скидки, используя spot instances. Далее мы разобрали четыре направления, которые следует рассмотреть для оптимизации ваших затрат в облаке, связанных с сервисами Amazon EC2. Это right sizing, дальше это increasing elasticity, то есть использование, правильное, правильное использование автоскейлинга. Далее optimal pricing model, то есть выбрать ту модель, которая оптимально подходит под наши нагрузки. И четвертое – это оптимизация хранилища, то есть есть некоторые нюансы по работе с нашими хранилищами. Про сервисы хранения storage мы разберем и более подробно поговорим с вами на следующих наших лекционных занятиях. На этом мы подошли к концу сегодняшнего лекционного занятия. Мы подробнее разобрали сервис EC2, а именно посмотрели, какие шаги нужно предпринять для того, чтобы создать новый EC2 instance. Далее рассмотрели, какие модели оплаты существуют, а также познакомились с теми направлениями работ, которые позволяют нам оптимизировать наши расходы на сервис EC2. На этом мы завершаем нашу сегодняшнюю сессию. Спасибо за внимание. Увидимся с вами на следующих наших активностях.
