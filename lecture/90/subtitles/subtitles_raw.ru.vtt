1
0:00:00.000 --> 0:00:02.280
Добрый день, уважаемые студенты!

2
0:00:02.280 --> 0:00:05.640
Я рад вас видеть на очередной лекции.

3
0:00:05.640 --> 0:00:08.880
Мы продолжаем предыдущую тему, а именно тему Compute.

4
0:00:08.880 --> 0:00:10.680
Сегодня у нас вторая часть.

5
0:00:10.680 --> 0:00:11.680
Итак, давайте начнем.

6
0:00:11.680 --> 0:00:17.600
В четвертой секции мы с вами поговорим про сервисы,

7
0:00:17.600 --> 0:00:18.880
связанные с контейнерами.

8
0:00:18.880 --> 0:00:23.080
Далее, в пятой секции, мы поговорим про сервис AWS

9
0:00:23.080 --> 0:00:24.080
Lambda.

10
0:00:24.080 --> 0:00:28.000
И самая последняя, шестая секция, про сервис AWS Elastic

11
0:00:28.000 --> 0:00:29.000
Beanstalk.

12
0:00:29.000 --> 0:00:36.920
Секция четвертая, сервисы связанные с контейнерами.

13
0:00:36.920 --> 0:00:41.480
Перед тем как мы доберемся до контейнеров, давайте

14
0:00:41.480 --> 0:00:42.480
вспомним.

15
0:00:42.480 --> 0:00:47.360
У нас есть физический сервер.

16
0:00:47.360 --> 0:00:53.920
Внутри дата-центров AWS физически на определенном участке

17
0:00:53.920 --> 0:00:58.560
расположены максимально мощные физические сервера.

18
0:00:58.560 --> 0:01:05.320
Далее, благодаря виртуализации, вот этот физический виртуальный

19
0:01:05.320 --> 0:01:10.040
сервер подразделяется, делится на независимые друг от друга

20
0:01:10.040 --> 0:01:13.800
виртуальные инстанции EC2.

21
0:01:13.800 --> 0:01:16.320
Таким образом, в рамках EC2 мы можем запрашивать

22
0:01:16.320 --> 0:01:21.040
более 50 различных типов, отличающихся количеством

23
0:01:21.040 --> 0:01:27.700
процессоров ядер процессора, а также количеством оперативной

24
0:01:27.700 --> 0:01:28.700
памяти.

25
0:01:28.700 --> 0:01:36.040
Теперь, двигаясь еще дальше, есть еще один вариант виртуализации

26
0:01:36.040 --> 0:01:40.280
на уровне операционной системы, когда мы устанавливаем

27
0:01:40.280 --> 0:01:43.680
операционную систему и поверх операционной системы

28
0:01:43.680 --> 0:01:46.600
запускаем изолированный контейнер.

29
0:01:46.600 --> 0:01:51.480
То есть, если говорим про EC2 Instance, там вы указываете

30
0:01:51.480 --> 0:01:54.520
во время создания определенную операционную систему.

31
0:01:54.520 --> 0:01:57.200
Когда мы говорим про контейнер, контейнер привязан к

32
0:01:57.200 --> 0:02:00.280
определенной операционной системе и запускается в

33
0:02:00.280 --> 0:02:02.280
рамках этой операционной системы.

34
0:02:02.280 --> 0:02:07.120
Но все остальное, а именно библиотеки, все конфигурации,

35
0:02:07.120 --> 0:02:12.520
код, рантайм, среда запуска вашей программы, она вся

36
0:02:12.520 --> 0:02:14.880
изолирована и самодостаточная.

37
0:02:14.880 --> 0:02:18.600
Таким образом, мы говорим, что контейнер это что-то,

38
0:02:18.600 --> 0:02:24.400
что repeatable, то есть, оно легко переносимое.

39
0:02:24.400 --> 0:02:29.000
То есть, вы берете готовый контейнер и копируете ее,

40
0:02:29.000 --> 0:02:31.640
запускаете в другом месте, в другом инвариументе,

41
0:02:31.640 --> 0:02:34.280
и она будет запускаться точно так же, так как она

42
0:02:34.280 --> 0:02:39.280
содержит все необходимое для своего функционирования.

43
0:02:39.280 --> 0:02:42.840
Еще другой важный момент, это то, что виртуальные

44
0:02:42.840 --> 0:02:45.740
машины запускаются намного медленнее по сравнению

45
0:02:45.740 --> 0:02:49.780
с контейнерами.

46
0:02:49.780 --> 0:02:51.120
Теперь двигаемся дальше.

47
0:02:51.120 --> 0:02:54.160
Для того, чтобы создавать контейнеры, работать с

48
0:02:54.160 --> 0:02:56.320
ней, нам нужна определенная программа.

49
0:02:56.320 --> 0:02:59.640
Самая популярная программа, которая позволяет нам создавать

50
0:02:59.640 --> 0:03:01.640
контейнеры, это Docker.

51
0:03:01.640 --> 0:03:02.640
Docker-контейнер.

52
0:03:02.640 --> 0:03:08.280
Docker-контейнер, это такая сущность, которая содержит

53
0:03:08.280 --> 0:03:11.760
в себе все необходимое для запуска и корректного

54
0:03:11.760 --> 0:03:15.520
функционирования вашего приложения, а именно библиотеки,

55
0:03:15.520 --> 0:03:19.480
системные инструменты, код и среда запуска вашей

56
0:03:19.480 --> 0:03:22.760
программы.

57
0:03:22.760 --> 0:03:26.880
Мы проговорили, что такое контейнер самыми простыми

58
0:03:26.880 --> 0:03:27.880
словами.

59
0:03:27.880 --> 0:03:32.240
Теперь давайте копнем немножко глубже.

60
0:03:32.240 --> 0:03:36.000
Когда мы говорим про виртуальные машины, с правой стороны

61
0:03:36.000 --> 0:03:40.840
вы видите пример деплоймента трех различных приложений,

62
0:03:40.840 --> 0:03:43.400
которые работают с различными библиотеками.

63
0:03:43.400 --> 0:03:46.080
Они специально выделены различным цветом, то есть

64
0:03:46.080 --> 0:03:48.800
application1, application2, application3.

65
0:03:48.800 --> 0:03:52.280
Каждая из них запущена на инстанции EC2.

66
0:03:52.280 --> 0:03:56.200
При этом вы видите, что операционная система, она

67
0:03:56.200 --> 0:03:58.240
изолирована друг от друга.

68
0:03:58.240 --> 0:04:01.760
То есть VM1, виртуал машин первая, у нее своя операционная

69
0:04:01.760 --> 0:04:05.600
система, она может совпадать с другими, а может и нет.

70
0:04:05.600 --> 0:04:07.320
Это зависит от самого приложения.

71
0:04:07.320 --> 0:04:15.680
То есть виртуальная машина работает поверх гипервизора.

72
0:04:15.680 --> 0:04:20.440
Теперь следующий уровень виртуализации это контейнеры.

73
0:04:20.440 --> 0:04:25.680
То есть выше гипервизора у нас уровень операционной

74
0:04:25.680 --> 0:04:28.720
системы нашего EC2 инстанца.

75
0:04:28.720 --> 0:04:33.840
Так вот в рамках одного инстанца EC2 вы видите с левой стороны,

76
0:04:33.840 --> 0:04:36.720
что мы запустили три различных контейнера.

77
0:04:36.720 --> 0:04:40.600
Каждый контейнер в себе содержит не только приложение,

78
0:04:40.600 --> 0:04:43.960
но и все, что необходимо для корректного функционирования

79
0:04:43.960 --> 0:04:45.400
каждого приложения.

80
0:04:45.400 --> 0:04:49.600
И при этом вы видите, что приложения работают с различными

81
0:04:49.600 --> 0:04:52.000
библиотеками, не связанные между собой.

82
0:04:52.000 --> 0:04:56.600
Самое главное, что была нужная операционная система.

83
0:04:56.600 --> 0:05:01.320
Здесь необходимо также сделать пометку, что контейнеры,

84
0:05:01.320 --> 0:05:05.280
они достаточно гибкие и могут запускаться на различных

85
0:05:05.280 --> 0:05:06.920
операционных системах.

86
0:05:06.920 --> 0:05:11.440
Основное требование, чтобы были все реализованы, все

87
0:05:11.440 --> 0:05:17.080
необходимые фичи, функционал, который нужно для конкретного

88
0:05:17.080 --> 0:05:18.080
контейнера.

89
0:05:18.080 --> 0:05:21.880
У нас есть различные варианты операционной системы Linux.

90
0:05:21.880 --> 0:05:26.000
В том случае, когда для нашего контейнера нужен

91
0:05:26.000 --> 0:05:29.560
тот функционал, который есть у двух различных вариантов

92
0:05:29.560 --> 0:05:33.360
Linux-операционной системы, мы говорим о том, что этот

93
0:05:33.360 --> 0:05:36.840
контейнер может успешно запуститься и в первом,

94
0:05:36.840 --> 0:05:39.800
и во втором варианте операционной системы.

95
0:05:39.800 --> 0:05:48.480
Таким образом, контейнер в том же состоянии, который

96
0:05:48.480 --> 0:05:52.520
есть, вы можете запускать на любом другом компьютере

97
0:05:52.520 --> 0:05:55.880
на отличающейся операционной системе.

98
0:05:55.880 --> 0:05:59.360
И это придает некоторую гибкость во время работы

99
0:05:59.360 --> 0:06:00.360
с контейнерами.

100
0:06:00.360 --> 0:06:07.440
Другой момент, это то, что в рамках одного из этого

101
0:06:07.440 --> 0:06:11.960
контейнера мы можем запускать очень маленькие контейнеры

102
0:06:11.960 --> 0:06:15.640
и в одном и ситу инстанции может находиться в один

103
0:06:15.640 --> 0:06:19.280
момент времени сотни различных контейнеров.

104
0:06:19.280 --> 0:06:25.960
Каждый контейнер обслуживает какое-то определенное приложение.

105
0:06:25.960 --> 0:06:34.160
Теперь двигаясь к AWS, вы скорее всего уже в уме запланировали,

106
0:06:34.160 --> 0:06:37.400
что для того, чтобы работать с контейнерами, вам необходимо

107
0:06:37.400 --> 0:06:43.240
запустить один и ситу инстанции, там установить докер приложения

108
0:06:43.240 --> 0:06:45.520
и вы можете работать с контейнерами.

109
0:06:45.520 --> 0:06:52.240
Да, это правильный вариант работы с контейнерами в

110
0:06:52.240 --> 0:06:54.840
облаке, но не самый лучший.

111
0:06:54.840 --> 0:06:57.960
Самый лучший вариант, это есть специально созданный

112
0:06:57.960 --> 0:07:01.560
для этого сервис Amazon Elastic Container Service.

113
0:07:01.560 --> 0:07:05.880
Чаще она встречается в сокращенном варианте EACS

114
0:07:05.880 --> 0:07:10.480
и дает возможность вам работать с контейнерами в более удобном

115
0:07:10.480 --> 0:07:11.480
виде.

116
0:07:11.480 --> 0:07:15.560
Таким образом вы можете запускать до 10 тысяч ваших

117
0:07:15.560 --> 0:07:20.080
контейнеров за несколько секунд, используя этот

118
0:07:20.080 --> 0:07:21.080
сервис.

119
0:07:21.080 --> 0:07:25.680
Вы можете также удобно мониторить, управлять и даже настраивать

120
0:07:25.680 --> 0:07:30.800
различные действия и расписания для запуска и управления

121
0:07:30.800 --> 0:07:31.800
вашими контейнерами.

122
0:07:31.800 --> 0:07:38.280
Здесь также следует отметить, что EACS поддерживает не только

123
0:07:38.280 --> 0:07:46.360
on-demand, e-situ-instances, а также spot-instances и reserved-instances.

124
0:07:46.360 --> 0:07:48.080
Давайте рассмотрим пример.

125
0:07:48.080 --> 0:07:50.640
У нас есть некий task definition.

126
0:07:50.640 --> 0:07:53.760
Task definition это описание вашего контейнера.

127
0:07:53.760 --> 0:07:58.480
В нем содержится информация о вашем приложении, какие

128
0:07:58.480 --> 0:08:03.160
порты вы используете, дополнительные параметры возможно вы

129
0:08:03.160 --> 0:08:05.280
задаете для работы приложения.

130
0:08:05.280 --> 0:08:10.520
И представим, что в этом примере мы сделали task definition,

131
0:08:10.520 --> 0:08:13.840
описали два контейнера, контейнер A и контейнер

132
0:08:13.840 --> 0:08:14.840
B.

133
0:08:14.840 --> 0:08:20.820
Теперь в рамках нашей инфраструктуры нам необходимо три инстанца

134
0:08:20.820 --> 0:08:24.840
контейнера A и два инстанца контейнера B.

135
0:08:24.840 --> 0:08:30.960
Таким образом мы делаем task, то есть задача, либо

136
0:08:30.960 --> 0:08:35.440
instance контейнера, если так можно выразиться.

137
0:08:35.440 --> 0:08:38.560
Таким образом мы вот эти маленькие инстанции, в

138
0:08:38.560 --> 0:08:44.040
которых сидят наши контейнеры, через task передаем сервис

139
0:08:44.040 --> 0:08:45.040
Amazon EACS.

140
0:08:45.040 --> 0:08:50.640
И этот сервис для нас в зависимости от наших дополнительных

141
0:08:50.640 --> 0:08:55.080
входных данных для сервиса EACS располагает эти контейнеры

142
0:08:55.080 --> 0:08:59.600
и запускает их в нашем кластере EACS.

143
0:08:59.600 --> 0:09:05.360
Кластер EACS это набор EC2 инстанцев, которые запущены

144
0:09:05.360 --> 0:09:06.440
в виде группы.

145
0:09:06.440 --> 0:09:10.440
Таким образом сервис Amazon EACS устанавливает на каждом

146
0:09:10.440 --> 0:09:13.240
EC2 инстанции агент.

147
0:09:13.240 --> 0:09:17.000
Этот агент как раз таки помогает вам располагать

148
0:09:17.000 --> 0:09:19.560
ваши контейнеры внутри этих EC2 инстанцев.

149
0:09:19.560 --> 0:09:27.200
Когда мы говорим про ECS кластер для нас доступны три варианта.

150
0:09:27.200 --> 0:09:31.400
Первый вариант это когда мы создаем наши контейнеры

151
0:09:31.400 --> 0:09:39.020
и описываем дополнительные параметры какой мощности

152
0:09:39.020 --> 0:09:41.520
должна быть этот контейнер, в каком количестве мы эти

153
0:09:41.520 --> 0:09:46.360
контейнеры создаем, а также необходимые параметры

154
0:09:46.360 --> 0:09:51.120
для настройки сети и взаимодействия этих контейнеров между

155
0:09:51.120 --> 0:09:54.240
собой, то есть networking related settings.

156
0:09:54.240 --> 0:09:59.440
В этом случае мы говорим про кейс с правой стороны

157
0:09:59.440 --> 0:10:07.480
и благодаря связке сервисов Amazon ECS и сервиса AWS Fargate

158
0:10:07.480 --> 0:10:10.440
мы можем сконцентрироваться лишь на наших контейнерах.

159
0:10:10.440 --> 0:10:16.080
Все остальное, то есть управление операционной системы,

160
0:10:16.080 --> 0:10:19.240
управление докер-агентом, также докер-приложением,

161
0:10:19.240 --> 0:10:22.920
где запускаются и работают наши контейнеры, оно передается

162
0:10:22.920 --> 0:10:24.400
под управление AWS.

163
0:10:24.400 --> 0:10:31.480
Это в случае если у вас нет ресурсов либо специалистов

164
0:10:31.480 --> 0:10:35.500
или нет необходимости какой-то супер тонкой настройки

165
0:10:35.500 --> 0:10:38.680
ваших EC2 инстанцев, где запущены ваши контейнеры.

166
0:10:38.680 --> 0:10:44.080
В случае же если вам нужна какая-то тонкая настройка

167
0:10:44.080 --> 0:10:47.360
подвинутая, она не всегда необходима.

168
0:10:47.360 --> 0:10:50.520
Но в этом случае вы можете воспользоваться другим

169
0:10:50.520 --> 0:10:54.560
вариантом слева, когда вы полностью контролируете

170
0:10:54.560 --> 0:11:00.040
и инстанции в рамках ECS-кластера и указываете все необходимые

171
0:11:00.040 --> 0:11:01.760
более тонкие настройки.

172
0:11:01.760 --> 0:11:03.240
В этом случае есть два варианта.

173
0:11:03.240 --> 0:11:09.320
Ваш кластер ECS-кластер будет состоять из EC2-инстанцев

174
0:11:09.320 --> 0:11:10.960
либо Linux, либо Windows.

175
0:11:10.960 --> 0:11:14.520
И в том и в этом случае вам необходимо будет помимо

176
0:11:14.520 --> 0:11:18.520
того, что вы делаете в первом варианте, вам также необходимо

177
0:11:18.520 --> 0:11:23.880
ввести все настройки, которые необходимы для создания

178
0:11:23.880 --> 0:11:25.840
одного EC2-инстанца.

179
0:11:25.840 --> 0:11:29.180
Используя этот шаблон ваших входных данных, уже будет

180
0:11:29.180 --> 0:11:35.400
создаваться ECS-кластер.

181
0:11:35.400 --> 0:11:37.800
Давайте представим следующий кейс.

182
0:11:37.800 --> 0:11:40.960
Вы компания, разрабатываете некоторое приложение и

183
0:11:40.960 --> 0:11:44.640
используете докер контейнеры для этого.

184
0:11:44.640 --> 0:11:47.200
Компания растет, через некоторое время количество

185
0:11:47.200 --> 0:11:50.240
контейнеров, которые у вас есть, оно увеличивается.

186
0:11:50.240 --> 0:11:55.760
И вам нужно что-то, что помогло бы вам эффективно оркестрировать,

187
0:11:55.760 --> 0:11:58.880
то есть управлять вот этот большой объем ваших контейнеров.

188
0:11:58.880 --> 0:12:03.560
Для этого было создано опенсорсное приложение специально

189
0:12:03.560 --> 0:12:06.560
для оркестрации контейнеров, называется Kubernetes.

190
0:12:06.560 --> 0:12:10.360
Либо вы можете чаще встречать как K8S.

191
0:12:10.360 --> 0:12:14.480
Чтобы понять, что такое Kubernetes, когда мы говорим

192
0:12:14.480 --> 0:12:19.240
про докер, мы говорим, что как гостевая операционная

193
0:12:19.240 --> 0:12:23.040
система, мы работаем в рамках одной гостевой операционной

194
0:12:23.040 --> 0:12:24.280
системы.

195
0:12:24.280 --> 0:12:28.360
Когда мы говорим про Kubernetes, мы уже поднимаемся на уровень

196
0:12:28.360 --> 0:12:31.480
выше и работаем уже с несколькими докер хастами.

197
0:12:31.480 --> 0:12:40.800
Kubernetes нам позволяет упростить задачи масштабирования,

198
0:12:40.800 --> 0:12:45.000
провиженинга, то есть запуска наших контейнеров, вопросы

199
0:12:45.000 --> 0:12:49.560
связанные с настройкой сетей, а также распределением

200
0:12:49.560 --> 0:12:50.560
нагрузки.

201
0:12:50.560 --> 0:12:53.200
То есть это то решение, которое нам помогает эффективно

202
0:12:53.200 --> 0:12:56.920
справляться с этим большим количеством разнородных

203
0:12:56.920 --> 0:12:59.440
контейнеров.

204
0:12:59.440 --> 0:13:04.200
Когда мы говорим про Kubernetes, также есть некоторые популярные

205
0:13:04.200 --> 0:13:05.200
термины.

206
0:13:05.200 --> 0:13:09.240
Kubernetes управляет кластером.

207
0:13:09.240 --> 0:13:14.360
Кластер – это набор нескольких виртуальных машин.

208
0:13:14.360 --> 0:13:17.200
Каждая виртуальная машина в рамках кластера называется

209
0:13:17.200 --> 0:13:19.920
нодой.

210
0:13:19.920 --> 0:13:24.000
Мы с вами помним, что в рамках одной виртуальной машины

211
0:13:24.000 --> 0:13:27.920
может запускаться несколько сотен контейнеров.

212
0:13:27.920 --> 0:13:35.000
Так вот, в нашем случае, в случае Kubernetes, как контейнер

213
0:13:35.000 --> 0:13:36.000
выступает подой.

214
0:13:36.000 --> 0:13:39.800
То есть таким образом у нас кластер состоит из нодов,

215
0:13:39.800 --> 0:13:43.800
и в каждой ноде может запускаться большое количество подов,

216
0:13:43.800 --> 0:13:47.840
то есть контейнеров.

217
0:13:47.840 --> 0:13:49.200
Мы двигаемся дальше.

218
0:13:49.200 --> 0:13:53.880
Теперь поговорим про следующий сервис.

219
0:13:53.880 --> 0:13:56.840
Вы, наверное, подумали, что вы сейчас можете поднять

220
0:13:56.840 --> 0:13:59.520
кластер Kubernetes следующим образом.

221
0:13:59.520 --> 0:14:03.920
Запускаете несколько issue2-инстанцев, устанавливаете docker-приложение,

222
0:14:03.920 --> 0:14:07.960
поверх устанавливаете Kubernetes-приложение, и вот у вас есть Kubernetes-кластер,

223
0:14:07.960 --> 0:14:09.600
с которым вы можете работать.

224
0:14:09.600 --> 0:14:12.840
Да, это действительно так, это один из вариантов,

225
0:14:12.840 --> 0:14:17.520
но когда мы работаем с AWS, у нас есть вариант получше,

226
0:14:17.520 --> 0:14:21.200
а именно сервис Amazon Elastic Kubernetes Service.

227
0:14:21.200 --> 0:14:24.000
Чаще вы его будете встречать как Amazon IKS.

228
0:14:24.000 --> 0:14:27.920
Это тот сервис, который предоставляет нам Managed Kubernetes Service.

229
0:14:27.920 --> 0:14:32.400
То есть это тот сервис, который полностью совместим с приложением

230
0:14:32.400 --> 0:14:41.000
Kubernetes, и сервис позволяет пользователям, клиентам

231
0:14:41.000 --> 0:14:45.780
нашего облачного провайдера AWS разгрузиться, и большую

232
0:14:45.780 --> 0:14:50.000
часть операционной деятельности по обслуживанию этого

233
0:14:50.000 --> 0:14:54.640
кластера передать AWS, а сами больше сконцентрироваться

234
0:14:54.640 --> 0:14:55.800
на бизнес-задачах.

235
0:14:55.800 --> 0:15:01.840
То, что этот сервис совместим с приложением Kubernetes, говорит

236
0:15:01.840 --> 0:15:08.240
о том, что мы наши уже запущенные на локальном дата-центре

237
0:15:08.240 --> 0:15:12.120
нагрузки на Kubernetes можем с легкостью перенести на

238
0:15:12.120 --> 0:15:18.160
AWS, а именно в сервис Elastic Kubernetes Service.

239
0:15:18.160 --> 0:15:23.480
У вас может возникнуть вопрос, чем же все-таки отличается

240
0:15:23.480 --> 0:15:26.880
сервис Amazon ECS, а также Amazon IKS.

241
0:15:26.880 --> 0:15:29.840
На самом деле оба варианта, оба сервиса помогают нам

242
0:15:29.840 --> 0:15:34.920
оркестрировать нашим кластером Docker-контейнеров.

243
0:15:34.920 --> 0:15:38.300
Отличие лишь в том, что в первом случае мы работаем

244
0:15:38.300 --> 0:15:44.520
непосредственно с Docker-контейнерами и управляем нашим кластером

245
0:15:44.520 --> 0:15:47.400
посредством сервиса AWS.

246
0:15:47.400 --> 0:15:52.880
Когда мы говорим про IKS, оркестрации кластера уже

247
0:15:52.880 --> 0:16:00.480
занимается не решением от AWS, а программа опенсорсная

248
0:16:00.480 --> 0:16:04.800
Kubernetes, но она обернута в сервис, который нас разгружает

249
0:16:04.800 --> 0:16:06.840
от некоторых операционных моментов.

250
0:16:06.840 --> 0:16:14.400
То есть они похожи в зависимости от того, что у вас установлено,

251
0:16:14.400 --> 0:16:18.040
как ваша инфраструктура поднята, как она функционирует,

252
0:16:18.040 --> 0:16:21.320
либо если сейчас вы ни то ни другое не используете,

253
0:16:21.320 --> 0:16:25.000
то как минимум у клиентов AWS есть возможность выбрать

254
0:16:25.000 --> 0:16:27.880
один из этих вариантов.

255
0:16:27.880 --> 0:16:30.400
Следующий сервис, о котором я хотел вам рассказать,

256
0:16:30.400 --> 0:16:33.560
это Amazon Elastic Container Registry.

257
0:16:33.560 --> 0:16:36.280
Чаще вы его будете встречать как Amazon ECR.

258
0:16:36.280 --> 0:16:39.840
Это тот сервис, который является хранилищем всех

259
0:16:39.840 --> 0:16:41.540
ваших Docker-образов.

260
0:16:41.540 --> 0:16:47.240
Таким образом, когда вы создаете ваш кластер, неважно

261
0:16:47.240 --> 0:16:51.200
с использованием сервиса Amazon ECS, либо с использованием

262
0:16:51.200 --> 0:16:57.240
сервиса Amazon IKS, вам необходимо указать ваш контейнер,

263
0:16:57.240 --> 0:16:58.240
образ этого контейнера.

264
0:16:58.240 --> 0:17:01.560
В этом случае необходимо воспользоваться сервисом

265
0:17:01.560 --> 0:17:02.560
Amazon ECR.

266
0:17:02.560 --> 0:17:05.800
Как аналогия могу привести, когда мы с вами создаем

267
0:17:05.800 --> 0:17:11.360
EC2-инстанц, мы указываем AMI, то есть образ вашего будущего

268
0:17:11.360 --> 0:17:12.360
инстанца.

269
0:17:12.360 --> 0:17:19.800
AMI в этом случае выступает как Docker-образ.

270
0:17:19.800 --> 0:17:25.440
И хранилище всех ваших AMI в случае с контейнерами

271
0:17:25.440 --> 0:17:29.400
это сервис Amazon ECR.

272
0:17:29.400 --> 0:17:31.960
Мы с вами добрались до конца четвертой секции.

273
0:17:31.960 --> 0:17:34.720
Давайте пройдемся по самым основным моментам.

274
0:17:34.720 --> 0:17:41.200
Контейнеры это нечто, что может в себе хранить

275
0:17:41.200 --> 0:17:44.520
все необходимое для успешного запуска вашего приложения.

276
0:17:44.520 --> 0:17:47.800
Сюда входят библиотеки, системные настройки, код

277
0:17:47.800 --> 0:17:48.800
и так далее.

278
0:17:48.800 --> 0:17:55.040
Docker это та программа, которая позволяет вам создавать

279
0:17:55.040 --> 0:17:56.040
контейнеры.

280
0:17:56.040 --> 0:18:01.120
Это одна из самых популярных программ для этого.

281
0:18:01.120 --> 0:18:04.800
Одно приложение может запускаться в нескольких

282
0:18:04.800 --> 0:18:06.680
контейнерах, связанных между собой.

283
0:18:06.680 --> 0:18:13.440
Есть сервис Elastic Container Service, то есть ECR, которое позволяет

284
0:18:13.440 --> 0:18:19.880
вам оркестрировать вашими Docker-контейнерами.

285
0:18:19.880 --> 0:18:24.880
Следующее популярное приложение программы это

286
0:18:24.880 --> 0:18:25.880
Kubernetes.

287
0:18:25.880 --> 0:18:28.820
Это опенсорсное решение, которое позволяет вам

288
0:18:28.820 --> 0:18:31.640
оркестрировать ваши контейнеры.

289
0:18:31.640 --> 0:18:35.200
Специально для Кубернетес был создан отдельный сервис

290
0:18:35.200 --> 0:18:36.920
Elastic Kubernetes Service.

291
0:18:36.920 --> 0:18:42.640
Он совместим с Кубернетес и позволяет вам разгрузиться

292
0:18:42.640 --> 0:18:48.440
от операционной работы, но при этом управлять вашим

293
0:18:48.440 --> 0:18:52.640
кластером Docker-контейнеров через Кубернетес.

294
0:18:52.640 --> 0:18:56.680
И третий сервис это Elastic Container Registry.

295
0:18:56.680 --> 0:19:01.000
Это сервис, который является хранилищем всех ваших

296
0:19:01.000 --> 0:19:04.440
Docker-контейнеров.

297
0:19:04.440 --> 0:19:07.520
Мы с вами добрались до пятой секции и здесь мы поговорим

298
0:19:07.520 --> 0:19:09.280
про сервис AWS Lambda.

299
0:19:09.280 --> 0:19:13.560
Это мой самый любимый сервис внутри всех сервисов AWS.

300
0:19:13.560 --> 0:19:17.360
И сейчас вы узнаете почему.

301
0:19:17.360 --> 0:19:21.640
Мы с вами ранее проговаривали, что у нас есть различные

302
0:19:21.640 --> 0:19:27.040
сервисы, которые предоставляют различные IT-ресурсы.

303
0:19:27.040 --> 0:19:32.240
Когда мы говорим про Compute, EC2-сервис предоставляет

304
0:19:32.240 --> 0:19:34.200
нам виртуальные машины.

305
0:19:34.200 --> 0:19:38.320
Сервисы ECS и EKS помогают нам работать с контейнерами.

306
0:19:38.320 --> 0:19:42.640
Так вот, следующий уровень это AWS Lambda Serverless Computing.

307
0:19:42.640 --> 0:19:49.840
То есть, это сервис, который исключает абсолютно все

308
0:19:49.840 --> 0:19:54.020
операционные задачи под вас и достаточно вам ваш

309
0:19:54.020 --> 0:19:58.440
код загрузить в этот сервис.

310
0:19:58.440 --> 0:20:02.720
Все что связано с запуском этого сервиса, поддержкой,

311
0:20:02.720 --> 0:20:05.880
так далее, настройкой мониторинга занимается и берет на себя

312
0:20:05.880 --> 0:20:08.040
AWS.

313
0:20:08.040 --> 0:20:15.040
Таким образом, я как разработчик могу исключить необходимость

314
0:20:15.040 --> 0:20:18.820
системного администратора при построении какого-то

315
0:20:18.820 --> 0:20:19.820
решения.

316
0:20:19.820 --> 0:20:27.640
Также и вы, так как IT-университеты больше выпускают разработчиков,

317
0:20:27.640 --> 0:20:31.040
нежели системных администраторов, вы также можете воспользоваться

318
0:20:31.040 --> 0:20:34.760
этим сервисом для запуска своих собственных решений,

319
0:20:34.760 --> 0:20:39.440
собственных стартап-проектов, где благодаря AWS исключается

320
0:20:39.440 --> 0:20:43.960
необходимость целого человека, специалиста, то есть, системного

321
0:20:43.960 --> 0:20:45.120
администратора.

322
0:20:45.120 --> 0:20:50.320
Это поможет вам сократить некоторые расходы и увеличить

323
0:20:50.320 --> 0:20:54.800
шансы успешного запуска вашего стартапа.

324
0:20:54.800 --> 0:20:58.760
Касательно оплаты, здесь тоже очень важный момент.

325
0:20:58.760 --> 0:21:02.700
Вы оплачиваете за количество времени, когда лямбда была

326
0:21:02.700 --> 0:21:03.700
запущена.

327
0:21:03.700 --> 0:21:07.840
В случае, когда ваш код не запускается, вы абсолютно

328
0:21:07.840 --> 0:21:09.720
ничего не оплачиваете.

329
0:21:09.720 --> 0:21:16.000
Это также идеально подходящая модель оплаты для тех же

330
0:21:16.000 --> 0:21:19.680
стартапов, либо для тех нагрузок, которые не постоянны.

331
0:21:19.680 --> 0:21:23.080
Представьте, вы некий стартап, у вас нагрузки небольшие,

332
0:21:23.080 --> 0:21:27.280
потому что вы не наработали клиентскую базу, вы не настолько

333
0:21:27.280 --> 0:21:30.680
популярны, таким образом ваш код будет запускаться

334
0:21:30.680 --> 0:21:34.360
только в тот момент, когда ваше приложение будут

335
0:21:34.360 --> 0:21:35.360
использовать.

336
0:21:35.360 --> 0:21:38.200
Если ваше приложение никто не использует, то вы соответственно

337
0:21:38.200 --> 0:21:42.320
ничего не оплачиваете.

338
0:21:42.320 --> 0:21:45.600
Давайте рассмотрим подробнее, какие преимущества у сервиса

339
0:21:45.600 --> 0:21:47.960
AWS LAMBDA есть.

340
0:21:47.960 --> 0:21:51.400
С лямбдой вам нет необходимости изучать новые языки программирования.

341
0:21:51.400 --> 0:21:54.520
Оно и так изначально поддерживает самые популярные языки

342
0:21:54.520 --> 0:22:02.440
программирования, в том числе Python, JavaScript, Node.js, Ruby, C-sharp

343
0:22:02.440 --> 0:22:03.440
и так далее.

344
0:22:03.440 --> 0:22:10.000
Вы уже поняли, что большую часть администрирования

345
0:22:10.000 --> 0:22:13.840
по запуску вашей лямбды берет на себя AWS, вам необходимо

346
0:22:13.840 --> 0:22:17.400
лишь загрузить ваш код.

347
0:22:17.400 --> 0:22:23.080
Внутри AWS также сидит встроена защита от падений.

348
0:22:23.080 --> 0:22:24.080
Что это значит?

349
0:22:24.080 --> 0:22:28.800
Это значит, микроконтейнеры, в котором запускается ваш

350
0:22:28.800 --> 0:22:32.800
код, находятся в нескольких availability зонах в рамках

351
0:22:32.800 --> 0:22:33.800
региона.

352
0:22:33.800 --> 0:22:37.040
Таким образом, если что-то происходит в availability зоне,

353
0:22:37.040 --> 0:22:40.280
то ваш контейнер запустится в другой availability зоне.

354
0:22:40.280 --> 0:22:44.840
Вы этого даже никак не заметите и не почувствуете, не узнаете,

355
0:22:44.840 --> 0:22:47.080
оно встроенно сидит внутри лямбды.

356
0:22:47.080 --> 0:22:51.280
Таким образом, все ваши запросы на лямбду будут

357
0:22:51.280 --> 0:22:56.440
успешно отработаны.

358
0:22:56.440 --> 0:23:00.340
Бывают некоторые нагрузки, когда вам необходимо запускать

359
0:23:00.340 --> 0:23:03.960
несколько лямбд, это какая-то сложная логика и одна лямбда

360
0:23:03.960 --> 0:23:06.560
может запускать другую лямбду, либо в зависимости

361
0:23:06.560 --> 0:23:09.880
от результатов выполнения одной лямбды, при некоторых

362
0:23:09.880 --> 0:23:12.160
дополнительных условиях вы можете запускать или

363
0:23:12.160 --> 0:23:15.080
не запускать другие лямбды.

364
0:23:15.080 --> 0:23:18.160
Для построения этой сложной логики, либо аркистрации

365
0:23:18.160 --> 0:23:22.700
нескольких лямбда функций, вы можете воспользоваться

366
0:23:22.700 --> 0:23:25.360
сервисом AWS Step Functions.

367
0:23:25.360 --> 0:23:28.840
Step Functions как раз таки расписывает эту логику и в зависимости

368
0:23:28.840 --> 0:23:32.080
от логики она будет вызывать ту или иную лямбду.

369
0:23:32.080 --> 0:23:35.600
Но лямбда также может использоваться отдельно, самостоятельно,

370
0:23:35.600 --> 0:23:38.900
независимая функция, которая в зависимости от запроса

371
0:23:38.900 --> 0:23:40.720
возвращает какой-то готовый ответ.

372
0:23:40.720 --> 0:23:44.080
Например, у вас есть веб-сайт и вы запрашиваете информацию

373
0:23:44.080 --> 0:23:45.400
о каком-то продукте.

374
0:23:45.400 --> 0:23:49.080
Таким образом, когда запрос прилетает до вашей лямбды,

375
0:23:49.080 --> 0:23:56.320
лямбда, используя входные данные, идет в хранилище

376
0:23:56.320 --> 0:23:59.720
информацию о ваших продуктах и извлекает необходимую

377
0:23:59.720 --> 0:24:03.640
информацию, далее возвращает это в вызывающей стороне.

378
0:24:03.640 --> 0:24:07.720
Как хранилище у вас может выступить объектное хранилище

379
0:24:07.720 --> 0:24:10.920
в качестве сервиса AWS S3.

380
0:24:10.920 --> 0:24:18.160
Если у вас SQL база данных, это сервис AWS RDS, в случае

381
0:24:18.160 --> 0:24:22.720
если у вас noSQL база данных, то у нас есть AWS DynamoDB, то

382
0:24:22.720 --> 0:24:26.840
есть вариантов интеграции сервиса лямбда с другими

383
0:24:26.840 --> 0:24:30.240
сервисами имеется большое количество.

384
0:24:30.240 --> 0:24:34.960
Также немаловажное преимущество это pay per use pricing, то есть

385
0:24:34.960 --> 0:24:37.880
вы оплачиваете только за то время, когда ваша лямбда

386
0:24:37.880 --> 0:24:39.240
была запущена.

387
0:24:39.240 --> 0:24:42.880
Это позволяет значительно сэкономить ваши затраты,

388
0:24:42.880 --> 0:24:48.000
в случае если ваши нагрузки не постоянны.

389
0:24:48.000 --> 0:24:52.520
Давайте поговорим о самых популярных сервисах, которые

390
0:24:52.520 --> 0:24:56.400
работают в связке с AWS LAMBDA.

391
0:24:56.400 --> 0:24:59.420
Когда мы говорим про объектное хранилище, самым популярным

392
0:24:59.420 --> 0:25:02.880
вариантом является Amazon S3.

393
0:25:02.880 --> 0:25:05.600
Оно нативно интегрируется с этим сервисом и никаких

394
0:25:05.600 --> 0:25:07.640
проблем не возникает.

395
0:25:07.640 --> 0:25:10.820
Другой вариант, когда мы говорим, что нам необходимо

396
0:25:10.820 --> 0:25:13.460
хранить некоторые данные в не структурированном

397
0:25:13.460 --> 0:25:16.600
виде, нам необходимо использовать noSQL баз данных.

398
0:25:16.600 --> 0:25:19.880
В этом случае выступает Amazon DynamoDB.

399
0:25:19.880 --> 0:25:24.520
Amazon DynamoDB является также сервер-лесс решением баз

400
0:25:24.520 --> 0:25:26.760
данных noSQL.

401
0:25:26.760 --> 0:25:30.280
Таким образом она также нативно интегрирована

402
0:25:30.280 --> 0:25:33.000
с сервисом AWS LAMBDA.

403
0:25:33.000 --> 0:25:40.640
Далее у нас есть два сервиса AWS SNS, а также Amazon SQS.

404
0:25:40.640 --> 0:25:48.040
SNS это когда мы в зависимости от тех или иных условий

405
0:25:48.040 --> 0:25:53.760
можем в формате push отправлять уведомления.

406
0:25:53.760 --> 0:26:01.660
Когда мы говорим SQS, это работа с очередью и нагрузки

407
0:26:01.660 --> 0:26:03.240
формата pull.

408
0:26:03.240 --> 0:26:07.600
То есть в случае SNS мы передаем какое-то сообщение, а оно

409
0:26:07.600 --> 0:26:12.640
сразу отправляется, пушится к получателям.

410
0:26:12.640 --> 0:26:14.840
Когда мы говорим SQS, это pull.

411
0:26:14.840 --> 0:26:17.960
То есть в SQS в очереди накапливается определенное количество

412
0:26:17.960 --> 0:26:21.360
сообщений и мы в режиме pull, то есть подтягиваем

413
0:26:21.360 --> 0:26:25.840
необходимый объем сообщений для обработки в тот момент,

414
0:26:25.840 --> 0:26:26.840
когда нам это нужно.

415
0:26:26.840 --> 0:26:31.320
Это два варианта построения архитектуры в облаке и

416
0:26:31.320 --> 0:26:34.880
оба варианта также интегрированы с AWS LAMBDA.

417
0:26:34.880 --> 0:26:38.720
Когда мы говорим, что нам необходимо построить API,

418
0:26:38.720 --> 0:26:42.760
то есть Application Program Interface, мы можем интегрировать

419
0:26:42.760 --> 0:26:45.360
LAMBDA с Amazon API Gateway.

420
0:26:45.360 --> 0:26:51.240
Это одна из самых популярных связок LAMBDA.

421
0:26:51.240 --> 0:26:55.080
Еще один существующий, но менее популярный вариант

422
0:26:55.080 --> 0:26:58.800
сервиса это Application Load Balancer.

423
0:26:58.800 --> 0:27:02.280
Например, может выступать, представьте, у вас есть

424
0:27:02.280 --> 0:27:07.080
кластер EC2, он запускается, делает некоторые нагрузки,

425
0:27:07.080 --> 0:27:11.480
но при этом вы знаете, что после восьми часов вечера

426
0:27:11.480 --> 0:27:21.180
вам смело можно отключать 50% ваших EC2 инстанцев, потому

427
0:27:21.180 --> 0:27:23.240
что нагрузка резко уменьшается.

428
0:27:23.240 --> 0:27:29.000
В этом случае вы можете настроить Event, которое триггерит

429
0:27:29.000 --> 0:27:35.120
вашу LAMBDA в 8 часов вечера, дальше LAMBDA уже передает

430
0:27:35.120 --> 0:27:40.240
запрос на сервис Load Balancer, который сокращает количество

431
0:27:40.240 --> 0:27:46.720
инстанцев EC2.

432
0:27:46.720 --> 0:27:49.840
Давайте теперь подробнее поговорим о том, какие

433
0:27:49.840 --> 0:27:54.680
настройки необходимо произвести для запуска нашей LAMBDA функции.

434
0:27:54.680 --> 0:27:58.120
Самое первое, нам нужен код программы, которая

435
0:27:58.120 --> 0:27:59.600
будет запускаться.

436
0:27:59.600 --> 0:28:06.000
Далее нам необходимо настроить IAM role для LAMBDA функции.

437
0:28:06.000 --> 0:28:10.460
Если вы создаете LAMBDA функцию в AWS Management Console, то для вас

438
0:28:10.460 --> 0:28:15.240
создается роль с минимальными правами, а именно с правами

439
0:28:15.240 --> 0:28:18.620
для сервиса CloudWatch, чтобы функция могла писать туда

440
0:28:18.620 --> 0:28:20.560
свои логи отработки.

441
0:28:20.560 --> 0:28:24.520
Если вам необходимо, чтобы LAMBDA функция работала с

442
0:28:24.520 --> 0:28:28.140
другими AWS сервисами, вам необходимо соответствующие

443
0:28:28.140 --> 0:28:31.280
полисы, права, доступы добавить в эту роль.

444
0:28:31.280 --> 0:28:40.560
Также нам необходимо указать runtime, то есть в какой среде

445
0:28:40.560 --> 0:28:45.360
запускать ваш код, либо это Python, Node.js, C-Sharp и так далее.

446
0:28:45.360 --> 0:28:52.440
Помимо самого кода LAMBDA, мы также можем использовать

447
0:28:52.440 --> 0:28:54.080
другие зависимости.

448
0:28:54.080 --> 0:29:00.400
Это могут быть дополнительные кастомные библиотеки, необходимые

449
0:29:00.400 --> 0:29:02.800
для запуска вашего кода.

450
0:29:02.800 --> 0:29:10.040
В этом случае вам необходимо создать архив и этот архив

451
0:29:10.040 --> 0:29:14.120
загружать в сервисы AWS LAMBDA.

452
0:29:14.120 --> 0:29:18.600
В случае, когда вы не используете дополнительные библиотеки,

453
0:29:18.600 --> 0:29:21.600
библиотеки достаточно редко используются и в случае

454
0:29:21.600 --> 0:29:25.420
Python, стандартных библиотек Python хватает для большинства

455
0:29:25.420 --> 0:29:26.420
задач.

456
0:29:26.420 --> 0:29:32.280
В этом случае у нас есть только код программы и

457
0:29:32.280 --> 0:29:38.040
в этом случае вы можете работать в консоли AWS LAMBDA

458
0:29:38.040 --> 0:29:40.800
и копировать, вставлять код и сохранять этот код

459
0:29:40.800 --> 0:29:43.720
вот в этой же странице, что очень удобно.

460
0:29:43.720 --> 0:29:52.000
Касательно времени запуска, функция максимум может

461
0:29:52.000 --> 0:29:54.520
запускаться 15 минут, то есть 900 секунд.

462
0:29:54.520 --> 0:29:56.520
Больше этого она запускаться не может.

463
0:29:56.520 --> 0:30:01.280
В случае, если вам нужно больше времени, вам необходимо

464
0:30:01.280 --> 0:30:07.800
рассмотреть вариант использования Step Functions, когда одна LAMBDA

465
0:30:07.800 --> 0:30:11.940
запускает следующую LAMBDA, таким образом вы получаете

466
0:30:11.940 --> 0:30:14.160
дополнительные 15 минут запуска.

467
0:30:14.160 --> 0:30:17.700
В случае, если этот вариант вам не подходит, вы можете

468
0:30:17.700 --> 0:30:21.080
также посмотреть в сторону контейнеров либо в сторону

469
0:30:21.080 --> 0:30:22.080
EC2-инстанцев.

470
0:30:22.080 --> 0:30:26.040
В зависимости от вашей бизнес-задачи тот или иной вариант может

471
0:30:26.040 --> 0:30:33.240
быть вам ближе либо выгоден с точки зрения реализации.

472
0:30:33.240 --> 0:30:38.280
Когда мы говорим о мощности нашей функции, то мы контролируем

473
0:30:38.280 --> 0:30:40.600
количество оперативной памяти, которую мы можем

474
0:30:40.600 --> 0:30:41.720
ей выделить.

475
0:30:41.720 --> 0:30:47.640
Мы можем выдать минимально 128 МБ для этой функции,

476
0:30:47.640 --> 0:30:52.960
либо до 10 ГБ оперативной памяти.

477
0:30:52.960 --> 0:30:59.760
Количество ядер будет увеличиваться пропорционально увеличению

478
0:30:59.760 --> 0:31:01.720
количества оперативной памяти.

479
0:31:01.720 --> 0:31:05.520
Ее мы отдельно от оперативной памяти устанавливать не

480
0:31:05.520 --> 0:31:10.160
можем.

481
0:31:10.160 --> 0:31:15.240
Давайте рассмотрим пример использования AWS LAMBDA, достаточно

482
0:31:15.240 --> 0:31:16.320
популярный пример.

483
0:31:16.320 --> 0:31:22.680
У нас есть наборы EC2-инстанцев и в зависимости от наших

484
0:31:22.680 --> 0:31:27.320
нагрузок мы понимаем, что в 10 часов вечера мы можем

485
0:31:27.320 --> 0:31:31.580
отключать все наши инстанции, а в 5 часов утра нам необходимо

486
0:31:31.580 --> 0:31:33.680
стартовать наши инстанции.

487
0:31:33.680 --> 0:31:38.280
Как мы можем настроить нашу архитектуру для того, чтобы

488
0:31:38.280 --> 0:31:39.800
это все работало.

489
0:31:39.800 --> 0:31:41.760
Мы создаем два ивента.

490
0:31:41.760 --> 0:31:45.760
Эти ивенты создаются в сервисе AWS CloudWatch.

491
0:31:45.760 --> 0:31:50.240
Первый ивент по расписанию в 10 часов вечера будет

492
0:31:50.240 --> 0:31:52.720
триггерить первую LAMBDA.

493
0:31:52.720 --> 0:31:55.440
Эта LAMBDA на вход принимает этот ивент.

494
0:31:55.440 --> 0:31:58.200
Также в этой LAMBDA либо в ивенте мы можем прописать

495
0:31:58.200 --> 0:32:02.280
список инстанцев на отключение и в момент запуска этой

496
0:32:02.280 --> 0:32:04.680
LAMBDA у нее есть соответствующая роль.

497
0:32:04.680 --> 0:32:08.120
У этой роли есть права для отключения из этого

498
0:32:08.120 --> 0:32:09.120
инстанцев.

499
0:32:09.120 --> 0:32:13.640
Она запускает соответствующие команды и наши истинсы отключаются.

500
0:32:13.640 --> 0:32:21.000
Второй ивент он по расписанию триггерит в 5 часов утра

501
0:32:21.000 --> 0:32:23.000
уже другую вторую LAMBDA.

502
0:32:23.000 --> 0:32:26.360
У этой LAMBDA есть соответствующая либо та же роль, либо другая

503
0:32:26.360 --> 0:32:30.440
роль, у которой есть права на запуск истинсов.

504
0:32:30.440 --> 0:32:34.840
Так вот в момент триггера ивентом CloudWatch нашей этой

505
0:32:34.840 --> 0:32:40.040
LAMBDA функции она исполняет свой код и в зависимости

506
0:32:40.040 --> 0:32:43.720
от входных данных списка EC2 инстанцев эти инстанцы

507
0:32:43.720 --> 0:32:48.880
она стартует.

508
0:32:48.880 --> 0:32:51.360
Давайте теперь рассмотрим второй пример.

509
0:32:51.360 --> 0:32:54.920
Представим, что у нас есть некоторое приложение,

510
0:32:54.920 --> 0:32:56.800
которое в себе содержит фотографии.

511
0:32:56.800 --> 0:33:02.440
Наш пользователь приложения загружает некоторую фотографию.

512
0:33:02.440 --> 0:33:06.200
Эта фотография у нас сохраняется в S3 bucket.

513
0:33:06.200 --> 0:33:10.840
Далее как только у нас файл загрузился в S3 bucket,

514
0:33:10.840 --> 0:33:14.880
происходит запускается ивент, который триггерит

515
0:33:14.880 --> 0:33:16.160
нашу LAMBDA.

516
0:33:16.160 --> 0:33:19.600
Запускается наша LAMBDA, в ивенте сидят входные данные,

517
0:33:19.600 --> 0:33:25.360
а в том числе информация с ссылкой на эту картинку.

518
0:33:25.360 --> 0:33:27.720
Мы понимаем какая картинка была загружена.

519
0:33:27.720 --> 0:33:31.520
Далее LAMBDA использует свою роль, у нее есть соответствующие

520
0:33:31.520 --> 0:33:32.520
права.

521
0:33:32.520 --> 0:33:37.200
Она загружает эту картинку, обрабатывает ее и создает

522
0:33:37.200 --> 0:33:39.800
эту же картинку в различных разрешениях.

523
0:33:39.800 --> 0:33:43.000
В том числе и картинку так называемую thumbnail.

524
0:33:43.000 --> 0:33:47.800
Это мини версия этой картинки, которая весит очень мало,

525
0:33:47.800 --> 0:33:50.480
но при этом эта картинка отображается, когда мы

526
0:33:50.480 --> 0:33:54.080
видим наши картинки в списке.

527
0:33:54.080 --> 0:34:00.720
И далее после отработки, на подготовке всех необходимых

528
0:34:00.720 --> 0:34:05.520
картинок, она загружает уже эти картинки в другой

529
0:34:05.520 --> 0:34:06.520
S3 bucket.

530
0:34:06.520 --> 0:34:13.880
И если додумывать дальше, то приложение уже может

531
0:34:13.880 --> 0:34:17.240
отображать другим пользователям список этих фотографий

532
0:34:17.240 --> 0:34:20.840
в различных разрешениях, а также может использовать

533
0:34:20.840 --> 0:34:26.240
thumbnail для отображения мини версии при просмотре списка

534
0:34:26.240 --> 0:34:30.320
всех наших картинок.

535
0:34:30.320 --> 0:34:34.560
Давайте подробнее остановимся на основных лимитах сервиса

536
0:34:34.560 --> 0:34:35.560
AWS Lambda.

537
0:34:35.560 --> 0:34:38.440
Здесь хотел бы также отметить, большинство лимитов, она

538
0:34:38.440 --> 0:34:42.160
является soft и может быть увеличена по обращению

539
0:34:42.160 --> 0:34:45.120
в AWS support.

540
0:34:45.120 --> 0:34:48.240
Вы можете в рамках одного региона запускать параллельно

541
0:34:48.240 --> 0:34:52.440
до 1000 execution of Lambda.

542
0:34:52.440 --> 0:34:54.560
То есть представим, что у вас есть определенная

543
0:34:54.560 --> 0:34:58.360
функция, она передает информацию о каком-то продукте и в

544
0:34:58.360 --> 0:35:02.720
случае, если внезапно 1000 пользователей запросят

545
0:35:02.720 --> 0:35:05.760
информацию о некотором продукте и вам необходимо

546
0:35:05.760 --> 0:35:10.600
параллельно запустить 1000 Lambda, то AWS на своей стороне

547
0:35:10.600 --> 0:35:14.880
автоматически создаст микроконтейнеры, где запускаются ваши

548
0:35:14.880 --> 0:35:20.960
лямбы в необходимом количестве до 1000 и успешно запустит

549
0:35:20.960 --> 0:35:21.960
все эти лямбы.

550
0:35:21.960 --> 0:35:27.760
Далее, если количество запросов резко уменьшится, то все

551
0:35:27.760 --> 0:35:32.420
запущенные микроконтейнеры, они будут постепенно уничтожаться

552
0:35:32.420 --> 0:35:34.240
по внутренней логике AWS.

553
0:35:34.240 --> 0:35:37.920
В случае, если у вас придет больше запросов, то вы можете

554
0:35:37.920 --> 0:35:42.520
настроить retry логику и ваш запрос будет через некоторое

555
0:35:42.520 --> 0:35:44.640
время отправлен еще раз.

556
0:35:44.640 --> 0:35:48.840
Так как на тот момент уже будет скорее всего запускаться

557
0:35:48.840 --> 0:35:52.040
меньшее количество лямб, то эти запросы тоже будут

558
0:35:52.040 --> 0:35:55.120
успешно обработаны.

559
0:35:55.120 --> 0:36:00.480
Если мы говорим про размер нашей функции, включая

560
0:36:00.480 --> 0:36:04.280
код, а также все необходимые библиотеки для запуска,

561
0:36:04.280 --> 0:36:11.520
то оно может быть размером до 250 мегабайтов в не архивированном

562
0:36:11.520 --> 0:36:12.520
состоянии.

563
0:36:12.520 --> 0:36:18.600
Если мы говорим про мощность лямбы, то мы можем выделить

564
0:36:18.600 --> 0:36:24.640
минимум 128 мегабайтов оперативной памяти и максимум 10 гигабайтов

565
0:36:24.640 --> 0:36:28.800
оперативной памяти для одной нашей функции.

566
0:36:28.800 --> 0:36:32.360
Здесь следует отметить, что количество ядер процессора

567
0:36:32.360 --> 0:36:38.120
будет выделяться параллельно количеству выделенных

568
0:36:38.120 --> 0:36:41.320
мегабайтов оперативной памяти.

569
0:36:41.320 --> 0:36:47.400
Если мы говорим про максимальную длительность запуска одной

570
0:36:47.400 --> 0:36:51.920
функции, то это 900 секунд либо 15 минут.

571
0:36:51.920 --> 0:36:54.840
Мы с вами добрались до конца пятой секции.

572
0:36:54.840 --> 0:36:57.640
Давайте пройдемся по самым основным моментам.

573
0:36:57.640 --> 0:37:03.280
AWS Lambda это тот сервис, который предоставляет нам бессерверные

574
0:37:03.280 --> 0:37:04.560
мощности.

575
0:37:04.560 --> 0:37:09.120
Идея в том, что мы не менеджим наши серверы, а лишь загружаем

576
0:37:09.120 --> 0:37:10.120
наш код.

577
0:37:10.120 --> 0:37:14.600
Все, что относится к обслуживанию запуска этого кода, оно

578
0:37:14.600 --> 0:37:16.760
происходит на стороне AWS.

579
0:37:16.760 --> 0:37:22.640
Также AWS Lambda включает автоматическое масштабирование.

580
0:37:22.640 --> 0:37:27.320
То есть, если внезапно происходит всплеск запросов на нашу

581
0:37:27.320 --> 0:37:31.280
лямду, то все эти запросы параллельно будут обработаны.

582
0:37:31.280 --> 0:37:37.440
Lambda может быть достаточно мощной и мы можем выделять

583
0:37:37.440 --> 0:37:42.520
до 10 гигабайтов оперативной памяти для одной нашей функции.

584
0:37:42.520 --> 0:37:47.000
Более того, каждая наша лямда может запускаться максимум

585
0:37:47.000 --> 0:37:48.000
15 минут.

586
0:37:48.000 --> 0:37:50.920
Этого времени более чем достаточно для выполнения

587
0:37:50.920 --> 0:37:51.960
большинства задач.

588
0:37:51.960 --> 0:37:58.200
На этом мы остановились на самых основных моментах,

589
0:37:58.200 --> 0:38:01.040
связанных с сервисом AWS Lambda.

590
0:38:01.040 --> 0:38:05.080
Я очень надеюсь, что этот сервис вам пригодится в

591
0:38:05.080 --> 0:38:07.800
будущем при построении ваших стартапов.

592
0:38:07.800 --> 0:38:12.560
Это идеальный выбор для запуска чего-либо в облаке.

593
0:38:12.560 --> 0:38:18.560
И также никогда не забывайте, что нельзя сильно привязываться

594
0:38:18.560 --> 0:38:19.560
к лямде.

595
0:38:19.560 --> 0:38:24.320
И бывают ситуации, когда нужно ваши нагрузки, которые

596
0:38:24.320 --> 0:38:28.280
стали постоянными, переносить уже на другие мощности.

597
0:38:28.280 --> 0:38:31.080
Но когда мы говорим про самое-самое начало, когда

598
0:38:31.080 --> 0:38:36.080
ничего не понятно, ничего не известно, то все серверless

599
0:38:36.080 --> 0:38:41.920
лямды, начиная от лямды, заканчивая другими сервисами,

600
0:38:41.920 --> 0:38:44.520
работающими в связке с этой лямдой, являются идеальным

601
0:38:44.520 --> 0:38:45.520
решением.

602
0:38:45.520 --> 0:38:51.200
На этом мы с вами добрались до шестой секции.

603
0:38:51.200 --> 0:38:54.560
Последняя секция в рамках нашей сегодняшней лекции.

604
0:38:54.560 --> 0:39:01.600
И мы с вами поговорим подробнее про сервис AWS Elastic Beanstalk.

605
0:39:01.600 --> 0:39:05.960
Elastic Beanstalk является следующим примером компьют-сервиса,

606
0:39:05.960 --> 0:39:09.680
предоставляется в форме PaaS, то есть Platform as a Service.

607
0:39:09.680 --> 0:39:14.080
Идея в том, что вы загружаете код вашего веб-приложения,

608
0:39:14.080 --> 0:39:17.760
Elastic Beanstalk поднимает всю необходимую инфраструктуру

609
0:39:17.760 --> 0:39:20.080
для того, чтобы запустить это веб-приложение.

610
0:39:20.080 --> 0:39:25.360
Что подразумевается под поднять инфраструктуру,

611
0:39:25.360 --> 0:39:28.720
это фактически развертывание вашего веб-приложения,

612
0:39:28.720 --> 0:39:33.280
настройка балансирования, нагрузки, а также автоматического

613
0:39:33.280 --> 0:39:36.800
масштабирования и все необходимое связанное с мониторингом

614
0:39:36.800 --> 0:39:39.160
и логированием вашего веб-приложения.

615
0:39:39.160 --> 0:39:43.120
Здесь следует отметить, что этот сервис, использование

616
0:39:43.120 --> 0:39:46.920
этого сервиса является бесплатным, то есть вы ни доллара не

617
0:39:46.920 --> 0:39:49.320
оплачиваете за этот сервис.

618
0:39:49.320 --> 0:39:57.320
Но все те ресурсы, которые были подняты в рамках сервиса

619
0:39:57.320 --> 0:40:00.840
Elastic Beanstalk, они оплачиваются по стандартным тарифам.

620
0:40:00.840 --> 0:40:04.880
Например, если вы передали некоторые входные параметры

621
0:40:04.880 --> 0:40:09.280
в сервис Elastic Beanstalk и для вас была поднята инфраструктура

622
0:40:09.280 --> 0:40:12.800
с двумя EC2-инстанциями, то вы будете оплачивать

623
0:40:12.800 --> 0:40:15.840
за эти два EC2-инстанца по стандартному тарифу этого

624
0:40:15.840 --> 0:40:16.840
сервиса.

625
0:40:16.840 --> 0:40:22.000
Это и относится ко всем другим IT-ресурсам и другим

626
0:40:22.000 --> 0:40:25.800
сервисам AWS, с которым взаимодействует Elastic Beanstalk.

627
0:40:25.800 --> 0:40:29.480
То есть вы бы столько же денег заплатили бы, если

628
0:40:29.480 --> 0:40:33.720
бы вы поднимали те же два EC2-инстанца вручную.

629
0:40:33.720 --> 0:40:39.800
� азница лишь в том, что поднятие инфраструктуры было проделано

630
0:40:39.800 --> 0:40:45.600
вместо вас, для вас, автоматически через сервис Elastic Beanstalk.

631
0:40:45.600 --> 0:40:50.600
Фактически вы оплачиваете ту же сумму, плюс ко всему

632
0:40:50.600 --> 0:40:54.760
этому экономите свое время и поднимаете инфраструктуру

633
0:40:54.760 --> 0:40:55.760
автоматически.

634
0:40:55.760 --> 0:41:00.800
Здесь вы можете наглядно видеть, какую часть работы

635
0:41:00.800 --> 0:41:04.480
AWS через сервис Elastic Beanstalk берет на себя.

636
0:41:04.480 --> 0:41:09.440
То есть то, что вы управляете, это ваш код и ваши настройки

637
0:41:09.440 --> 0:41:11.120
для Elastic Beanstalk.

638
0:41:11.120 --> 0:41:15.560
Все остальное управляется AWS, то есть HTTP-сервер, application

639
0:41:15.560 --> 0:41:19.480
server, language interpreter, то есть среда запуска вашего

640
0:41:19.480 --> 0:41:22.000
кода, операционная система и даже хост.

641
0:41:22.000 --> 0:41:29.120
Elastic Beanstalk вы можете использовать как в AWS Management консоли,

642
0:41:29.120 --> 0:41:34.180
также вы можете использовать AWS CLI для запуска инфраструктуры

643
0:41:34.180 --> 0:41:36.720
с использованием Elastic Beanstalk.

644
0:41:36.720 --> 0:41:40.160
Когда мы говорим про поддержку платформ, то поддерживаются

645
0:41:40.160 --> 0:41:48.000
Docker, Go, Java,.NET, Node.js, PHP, Python и Ruby и другие платформы.

646
0:41:48.000 --> 0:41:51.640
Если мы говорим про веб-серверы, которые поддерживаются,

647
0:41:51.640 --> 0:41:57.240
то для Java приложений поддерживается Apache Tomcat, для PHP и Python приложения

648
0:41:57.240 --> 0:42:00.680
поддерживается Apache HTTP Server.

649
0:42:00.680 --> 0:42:04.400
Если мы говорим про Node.js приложения, для них доступны

650
0:42:04.400 --> 0:42:07.840
NGINX и Apache HTTP Server.

651
0:42:07.840 --> 0:42:11.640
Если Ruby приложения, то это Passenger и Puma.

652
0:42:11.640 --> 0:42:19.800
Если мы говорим про.NET приложения, Java и Docker вместе с Go, то поддерживается

653
0:42:19.800 --> 0:42:25.960
Microsoft Internet Information Services, то есть IIS.

654
0:42:25.960 --> 0:42:28.040
Давайте остановимся на основных преимуществах

655
0:42:28.040 --> 0:42:31.120
сервиса AWS Elastic Beanstalk.

656
0:42:31.120 --> 0:42:34.520
Первое это то, что вы очень быстро и просто можете

657
0:42:34.520 --> 0:42:37.200
начать, то есть запустить ваше веб-приложение, поднимается

658
0:42:37.200 --> 0:42:41.380
вся необходимая инфраструктура, вы фактически меньше времени

659
0:42:41.380 --> 0:42:44.000
теряете на все это дело.

660
0:42:44.000 --> 0:42:46.760
Другой момент это то, что ваши специалисты, ваши

661
0:42:46.760 --> 0:42:52.400
разработчики, они освобождаются от операционной деятельности

662
0:42:52.400 --> 0:42:55.120
и могут сконцентрироваться на бизнес-содачах.

663
0:42:55.120 --> 0:42:59.280
Таким образом, эффективность ваших разработчиков повышается.

664
0:42:59.280 --> 0:43:02.360
Другой момент это то, что Elastic Beanstalk, оно подходит

665
0:43:02.360 --> 0:43:04.400
для большинства веб-приложений.

666
0:43:04.400 --> 0:43:11.120
Таким образом, очень редко, когда возможности Elastic Beanstalk

667
0:43:11.120 --> 0:43:14.960
для веб-приложения становятся мало.

668
0:43:14.960 --> 0:43:20.040
И в большинстве случаев вы будете двигаться с Elastic

669
0:43:20.040 --> 0:43:22.480
Beanstalk и все будет хватать.

670
0:43:22.480 --> 0:43:31.800
Другой момент это то, что в Elastic Beanstalk вы можете достаточно

671
0:43:31.800 --> 0:43:35.920
гибко настроить ваши ресурсы.

672
0:43:35.920 --> 0:43:40.240
Как пример, вы можете указать определенный instance type в

673
0:43:40.240 --> 0:43:44.920
рамках сервиса Amazon EC2, который может поднимать Elastic Beanstalk.

674
0:43:44.920 --> 0:43:51.120
На этом мы подошли к концу шестой секции.

675
0:43:51.120 --> 0:43:53.000
Давайте остановимся на основных моментах.

676
0:43:53.000 --> 0:43:58.320
В случае, когда у вас веб-приложение, то обязательно следует

677
0:43:58.320 --> 0:44:02.480
рассмотреть сервис AWS Elastic Beanstalk, так как она помогает

678
0:44:02.480 --> 0:44:07.200
вам упростить процесс развертывания вашей IT-инфраструктуры

679
0:44:07.200 --> 0:44:08.200
в облаке.

680
0:44:08.200 --> 0:44:11.520
Elastic Beanstalk поддерживает достаточно большой выбор

681
0:44:11.520 --> 0:44:18.480
платформ — это Java,.NET, PHP, Node.js, Python, Ruby, Go, Docker и другие.

682
0:44:18.480 --> 0:44:21.280
Если мы говорим касательно оплаты, это сервис полностью

683
0:44:21.280 --> 0:44:26.480
бесплатный для клиентов AWS и вы не оплачиваете за

684
0:44:26.480 --> 0:44:28.400
использование этого сервиса.

685
0:44:28.400 --> 0:44:31.280
Но вам необходимо оплачивать по стандартным тарифам

686
0:44:31.280 --> 0:44:35.840
за те сервисы, где вы создаете ее ресурсы.

687
0:44:35.840 --> 0:44:39.000
Например, если Elastic Beanstalk поднимает EC2-инстанции,

688
0:44:39.000 --> 0:44:42.440
то да, вы за эти EC2-инстанции в рамках стандартных тарифов

689
0:44:42.440 --> 0:44:47.640
будете оплачивать за использование.

690
0:44:47.640 --> 0:44:49.920
На этом мы подошли к концу нашей сессии.

691
0:44:49.920 --> 0:44:53.040
Давайте остановимся на самых основных моментах.

692
0:44:53.040 --> 0:44:57.080
За эти две лекции мы с вами рассмотрели, какие сервисы

693
0:44:57.080 --> 0:45:00.360
вычисления для нас доступны в AWS.

694
0:45:00.360 --> 0:45:03.680
Мы подробнее познакомились с сервисом Amazon EC2.

695
0:45:03.680 --> 0:45:08.200
Далее мы посмотрели, какие сервисы есть, когда мы

696
0:45:08.200 --> 0:45:09.680
работаем с контейнерами.

697
0:45:09.680 --> 0:45:16.920
Это Amazon EKS, Amazon ECS и Amazon ECR.

698
0:45:16.920 --> 0:45:20.600
Далее познакомились с сервер-лесс решением.

699
0:45:20.600 --> 0:45:22.800
Это AWS Lambda.

700
0:45:22.800 --> 0:45:25.120
� ассмотрели, какие плюсы есть, минусы.

701
0:45:25.120 --> 0:45:29.560
Ну и в самом конце познакомились с сервисом для быстрого

702
0:45:29.560 --> 0:45:31.800
развертывания в веб-приложении.

703
0:45:31.800 --> 0:45:36.520
Это AWS Elastic Beanstalk.

704
0:45:36.520 --> 0:45:41.080
Вы видите, что AWS предоставляет широкий выбор сервисов

705
0:45:41.080 --> 0:45:45.020
и в зависимости от вашей бизнес потребности для

706
0:45:45.020 --> 0:45:48.240
вас могут подойти один или несколько вариантов,

707
0:45:48.240 --> 0:45:49.400
которые вы будете использовать.

708
0:45:49.400 --> 0:45:52.920
Оно будет максимально эффективно и максимально выгодно для

709
0:45:52.920 --> 0:45:53.920
вас.

710
0:45:53.920 --> 0:45:57.600
Если вам необходима дополнительная информация по тому или

711
0:45:57.600 --> 0:46:00.480
иному сервису, здесь вы видите дополнительные

712
0:46:00.480 --> 0:46:04.640
ссылки, которые вам могут быть полезны.

713
0:46:04.640 --> 0:46:07.240
На этом мы завершаем наше сегодняшнее лекционное

714
0:46:07.240 --> 0:46:08.240
занятие.

715
0:46:08.240 --> 0:46:12.880
Я надеюсь, вы научились чему-то новому и увидимся с вами

716
0:46:12.880 --> 0:46:40.640
на следующих наших активностях.
