Добрый день, уважаемые студенты! Я рад вас видеть на самом последнем лекционном занятии нашего курса. Сегодня мы с вами поговорим про автоматическое масштабирование и мониторинг. Окей, давайте начнем. Сегодняшняя лекция поделена на три части. В первой части мы поговорим про балансирование нагрузки и соответствующий сервис AWS Elastic Load Balancing. Следующий сервис, который полностью про мониторинг инфраструктуры в облаке, это Amazon CloudWatch. Самое последнее - это сервис, который позволяет настроить вашу инфраструктуру таким образом, чтобы в зависимости от нагрузки автоматически увеличивалась, либо уменьшалась, это Amazon EC2 Auto Scaling. Начинаем с Elastic Load Balancing. Это сервис, который распределяет входящий трафик приложения, сетевой трафик по нескольким таргетам, в одной, либо в нескольких availability зонах. Elastic Load Balancing это тот сервис, который масштабируется при увеличении вашей нагрузки, таким образом мы оплачиваем только за то, что мы используем. Если сравнивать с локальной инфраструктурой, с локальным дата-центром, когда мы говорим про балансирование нагрузки, то покупается отдельное железо, которое балансирует нагрузку, либо это делается на уровне приложения. То есть какое-то приложение, туда на вход идет весь наш трафик и он дальше распределяет этот трафик по нашим IT-ресурсам. Важный момент - при локальном исполнении приложения, либо железа, оно само не масштабируется. Это отдельный вид работ, на который нужно выделять людей, выделять ресурсы. И в случае, если ваш трафик превысит лимиты вашего локального балансировщика, то он не сможет обработать весь этот трафик и скорее всего упадет. Когда мы говорим про Elastic Load Balancer, он не ограниченный с точки зрения масштабирования. Другой важный момент, вам не нужно покупать лицензии заранее, вы оплачиваете только ровно за то, что вы используете. Существует три вида Load Balancer. Первый - это Application Load Balancer, далее идет Network Load Balancer и последний Classic Load Balancer предыдущего поколения. Давайте остановимся подробнее на каждом из этих видов. Первый Application Load Balancer, это тот ресурс, который работает на уровне HTTP и HTTPS трафика, то есть это седьмой уровень по OSI модели Application Layer. Отличие Load Balancer в том, что это более продвинутый вариант, новая версия Load Balancer, она работает с различными ресурсами, а именно EC2 инстансы, контейнеры, он может балансировать трафик на определенный список IP адресов, а также можно балансировать трафик на лямбда функции. Если мы говорим про второй вид Network Load Balancer, это тот Balancer, который работает на уровне Transport Layer, то есть четвертый уровень по OSI модели, а это трафик TCP и UDP. Отличие в том, что оно оптимизировано для больших нагрузок и в секунду может обрабатывать миллионы запросов. Также оно дополнительно оптимизировано на тот вид трафика, в котором есть внезапный всплеск. И третий, это предыдущее поколение Classic Load Balancer, сейчас она недоступна для выбора, а лишь существует для обратной совместимости и доступна в инфраструктурах, где Classic Load Balancer активен. Оно работает и на четвертом, и на седьмом уровне по OSI модели, поэтому поддерживает HTTP, HTTPS, TCP, UDP трафик. Балансирует нагрузку только на EC2 инстансы, это самая первая версия балансировщика, поэтому по сравнению с Application и Network Load Balancer является не такой функциональной. В целом рекомендация от самого Amazon - это использовать либо Application Load Balancer, либо Network Load Balancer в зависимости от вашей нагрузки. На этом слайде пример архитектуры, где настроен Load Balancer. Вы видите, у нас есть клиенты, Load Balancer настроен не на одну, а на несколько availability zone, чтобы предоставить availability, приходит трафик от наших клиентов, далее Load Balancer направляет на Listener. Listener - это такие ресурсы, которые проверяют все ли в порядке с нашими таргетами. Таргеты - это наши EC2 инстансы, в большинстве случаев, которые обрабатывают конкретный запрос. Listener - также это тот ресурс, на котором можно настроить Health Check, то есть проверка доступности, он через определенные промежутки времени отправляет запрос на таргеты, сам запрос также можно настроить и если не получает ожидаемый ответ помечает таргет как unhealthy, то есть недоступный и балансирует трафик только на healthy targets, то есть доступные таргеты. Как только таргет становится доступным, он возобновляет направление трафика на этот таргет. Если говорить про отличия настройки, то при работе с ALB и NLB мы настраиваем наши таргет группы и все наши таргеты привязываем к таргет группам. Когда мы говорим Classic Load Balancer, то все наши EC2 инстансы привязываются напрямую к Load Balancer. Давайте рассмотрим основные примеры использования ELB. Самый первый - это предоставление высокой доступности и отказоустойчивости ваших приложений. Представим, что вы находитесь в одной availability зоне и у вас 10 таргетов, в случае если половина становится по той или иной причине недоступной, то трафик начинает перенаправляться на оставшиеся 5, при этом на предыдущие 5, которые недоступны, трафик не будет направляться. Если мы говорим про более продвинутую инфраструктуру, когда она развернута на нескольких availability зонах и представим, что что-то произошло с целой availability зоной, то опять же ELB понимает, что таргеты на конкретной availability зоне недоступны, перестает направлять туда трафик. Таким образом трафик, который шел на первую availability зону, перенаправляется на все остальные. Следующее это то, что сейчас достаточно популярным становится использование контейнеров. ELB также не отстает от этих трендов и есть возможность нативно интегрироваться с сервисом ECS, Elastic Container Service. Если использовать связку ELB, CloudWatch и Amazon EC2 Autoscaling, это два сервиса, которые мы пройдем чуть дальше на следующих слайдах, то она позволяет нам превратить нашу инфраструктуру в некий живой абстрактный организм, когда в зависимости от нагрузки у вас увеличивается количество EC2 инстансов и уменьшается, если трафик соответственно уменьшается. Elastic Load Balancer нативно работает с VPC, если ваша инфраструктура развернута с использованием Virtual Private Cloud и настроены также все ресурсы безопасности, то есть Security группы, Network ACL и так далее, то Elastic Load Balancer нативно встраивается в эту инфраструктуру и будет работать со всеми ресурсами внутри вашего VPC. Еще один пункт - это работа с гибридными архитектурами, когда вам нужно балансировать трафик часть на список EC2 инстансов и часть на сервера, находящиеся локально в вашем дата-центре. Это тоже можно настроить и ELB это поддерживает. Самое последнее - это также один из существующих трендов, это бессерверные архитектуры, в этом плане ELB также не отстает от этих трендов и есть возможность как таргеты указать лямбда функции. Таким образом у лямбда функции есть соответствующая связка с ELB и можно напрямую из веб-браузера, с сайта делать соответствующий запрос, который обработает лямбда. Из-за того, что внутри Application load balancer есть возможность настроить сложную логику перенаправления, то соответственно определенный вызов будет направляться на определенную лямбда функцию и соответствующе обрабатываться. Если мы говорим про мониторинг наших load balancer, выделяют три направления. Первое - это Amazon CloudWatch Metrics, когда наш load balancer и соответственно таргеты направляют метрики в CloudWatch Metrics. Оттуда мы уже видим статистику и можем принимать соответствующие решения. Другое - Access Logs, мы можем запросы логировать и сохранять внутри S3 для дальнейшего анализа. Самое последнее - AWS CloudTrail Logs, это когда происходит вызов на AWS API, не важно как через Console, CLI Command Line Interface, либо через SDK. Все эти запросы будут сохранены и в случае инфраструктурных изменения на уровне load balancer, вы сможете посмотреть, кто сделал вызов, какой вызов произошел, с какого IP адреса и так далее. Это нужно для целей аудита, в случае если у вас произошли какие-то изменения на уровне инфраструктуры и это привело к ошибке. На этом мы подошли к концу первой секции нашей сегодняшней лекции. Давайте остановимся на самых основных моментах. Elastic Load Balancing, либо вкратце ELB, это тот сервис, который распределяет входящий трафик на несколько таргетов. Эти таргеты могут находиться в нескольких availability зонах и как таргет могут выступать EC2 инстансы, контейнеры, IP-адреса либо лямбда функции. Существует три вида ELB - это Application Load Balancer, Network Load Balancer и предыдущее поколение Classic Load Balancer. Если мы говорим про связку ELB, CloudWatch и EC2 Autoscaling, связка из этих трех сервисов это мощнейший инструмент, который позволяет превратить вашу инфраструктуру в некий абстрактный живой организм и таким образом она будет изменяться в зависимости от трафика, в случае если у вас внезапный всплеск трафика, то она соответствующе увеличивается, чтобы обработать все ваши входящие запросы и в случае когда у нас небольшое количество запросов, то инфраструктура автоматически уменьшается, для того чтобы не нести расходы впустую. Мы с вами добрались до второй части нашей сегодняшней лекции, подробнее поговорим про сервис Amazon CloudWatch. Amazon CloudWatch - это тот сервис, который предоставляет все необходимые инструменты для мониторинга нашей инфраструктуры в AWS. С CloudWatch мы можем настроить сбор метрик и на эти метрики настроить alarms. То есть представим что мы настроили метрику, мы отправляем информацию по текущему уровню нагрузки на CPU с каждого нашего EC2 инстанcа. Далее мы настроили alarm, когда мы говорим, что при увеличении средней нагрузки на наши EC2 инстансы, при превышении больше 60% происходит некоторое действие, срабатывает alarm и мы можем направить этот alarm на SNS topic, то есть придет уведомление на почту, можем отправить на SQS, для того чтобы она по очереди обрабатывалась, можем отправить на Lambda, чтобы Lambda могла наложить какую-то кастомную логику и что-то сделать, либо можем отправить напрямую на EC2 Auto Scaling, для того чтобы автоматически добавился новый инстанс. Мы также можем накапливать логи внутри CloudWatch, это логи наших приложений, системные логи для дальнейшего аудита и анализа. Еще один функционал, который предоставляет Amazon CloudWatch это настройка events, то есть events - это прописанный документ, в котором описывается определенное событие внутри AWS, в случае когда это событие происходит, то мы можем триггернуть какой-то наш таргет. Приведу пример, мы настроили event, что при отключении EC2 инстанса на availability зоне 1 мы будем триггерить нашу Lambda. Lambda соответственно отработает по какой-то своей логике и вернет ответ. Еще одним таргетом может быть SQS, для того чтобы на email пришло уведомление и мы поняли что у нас произошло подключение EC2 инстанса, а оно не должно было происходить. Мы можем настроить event абсолютно для любых событий происходящих внутри AWS, практически все сервисы поддерживают настройку event. Доступные операции и сервисы вы можете подробнее посмотреть в документации AWS. Давайте подробнее рассмотрим CloudWatch Alarm. Существует три вида, самый популярный - это Static threshold, когда мы мониторим одну определенную метрику, в случае когда его значение превышает, либо становится меньше определенного значения, то срабатывает alarm и отправляется соответствующая информация на наши таргеты, срабатывает действие. Когда мы говорим Anomaly detection, то здесь подключается некоторый искусственный интеллект со стороны AWS и смотрит есть ли некоторые подозрительные скачки внутри наших метрик. И третье - это продвинутый вариант Static threshold, когда мы можем один либо несколько метрик собрать в одном математическом выражении, результат которого будет отслеживаться. Давайте рассмотрим на примере Static threshold, какую информацию необходимо ввести для того чтобы настроить alarm. Самое первое мы указываем Namespace. Namespace это сервис. Если мы говорим EC2, то namespace мы указываем из выпадающего списка AWS / EC2. Далее - Metric. Если возьмем EC2, то у него есть метрика CPU utilization, то есть нагрузка на CPU. Следующее - это Statistic, то есть какая операция срабатывает на нашей метрике. Мы можем взять средние значения, сумму, минимальное, максимальное значение и так далее. Другое - это Period, то есть за какой период учитываются датапойнты. Как мы с вами помним, датапойнты это информация о нашей метрике в определенный момент времени. Представим, что у нас отправляются каждые пять минут метрики по нашему CPU. И каждые пять минут она в CloudWatch отображается одним датапойнтом с соответствующим значением. Так вот период влияет на то, какое количество датапойнтов будет учитываться для принятия решения. Следующее - это Conditions, здесь мы указываем определенные условия, которыми может быть выражение больше, больше либо равно, меньше, меньше либо равно и так далее. Additional configuration information - это дополнительная информация, дополнительные условия, которые могут быть в том числе указаны и как Actions здесь указываются наши таргеты. То есть, что будет триггерить наш alarm. Это может быть SNS topic, это может быть Amazon EC2 Autoscaling действие, либо мы можем триггернуть наш EC2 инстанс. На этом мы добрались до конца второй части. Подробнее изучили сервис CloudWatch. Это тот сервис, который предоставляет все инструменты для мониторинга нашей инфраструктуры. С CloudWatch мы можем хранить и работать с метриками, мы можем собирать логи наших приложений, можем настроить alarms на наши метрики, а также мы можем настроить дополнительные events, при срабатывании которого будут триггериться соответствующие ресурсы AWS. Мы с вами добрались до последней части сегодняшней нашей лекции и это сервис Amazon EC2 Auto Scaling. Когда мы работаем в AWS, создаем приложения, важно, чтобы приложение могло автоматически масштабироваться в сторону увеличения и в сторону уменьшения, в зависимости от спроса, от трафика. Почему это важно? Давайте рассмотрим на следующем примере. Представим, есть приложения и вы видите нагрузку на инфраструктуру в зависимости от дня недели. Вы видите, что основная нагрузка приходится на среду и минимальная нагрузка это в воскресенье. Если мы увеличим серверные мощности, вычислительные мощности до необходимого, чтобы обрабатывать весь трафик в среду, вы видите, сколько лишних ресурсов мы запросим и фактически будем оплачивать воздух. Если мы попытаемся как-то найти такое количество вычислительных ресурсов, чтобы большую часть нагрузки обрабатывать, а остальные урезать, это тоже не очень хорошая стратегия, потому что в этом случае ваши клиенты попросту не смогут получить вашу услугу, сервис и таким образом вы потеряете своих клиентов. Что предлагает нам Amazon EC2 Auto Scaling? Это тот сервис, который помогает автоматически масштабировать как в сторону увеличения, так в сторону уменьшения количества наших EC2 инстансов. И вы видите, что мы с этим сервисом можем идеально управлять количеством необходимых инстансов, чтобы все дни наши EC2 инстансы максимально работали. В этом случае мы не оплачиваем за простой наших серверов всю работу по добавлению новых инстансов и удалению ненужных инстансов проделывает за нас этот сервис. Более того, он автоматически мониторит, если у нас наше приложение либо EC2 инстанс недоступен, то он автоматически его заменяет, что тоже очень важно. И более того, можно настроить несколько опций масштабирования. Это может быть ручное, это может быть масштабирование по расписанию, динамическое, по спросу. Можем настроить predective, то есть прогнозируемое масштабирование, когда ожидается по определенным метрикам увеличение нагрузки, то соответственно этот сервис увеличит количество наших EC2 инстансов. Автоматическое масштабирование хорошо подходит как для прогнозируемых, так и непрогнозируемых нагрузок. На этом слайде вы видите пример нагрузки на инфраструктуру Amazon.com за одну неделю. Мы видим, что пиковые нагрузки, они одинаковые плюс-минус для каждого дня недели, а также минимальные нагрузки также плюс-минус похожи. В этом случае, помимо мониторинга метрик можем настроить масштабирование по расписанию. Мы знаем, что с 19 часов вечера нагрузка начинает увеличиваться в 2 раза, дальше к 21 часам вечера нагрузка увеличивается в 3 раза по сравнению от первоначальной. И соответственно можем заранее приготовить наши инстансы к ожидаемой нагрузке. Если же мы говорим про непредсказуемые нагрузки, давайте рассмотрим пример нагрузки на сайт Amazon.com за ноябрь месяца. В конце месяца мы знаем, у нас проходят Black Friday и Cyber Monday, когда предоставляются большие скидки и нагрузка на сайт растет очень сильно. Если говорить по трафику, по слайду, вы видите, что нагрузка увеличивается в 3-4 раза. И как вы видите, если бы мы подготовили заранее необходимое количество вычислительных мощностей и целый ноябрь ждали бы эти дни, первый момент, не факт, что мы угадаем какая будет нагрузка, даже если мы угадаем, вы видите, нагрузка в этом графике, она всего лишь 24%. Все оставшееся время, то 70% времени наши сервера бы простаивали. В этом случае автоскейлинг дает очень хорошие возможности для того, чтобы исключить ненужные траты в облаке AWS. И все ваши сервера работают в полную силу. Если нагрузка на ваши сервера уменьшается, то соответственно эти сервера отключаются и уже на конкретную нагрузку выделяется лишь необходимое количество EC2 инстансов. Давайте теперь подробнее остановимся на технических тонкостях. Для этого введем понятие Auto Scaling group. Это набор EC2 инстансов, которые воспринимаются как одна логическая группа для целей масштабирования. Когда мы указываем Auto Scaling group, мы даем информацию по нашим EC2 инстансам, а также передаем дополнительные три параметра. Первый - это Minimum size, то есть минимальное количество инстансов в нашей группе, которое возможно, меньше которого Auto Scaling не будет уменьшать. Дальше есть Maximum size, это то количество EC2 инстансов, больше которого добавляться не будет вне зависимости от трафика, нагрузки и так далее, т.е. есть определенный бюджет, который вы не можете превышать и благодаря Minimum size и Maximum size вы можете быть уверены, что вы этот бюджет не превысите. И есть Desired Capacity, это то количество EC2 инстансов, которое будет запущено в самом начале запуска Auto Scaling group. На этом слайде вы можете видеть примеры Scale out, то есть масштабирование в сторону увеличения и Scale in, масштабирование в сторону уменьшения. В самом начале исходное состояние - у нас есть 2 EC2 инстанса, далее происходит у нас Scale out, то есть масштабирование в сторону увеличения и добавляется дополнительный третий инстанс. Как только по тем или иным причинам, например по метрикам мы видим, что нагрузка на наши инстансы достаточно маленькая и есть возможность убрать один EC2 инстанс, и с текущей нагрузкой справится оставшаяся часть серверных мощностей. В этом случае срабатывает Scale in, то есть масштабирование в сторону уменьшения и вы видите, что третий инстанс удаляется, остается 2 инстанса. Двигаемся дальше, давайте рассмотрим входные данные для полноценной настройки Auto Scaling. Первое, мы указываем то, что мы масштабируем, а именно мы настраиваем так называемый Launch config, это информация о наших EC2 инстанcах, AMI, это вся та информация, которую мы вводим во время запуска нашего EC2 инстанcа. Далее, вторая колонка - это Where, то есть где наша Auto Scaling group будет жить. Если это VPC, мы указываем какая это VPC, в каком конкретно subnet-е эта группа живет. Далее, если к Auto Scaling group еще привязан Load balancer, который распределяет трафик по всем инстансам внутри группы, то мы также указываем какой это load balancer. И третье справа - информация по масштабированию, которая связана с Auto Scaling group. Мы можем, например, задать Maintain current number, это когда мы указываем необходимое количество инстансов, которое всегда должно быть доступно. Если, например, указываем 5, в случае возникновения проблем с любым количеством текущих инстансов, они автоматически заменяются и создается то количество инстансов, которое указали в самом начале. Есть Manual scaling, мы можем регулировать параметры minimum, max и desired capacity для того, чтобы увеличивать либо уменьшать количество инстансов в нашей группе. Также мы можем настроить Scheduled scaling, когда по расписанию у нас происходит масштабирование. Можно настроить Dynamic scaling, которое прописывается в scaling policies, а scaling policies, соответственно, смотрят на метрики. Здесь мы можем как раз привязаться на нагрузку на CPU, на нагрузку на оперативную память, на сеть и так далее. И Predictive scaling - это дополнительная опция от AWS Auto Scaling, которая по внутренней своей логике, возможно подключен некоторый искусственный интеллект, который может прогнозировать нагрузку и по своим прогнозам увеличивает, либо уменьшает количество инстансов в нашей Auto Scaling Group-е. Давайте рассмотрим самый популярный пример при настройке динамического масштабирования. Это связка ELB, CloudWatch и EC2 Auto Scaling. Все начинается с того, что у вас есть Auto Scaling Group, она привязана к ELB и ваши таргеты, то есть EC2 инстансы, отправляют метрики в Amazon CloudWatch. На стороне CloudWatch у вас есть настроенный alarm, при превышении, например, CPU нагрузки больше чем на 60% в течение 5 минут, соответственно, CloudWatch отправляет соответствующую команду EC2 Auto Scaling, которая добавляет дополнительный инстанс в Auto Scaling Group. Как только инстанс добавляется в Auto Scaling Group, отправляется команда для Elastic Load Balancer, чтобы зарегистрировать новый таргет внутри Auto Scaling Group и направлять трафик в этот инстанс. Этот процесс происходит на постоянной основе и все начинается с alarm. Я напоминаю, что для того, чтобы настроить alarm, необходимо, чтобы у вас были настроены соответствующие метрики и собиралась необходимая информация. Вместо CPU нагрузки мы можем взять абсолютно любой другой показатель. Мы можем взять для настройки alarm несколько метрик, это тоже возможно. Мы все это время с вами говорили про сервис EC2 Auto Scaling. Здесь же есть очень похожий по названию и по смыслу сервис AWS Auto Scaling. Этот сервис поддерживает большее количество сервисов. Помимо поддержки EC2 инстансов, он умеет работать с Elastic Container Service, с Docker-контейнерами, с DynamoDB, а именно с таблицами и индексами, а также работает с Aurora, а именно с репликами. Таким образом, все указанные сервисы и ресурсы могут масштабироваться с использованием сервиса AWS Auto Scaling. На этом мы заканчиваем третью часть сегодняшней нашей лекции. Подробнее поговорили про сервис Amazon EC2 Auto Scaling, а также AWS Auto Scaling. Они отличаются тем, что второй поддерживает большее количество сервисов, а первый Amazon EC2 Auto Scaling больше заточен под сервис EC2. Связка EC2 Auto Scaling, CloudWatch, а также ELB, дает возможность превратить вашу инфраструктуру в живой организм, который автоматически масштабируется в зависимости от нагрузки на ваше приложение. На этом мы прошли все секции сегодняшней нашей лекции. Давайте остановимся на самых основных моментах. В самом начале мы прошли и познакомились с сервисом Amazon Elastic Load Balancing. Это сервис, который дает возможность распределять нашу нагрузку на вычислительные ресурсы. Есть три вида. ALB Application Load Balancing, NLB Network Load Balancer и Classic Load Balancer, предыдущее поколение, которое на текущий момент недоступно для создания, но для обратной совместимости доступно для старых инфраструктур. Дальше мы поговорили про сервис CloudWatch. Это тот сервис, который предоставляет инструменты для мониторинга всей нашей инфраструктуры в AWS. После чего познакомились с парой сервисов для автомасштабирования. Это Amazon EC2 Auto Scaling, которая работает сервисом EC2, а также Amazon Auto Scaling, который работает с большим количеством сервисов, но смысл остается тот же. Связка из трех сервисов ELB, CloudWatch и Auto Scaling позволяет настроить динамическое масштабирование нашей инфраструктуры в AWS. На этом мы подошли к концу сегодняшней нашей лекции. Я очень надеюсь, что вы получили более полное представление о пройденных сервисах. Если будут вопросы, пишите в наши групповые чаты. И самые интересные вопросы будут опубликованы в наших Q&A сессиях. На этом с вами прощаюсь. Спасибо большое за внимание. Увидимся с вами на следующих наших активностях.