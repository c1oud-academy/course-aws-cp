 Добрый день, уважаемые студенты! Я рад вас всех видеть на самом последнем лекционном занятии нашего курса. Сегодня мы с вами поговорим про автоматическое масштабирование и мониторинг. Окей, давайте начнем. Сегодняшняя лекция поделена на три частей. В первой части мы поговорим про балансирование нагрузки и соответствующий сервис AWS Elastic Load Balancing. Следующий сервис, который полностью про мониторинг вашей инфраструктуры в облаке, это Amazon CloudWatch. Самое последнее это как раз таки тот сервис, который позволяет настроить вашу инфраструктуру таким образом, чтобы в зависимости от нагрузки она либо автоматически увеличивалась, либо уменьшалась. То есть это Amazon EC2 Autoscaling. Следующий сервис, который полностью про мониторинг вашей инфраструктуры в облаке, это Amazon CloudWatch. Самое последнее это Elastic Load Balancing. Это тот сервис, который распределяет входящий трафик приложения, либо сетевой трафик по нескольким таргетам, либо в одной availability зоне, либо в нескольких availability зонах. Это обучение вашей нагрузки таким образом мы оплачиваем только за то, что мы используем. Если сравнивать с локальной инфраструктурой, с локальным дата-центром, то в этом случае, когда мы говорим про балансирование нагрузки, либо покупается отдельное железо, которое балансирует нагрузку, либо это делается на уровне приложения. То есть какое-то приложение, туда на вход идет весь наш трафик и он дальше распределяет этот трафик по нашим IT-ресурсам. Важный момент это то, что при локальном исполнении либо приложения, либо железа, оно само не масштабируется. Это отдельный вид работ, на который нужно выделять людей, выделять ресурсы. И в случае, если ваш трафик, он превысит лимиты вашего балансировщика локального, то он не сможет обработать весь этот трафик и скорее всего упадет. Когда мы говорим про Elastic Load Balancer, он не ограниченный с точки зрения масштабирования и другой важный момент, вам не нужно закупаться заранее, не покупать лицензии заранее, вы оплачиваете только ровно за то, что вы используете. Существует три вида load балансеров. Первый это Application Load Balancer, далее идет Network Load Balancer и последний это Classic Load Balancer предыдущие поколения. Давайте остановимся подробнее на каждом из этих видов. Первый Application Load Balancer, это тот ресурс, который работает на уровне HTTP и HTTPS трафика, то есть это седьмой уровень по оси модели Application Layer. Отличие Load Balancer в том, что это более продвинутый вариант, новая версия Load Balancer, она работает с различными ресурсами, а именно EC2 инстанции, контейнеры, он может балансировать трафик на определенный список IP адресов, а также можно балансировать трафик на лямбда функции. Если мы говорим про второй вид Network Load Balancer, это тот балансер, который работает на уровне Transport Layer, то есть четвертый уровень по оси модели, а этот трафик TCP и DUP. Отличие его в том, что оно оптимизировано для больших нагрузок и в секунду может обрабатывать миллионы запросов. Также оно дополнительно оптимизировано на тот вид трафика, в котором есть внезапный всплеск. И третий, это предыдущее поколение Classic Load Balancer, сейчас она недоступна для выбора, а лишь существует для обратной совместимости и доступна в инфраструктурах, где Classic Load Balancer активен. Оно работает и на четвертом, и на седьмом уровне по оси модели, поэтому поддерживает HTTP, HTTPS, TCP, UDP, трафик. Балансирует он нагрузку только на EC2 инстанции, то есть это самая первая версия балансировщика, поэтому она по сравнению с Application и Network Load Balancer является не такой функциональной. В целом рекомендация от самого Amazon это использовать либо Application Load Balancer, либо Network Load Balancer в зависимости от вашей нагрузки. На этом слайде пример архитектуры, где настроен Load Balancer. Вы видите, что есть у нас клиенты, Load Balancer настроен не на одну, а на несколько availability zone, чтобы предоставить availability, приходит трафик от наших клиентов, далее Load Balancer направляет на Listener. Listener это такие ресурсы, которые проверяют все ли в порядке с нашими таргетами. Таргеты это как раз таки наши EC2 инстанции в большинстве случаев, которые обрабатывают конкретный запрос. Listener также это тот ресурс, на котором можно настроить Health Check, то есть проверка доступности, он через определенные промежутки времени отправляет запрос на таргеты, сам запрос также можно настроить и если не получает ожидаемый ответ помечает таргет как unhealthy, то есть недоступный и балансирует трафик только на healthy targets, то есть доступные таргеты. Как только таргет становится доступным, то он возобновляет направление трафика на этот таргет. Если говорить про отличия настройки, то при работе с ALB и NLB мы настраиваем наши таргет группы и все наши таргеты привязываем к таргет группам. Когда мы говорим Classic Load Balancer, то все наши EC2 инстанции, они привязываются напрямую к Load Balancer. Давайте рассмотрим основные примеры использования ALB. Самый первый это предоставление высокой доступности и отказа устойчивости ваших приложений. Представим, что вы находитесь в одной availability зоне и у вас 10 таргетов, в случае если половина становится по той или иной причине недоступной, то трафик начинает перенаправляться на оставшиеся 5, при этом на предыдущие 5, которые недоступны, трафик не будет направляться. Если мы говорим про более продвинутую инфраструктуру, когда она развернута на нескольких availability зонах и представим, что что-то произошло с целой availability зоной, то опять же ALB понимает, что таргеты на конкретной availability зоне недоступны, перестает направлять туда трафик, таким образом трафик, который шел на первую availability зону, она перенаправляется на все остальные. Следующее это то, что сейчас достаточно популярным становится использование контейнеров. ALB также не отстает от этих трендов и есть возможность нативно интегрироваться с сервисом ECS, Elastic Container Service. Если использовать связку ALB, CloudWatch и Amazon EC2 Autoscaling, это два сервиса, о котором мы пройдем чуть дальше на следующих слайдах, то она позволяет нам превратить нашу инфраструктуру в некий живой абстрактный организм, когда в зависимости от нагрузки у вас увеличивается количество EC2 инстанцев и уменьшается, если трафик соответственно тоже уменьшается. Elastic Load Balancer нативно работает с VPC, если ваша инфраструктура развернута с использованием Virtual Private Cloud и настроены также все ресурсы безопасности, то есть Security группы, Network ACL и так далее, то Elastic Load Balancer нативно встраивается в эту инфраструктуру и будет работать со всеми ресурсами внутри вашего VPC. Еще один пункт это работа с гибридными архитектурами, когда вам нужно балансировать трафик часть на список EC2 инстанцев и часть на сервера, находящиеся локально в вашем дата центре. Это тоже можно настроить и ELB это поддерживает. Самое последнее это также один из существующих трендов это бессерверные архитектуры, в этом плане ELB также не отстает от этих трендов и есть возможность как таргеты указать лямбда функции. Таким образом у лямбда функции есть соответствующая связка с ELB и можно напрямую из веб браузера сайта делать соответствующий запрос, который обработает лямбда. Из-за того, что внутри application load balancer есть возможность настроить сложную логику перенаправления, то соответственно определенный вызов будет направляться на определенную лямбда функцию и соответствующие обрабатываться. Если мы говорим про мониторинг наших load balancer выделяет три направления. Первое это Amazon CloudWatch Metrics, когда наши load balancer и соответственно таргеты направляют метрики в CloudWatch Metrics. Оттуда мы уже видим статистику и можем принимать соответствующие решения. Другое Access Logs, мы можем все наши запросы логировать и сохранять внутри S3 для дальнейшего анализа. Самое последнее AWS Cloud Trail Logs, это когда происходит вызов на AWS API, не важно как через консоль CLI Command Line Interface либо через SDK. Все эти запросы будут сохранены и в случае изменения инфраструктурных на уровне ваших load balancer вы сможете посмотреть, кто сделал вызов, какой именно вызов произошел с какого IP адреса и так далее. Это нужно для целей аудита в случае если у вас какие-то изменения на уровне инфраструктуры произошли и это привело к ошибке. На этом мы подошли к концу первой секции нашей сегодняшней лекции. Давайте остановимся на самых основных моментах. Elastic Load Balancing либо вкратце ELB это тот сервис, который распределяет входящий трафик на несколько таргетов. Эти таргеты могут находиться в нескольких availability зонах и как таргет могут выступать EC2 инстанции, контейнеры, IP адреса либо лямбда функции. Существует три вида ELB это Application Load Balancer, Network Load Balancer и предыдущее поколение Classic Load Balancer. Если мы говорим по связку ELB, CloudWatch и EC2 Autoscaling связка из этих трех сервисов это мощнейший инструмент, который позволяет превратить вашу инфраструктуру в некий абстрактный живой организм и таким образом она будет изменяться в зависимости от трафика в случае если у вас внезапный всплеск трафика, то она соответствующая увеличивается для того чтобы все ваши запросы обработать все входящие и в случае когда у нас небольшое количество запросов, то инфраструктура автоматически уменьшается для того чтобы не нести расходы впустую. Мы с вами добрались до второй части нашей сегодняшней лекции, подробнее поговорим про сервис Amazon CloudWatch. Amazon CloudWatch это тот сервис, который предоставляет все необходимые инструменты для мониторинга нашей инфраструктуры в AWS. С CloudWatch мы можем настроить сбор metric и на эти метрики настроить алармы. То есть представим что мы настроили метрику, мы отправляем информацию по текущему уровню нагрузки на CPU с каждого нашего EC2 инстанца, далее мы настроили аларм, когда мы говорим что при увеличении средней нагрузки на наши EC2 инстанции при превышении больше 60% происходит некоторое действие, срабатывает аларм и мы можем направить этот аларм на SNS topic, то есть придет уведомление на почту, можем отправить на SQS для того чтобы по очереди она обрабатывалась, можем отправить на Lambda, чтобы Lambda могла какую-то костумную логику наложить и что-то сделать, либо можем отправить напрямую на EC2 Auto Scaling для того чтобы добавился автоматически новый инстанс. Мы также можем накапливать логи внутри CloudWatch, это логи наших приложений, системные логи для дальнейшего аудита и анализа. Еще один функционал который предоставляет Amazon CloudWatch это настройка ивентов, то есть ивенты это прописанный документ и в котором описывается определенное событие внутри AWS, в случае когда это событие происходит, то мы можем триггернуть какой-то наш таргет. Приведу пример, мы настроили ивент, что при отключении EC2 инстанция на availability зоне 1 мы будем триггерить нашу Lambda. Lambda соответственно отработает по какой-то своей логике и вернет ответ. Еще одним таргетом может быть SQL для того чтобы в email пришло уведомление и мы поняли что у нас произошло подключение EC2 инстанция, а оно не должно было происходить. Мы можем настроить ивенты абсолютно для любых событий происходящих внутри AWS, практически все сервисы поддерживают настройку ивентов, доступные операции и сервисы вы можете подробнее посмотреть в документации AWS. Давайте подробнее рассмотрим CloudWatch Alarm. Существует три вида, сам популярный это static threshold, когда мы мониторим одну определенную метрику, в случае когда его значение превышает либо становится меньше определенного значения, то срабатывает аларм и отправляется соответствующая информация на наши таргеты, срабатывает действие. Когда мы говорим anomaly detection, то здесь подключается некоторый искусственный интеллект со стороны AWS и смотрит есть ли некоторые подозрительные скачки внутри наших метрик. И третье это продвинутый вариант static threshold, когда мы можем один либо несколько метрик собрать в одном математическом выражении, результат которого будет отслеживаться. Давайте рассмотрим на примере static threshold, какую информацию необходимо ввести для того, чтобы настроить аларм. Самое первое мы указываем namespace. Namespace это сервис, какой сервис? Если мы говорим EC2, то namespace мы указываем из выпадающего списка AWS slash EC2. Далее метрика, какая метрика? Если мы говорим, как пример возьмем EC2, то у него есть метрика CPU utilization, то есть нагрузка на CPU. Следующее это статистик, то есть какая операция срабатывает на нашей метрике. Мы можем взять средние значения, сумму, минимальное, максимальное значение и так далее. Другое это период, то есть за какой период учитываются датапойнты. Как мы с вами помним, датапойнты это информация о нашей метрике в определенный момент времени. Представим, что у нас отправляются каждые пять минут метрики по нашему CPU. И вот каждые пять минут она в CloudWatch отображается одним датапойнтом с соответствующим значением. Так вот период, он влияет на то, какое количество датапойнтов будет учитываться для принятия решения. Следующее это conditions, здесь мы указываем определенные условия, которым может быть выражение больше, больше либо равно, меньше, меньше либо равно и так далее. Additional configuration information это дополнительная информация, дополнительные условия, которые могут быть в том числе указаны и как actions здесь указываются наши таргеты. То есть, что будет триггерить наш аларм. Это может быть SNS topic, это может быть Amazon EC2 Autoscaling действие либо мы можем триггернуть наш EC2 Instance. На этом мы добрались до конца второй части. Подробнее изучили сервис CloudWatch. Это тот сервис, который предоставляет все инструменты для мониторинга нашей инфраструктуры. С CloudWatch мы можем хранить и работать с метриками, мы можем собирать логи наших приложений, можем настроить алармы на наши метрики, а также мы можем настроить дополнительные ивенты, при срабатывании которого будут триггериться соответствующие ресурсы AWS. Мы с вами добрались до последней части сегодняшней нашей лекции и это сервис Amazon EC2 Autoscaling. Когда мы работаем в AWS, создаем там различные приложения, очень важно, чтобы приложение могло автоматически масштабироваться в сторону увеличения и в сторону уменьшения, в зависимости от спроса, от трафика. Почему это важно? Давайте рассмотрим на следующем примере. Представим, что у нас есть некоторые приложения и вы видите нагрузку на нашу инфраструктуру в зависимости от дня недели. Вы видите, что основная нагрузка, она приходится на среду и минимальная нагрузка это в воскресенье. Если мы увеличим наши серверные мощности, вычислительные мощности до необходимого, чтобы обрабатывать весь трафик в среду, вы видите, сколько лишних ресурсов мы запросим и фактически будем оплачивать воздух. Если мы попытаемся как-то найти такое количество вычислительных ресурсов, чтобы большую часть нагрузки обрабатывать, а остальные урезать, это тоже не очень хорошая стратегия, потому что в этом случае ваши клиенты попросту не смогут получить вашу услугу, сервис и таким образом вы потеряете своих клиентов. Что предлагает нам Amazon EC2 Autoscaling? Это тот сервис, который помогает автоматически масштабировать как в сторону увеличения, так в сторону уменьшения количества наших EC2 инстанцев. И вы видите, что мы с этим сервисом можем идеально управлять количеством необходимых инстанцев, чтобы все дни наши EC2 инстанцы максимально работали. В этом случае мы не оплачиваем за простой наших серверов всю работу по добавлению новых инстанцев и удалению ненужных инстанцев проделывает за нас этот сервис. Более того, он автоматически мониторит, если у нас наше приложение либо EC2 инстанц недоступен, то он автоматически его заменяет, что тоже очень важно. И более того, можно настроить несколько опций масштабирования. Это может быть ручное, это может быть масштабирование по расписанию, динамическое, по спросу. Можем даже настроить предыктив, то есть прогнозируемое масштабирование, когда ожидается по определенным метрикам увеличение нагрузки, то соответственно этот сервис для нас увеличит количество наших EC2 инстанцев. Автоматическое масштабирование, оно хорошо подходит как для прогнозируемых, так и непрогнозируемых нагрузок. На этом сайте вы видите пример нагрузки на инфраструктуру Amazon.com за одну неделю. Мы видим, что пиковые нагрузки, они одинаковые плюс-минус для каждого дня недели, а также минимальные нагрузки также плюс-минус похожи. В этом случае мы помимо мониторинга метрик можем дополнительно настроить масштабирование по расписанию. Мы знаем, что с 7 часов вечера нагрузка начинает увеличиваться в 2 раза, дальше к 9 часов вечера нагрузка увеличивается в 3 раза по сравнению от первоначальной. И соответственно можем заранее приготовить наши инстанции к ожидаемой нагрузке. Если же мы говорим про непредсказуемые нагрузки, давайте рассмотрим пример нагрузки на сайт Amazon.com за ноябрь месяца. В конце месяца мы знаем, у нас проходят Black Friday и Cyber Monday, когда предоставляются большие скидки и нагрузка на сайт растет очень сильно. Если говорить по трафику, по слайду, вы видите, что нагрузка увеличивается в 3-4 раза. И как вы видите, если бы мы подготовили заранее необходимое количество почистительных мощностей и целый ноябрь ждали бы эти дни, первый момент, не факт, что мы угадаем какая будет нагрузка, даже если мы угадаем, вы видите, нагрузка в этом графике, она всего лишь 24%. Все оставшееся время, то 70% времени наши сервера бы простаивали. В этом случае автоскейлинг дает очень хорошие возможности для того, чтобы исключить ненужные траты в облаке AWS. И все ваши сервера работают в полную силу. Если нагрузка на ваши сервера уменьшается, то соответственно эти сервера отключаются и уже на конкретную нагрузку выделяется лишь необходимое количество ICO2-инстанций. Давайте теперь подробнее остановимся на технических тонкостях. Для этого введем понятие автоскейлинг групп. Это набор ICO2-инстанций, которые воспринимаются как одна логическая группа для целей масштабирования. Когда мы указываем автоскейлинг группу, мы даем информацию по нашим ICO2-инстанцам, а также передаем дополнительные три параметра. Первый это минимум сайз, то есть минимальное количество инстанций в нашей группе, которое возможно меньше которого автоскейлинг не будет уменьшать. Дальше есть максимум сайз, это то количество ICO2-инстанцев, больше которого добавляться не будет вне зависимости от трафика, нагрузки и так далее. То есть есть определенный бюджет, который вы не можете превышать и благодаря минимум сайз и максимум сайз вы можете быть уверены, что вы этот бюджет не превышите. И есть Desired Capacity, это то количество ICO2-инстанцев, которое будет запущено в самом начале запуска автоскейлинг группы. На этом сайде вы можете видеть примеры scaling out, то есть увеличение масштабированию в сторону увеличения и scaling in, масштабированию в сторону уменьшения. В самом начале исходное состояние это когда у нас есть 2 ICO2-инстанца, далее происходит у нас scaling out, то есть масштабирование в сторону увеличения и добавляется дополнительный третий инстанс. Как только по тем или иным причинам, например по метрикам мы видим, что нагрузка на наши инстанцы она достаточно маленькая и есть возможность убрать один ICO2-инстанц, и с текущей нагрузкой справится оставшаяся часть серверных мощностей. В этом случае срабатывает scaling in, то есть масштабирование в сторону уменьшения и вы видите, что третий инстанс удаляется, остается 2 инстанца. Двигаемся дальше, давайте рассмотрим какие входные данные нам нужно для полноценной настройки автоскейлинг. Первое, мы указываем что, то есть что мы масштабируем, а именно мы настраиваем так называемый launch config, это информация о наших ICO2-инстанцах, AMI, это вся та информация, которую мы вводим во время запуска нашего ICO2-инстанца. Далее вторая колонка это way, то есть где наша автоскейлинг-группа будет жить. Если это VPC, мы указываем какая это VPC, в каком конкретно сабнете эта группа живет. Далее если к автоскейлинг-группе еще привязан load balancer, который распределяет трафик по всем инстанцам внутри группы, то мы также указываем какой это load balancer. И третье справа это информация по самому масштабированию, которая связана к автоскейлинг-группе. Мы можем, например, задать maintain current number, это когда мы указываем необходимое количество инстанцев, которое всегда должно быть доступным. Если, например, указываем 5, в случае возникновения проблем с любым количеством текущих инстанцев, они автоматически заменяются и создается то количество инстанцев, которые мы указали в самом начале. Есть manual scaling, мы можем регулировать параметрами minimum, max и desired capacity для того, чтобы увеличивать либо уменьшать количество инстанцев в нашей группе. Также мы можем настроить scheduled scaling, когда по расписанию у нас происходит масштабирование. Можно настроить dynamic scaling, которое прописывается в scaling policies, а scaling policies, соответственно, смотрят на метрики. Здесь мы можем как раз привязаться на нагрузку на CPU, на нагрузку на оперативную память, на сеть и так далее. И predictive scaling это дополнительная опция от AWS Autoscaling, которая по внутренней своей логике, возможно подключен некоторый искусственный интеллект, который может прогнозировать нагрузку и по своим прогнозам либо увеличивает, либо уменьшает количество инстанцев в нашей автоскейлинг группе. Давайте рассмотрим самый популярный пример при настройке динамического масштабирования. Это связка ELB, CloudWatch и Isitu Autoscaling. Все начинается с того, что у вас есть автоскейлинг группа, она привязана к ELB и ваши таргеты, то есть Isitu Instance, они отправляют метрики в Amazon CloudWatch. На стороне CloudWatch у вас есть настроенный аларм, когда при превышении, например, CPU нагрузки больше чем на 60% в течение 5 минут, то, соответственно, CloudWatch отправляет соответствующую команду Isitu Autoscaling, которая добавляет дополнительный инстанс в автоскейлинг группу. Как только эта группа, как только этот инстанс добавляется в автоскейлинг группу, отправляется команда для Elastic Load Balancer, чтобы зарегистрировать новый таргет внутри автоскейлинг группы и начать направлять трафик в этот инстанс. Этот процесс происходит на постоянной основе и все начинается с аларма. Я напоминаю, что для того, чтобы настроить аларм, необходимо, чтобы у вас были настроены соответствующие метрики и собиралась необходимая информация. Вместо CPU нагрузки мы можем взять абсолютно любой другой показатель. Мы можем взять для настройки аларма несколько метрик, это тоже возможно. Мы все это время с вами говорили про сервис AWS Isitu Autoscaling. Здесь же есть очень похожий по названию и по смыслу сервис AWS Autoscaling. Этот сервис поддерживает большее количество сервисов. Помимо поддержки Isitu Instance он имеет работать с Elastic Container Service с нашими Docker-контейнерами, может работать с DynamoDB, а именно с таблицами и индексами, а также работает с Avroa, а именно с репликами. Таким образом, все указанные сервисы и ресурсы могут масштабироваться с использованием сервиса AWS Autoscaling. На этом мы заканчиваем третью часть сегодняшней нашей лекции. Подробнее поговорили про сервис Amazon Isitu Autoscaling, а также AWS Autoscaling. Они отличаются тем, что второй поддерживает большее количество сервисов, а первый Amazon Isitu Autoscaling он больше заточен под сервис Isitu. Связка Isitu Autoscaling, CloudWatch, а также ELB, она дает возможность превратить вашу инфраструктуру в живой организм, который автоматически масштабируется в зависимости от нагрузки на ваше приложение. На этом мы прошли все секции в сегодняшней нашей лекции. Давайте остановимся на самых основных моментах. В самом начале мы прошли и познакомились с сервисом Amazon Elastic Load Balancing. Это тот сервис, который дает возможность распределять нашу нагрузку на вычислительные ресурсы. Есть три вида. ELB Application Load Balancing, NLB Network Load Balancer и Classic Load Balancer, предыдущее поколение, которое на текущий момент недоступно для создания, но для обратной совместимости доступно для старых инфраструктур. Дальше мы поговорили про сервис CloudWatch. Это тот сервис, который предоставляет инструменты для мониторинга всей нашей инфраструктуры в AWS. После чего познакомились с парой сервисов для автомасштабирования. Это Amazon Isitu Autoscaling, которая работает сервисом Isitu, а также Amazon Autoscaling, который работает с большим количеством сервисов, но смысл остается тот же. Связка из трех сервисов ELB, CloudWatch и Autoscaling позволяет настроить динамическое масштабирование нашей инфраструктуры в AWS. На этом мы подошли к концу сегодняшней нашей лекции. Я очень надеюсь, что вы получили более полное представление о проведенных сервисах. Если будут вопросы, пишите в наши групповые чаты. И самые интересные вопросы будут опубликованы в наших Q&A сессиях. На этом с вами прощаюсь. Спасибо большое за внимание. Увидимся с вами на следующих наших активностях.
